{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "cifar10 CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulYUc57K00YB",
        "colab_type": "text"
      },
      "source": [
        "# CIFAR 10 ConvNet model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZhCa0XD00YZ",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL5pgrjG00Yo",
        "colab_type": "code",
        "outputId": "a9e457c8-b8a8-4291-ef10-1a1dd38b6865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "%tensorflow_version 2.0 # Set tf2.0 version in Google Colab\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "import datetime\n",
        "import time\n",
        "import tensorboard\n",
        "%load_ext tensorboard\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "print(\"Tensorflow version: \",tf.__version__)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `2.0 # Set tf2.0 version in Google Colab`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Tensorflow version:  2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUACH2R900ZC",
        "colab_type": "text"
      },
      "source": [
        "# Training model with model.fit method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEXmycBR00ZF",
        "colab_type": "text"
      },
      "source": [
        "### callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUzMZxir00ZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, TensorBoard, ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "logdir = 'logs/hparms'\n",
        "chekpoints_dir = os.path.join('chekpoints', \"ckpt_{epoch}\")\n",
        "batch_size = 250 # for having the rest to zero (50000 % 125 = 0)\n",
        "\n",
        "# plot two separable plots of loss/accuracy model \n",
        "def history_model(history):\n",
        "    plt.subplot(121)\n",
        "    #rcParams['figure.figsize'] = 13, 7\n",
        "    plt.plot(history['accuracy'])\n",
        "    plt.plot(history['val_accuracy'])\n",
        "    plt.title('ResNet accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylim([0.0,1.0])\n",
        "    plt.legend(['train_accuracy', 'val_accuracy'], loc='upper left')\n",
        "\n",
        "    plt.subplot(122)\n",
        "    plt.plot(history['loss'])\n",
        "    plt.plot(history['val_loss'])\n",
        "    plt.title('ResNet loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epochs')\n",
        "    plt.ylim([0.0,3.0])\n",
        "    plt.legend(['train_loss', 'val_loss'])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def lr_schedule(epoch: int):\n",
        "    lr = 0.01\n",
        "    if epoch > 180 :\n",
        "        lr = 0.0001\n",
        "    elif epoch > 90 :\n",
        "        lr = 0.001\n",
        "    return lr \n",
        "\n",
        "lrScheduler = LearningRateScheduler(lr_schedule)\n",
        "# defining the callbacks\n",
        "tensorboard_callback = TensorBoard(log_dir=logdir, histogram_freq=1, update_freq='epoch', profile_batch = 100000000)  # log metrics\n",
        "#Keras_callback =   # log hparams\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "# Save model after every 3 epochs (150000 / 50000)\n",
        "checkpoint_callback = ModelCheckpoint(filepath = chekpoints_dir, save_freq=150000, monitor='val_loss',save_best_only=True, verbose = 1)\n",
        "\n",
        "class TrainCallback(Callback):\n",
        "\n",
        "    def __init__(self, x_train, y_train):\n",
        "        super().__init__()\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "    \n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        print(\"<-----------------------------------------------       EPOCH {}     ----------------------------------------------->\".format(epoch+1))\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        (loss, acc) = self.model.evaluate(self.x_train, self.y_train, batch_size = 4096, verbose=0, callbacks=[checkpoint_callback])\n",
        "        print(f\"Real Loss on train : {loss}\")\n",
        "        print(f\"Real Acc on train : {acc}\")\n",
        "    \n",
        "    def on_test_begin(self, epoch, logs=None):\n",
        "        print(\"\\nCalculating the real train loss/accuracy ...\")\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwQjhn0h00ZO",
        "colab_type": "text"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKZCpf820-ys",
        "colab_type": "text"
      },
      "source": [
        "### CNN with 2 blocks of conv2D-Maxpool2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_2avu7Q00ZR",
        "colab_type": "code",
        "outputId": "1adea886-1a39-4d95-ab92-7714484da587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.layers import Input, Add, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.activations import relu, softmax\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "\n",
        "def conv_model(dropout_rate = 0.0):\n",
        "    \n",
        "    dropout_rate = dropout_rate\n",
        "    \n",
        "    input = Input((32, 32, 3), name='input')\n",
        "    \n",
        "    conv_1 = Conv2D(64, (3,3), strides=(1, 1), padding='same', activation='relu', name='conv_1')(input)\n",
        "    pool_1 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_1')(conv_1)\n",
        "    \n",
        "    conv_2 = Conv2D(64, (3,3), strides=(1, 1), padding='same', activation='relu', name='conv_2')(pool_1)\n",
        "    pool_2 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_2')(conv_2)\n",
        "    \n",
        "    flatten = Flatten(name='flatten')(pool_2)\n",
        "    \n",
        "    fc_1 = Dense(120, activation='relu', name='fc_1')(flatten)\n",
        "    fc_2 = Dense(80, activation='relu', name='fc_2')(fc_1)\n",
        "    \n",
        "    output = Dense(10, activation='softmax', name='output')(fc_2)\n",
        "    model = Model(input, output)\n",
        "    \n",
        "    plot_model(model, 'CNN.png')\n",
        "    \n",
        "    model.compile(\n",
        "      optimizer=Adam(learning_rate=0.001),\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "    )\n",
        "\n",
        "    \n",
        "    hist = model.fit(x_train, y_train , epochs=200,\n",
        "                     batch_size=256,\n",
        "                     validation_data=(x_test, y_test))\n",
        "    \n",
        "    history_model(hist.history)\n",
        "\n",
        "conv_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "50000/50000 [==============================] - 2s 44us/sample - loss: 1.6236 - accuracy: 0.4068 - val_loss: 1.3555 - val_accuracy: 0.5096\n",
            "Epoch 2/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2376 - accuracy: 0.5603 - val_loss: 1.1432 - val_accuracy: 0.5942\n",
            "Epoch 3/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 1.0822 - accuracy: 0.6190 - val_loss: 1.0300 - val_accuracy: 0.6330\n",
            "Epoch 4/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.9659 - accuracy: 0.6616 - val_loss: 0.9673 - val_accuracy: 0.6623\n",
            "Epoch 5/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.8881 - accuracy: 0.6903 - val_loss: 0.9212 - val_accuracy: 0.6779\n",
            "Epoch 6/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.8270 - accuracy: 0.7124 - val_loss: 0.8994 - val_accuracy: 0.6873\n",
            "Epoch 7/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.7686 - accuracy: 0.7302 - val_loss: 0.8771 - val_accuracy: 0.6940\n",
            "Epoch 8/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.7228 - accuracy: 0.7467 - val_loss: 0.8425 - val_accuracy: 0.7104\n",
            "Epoch 9/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.6805 - accuracy: 0.7628 - val_loss: 0.8297 - val_accuracy: 0.7159\n",
            "Epoch 10/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.6400 - accuracy: 0.7769 - val_loss: 0.8505 - val_accuracy: 0.7089\n",
            "Epoch 11/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.5938 - accuracy: 0.7933 - val_loss: 0.8830 - val_accuracy: 0.7036\n",
            "Epoch 12/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.5535 - accuracy: 0.8079 - val_loss: 0.8436 - val_accuracy: 0.7135\n",
            "Epoch 13/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.5204 - accuracy: 0.8201 - val_loss: 0.8764 - val_accuracy: 0.7122\n",
            "Epoch 14/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.4822 - accuracy: 0.8317 - val_loss: 0.8839 - val_accuracy: 0.7166\n",
            "Epoch 15/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.4454 - accuracy: 0.8447 - val_loss: 0.9090 - val_accuracy: 0.7209\n",
            "Epoch 16/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.4093 - accuracy: 0.8584 - val_loss: 0.9655 - val_accuracy: 0.7100\n",
            "Epoch 17/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.3852 - accuracy: 0.8651 - val_loss: 0.9976 - val_accuracy: 0.7022\n",
            "Epoch 18/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.3428 - accuracy: 0.8802 - val_loss: 0.9776 - val_accuracy: 0.7186\n",
            "Epoch 19/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.3074 - accuracy: 0.8943 - val_loss: 1.0091 - val_accuracy: 0.7214\n",
            "Epoch 20/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.2854 - accuracy: 0.9023 - val_loss: 1.1595 - val_accuracy: 0.6986\n",
            "Epoch 21/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.2682 - accuracy: 0.9067 - val_loss: 1.1342 - val_accuracy: 0.7075\n",
            "Epoch 22/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.2261 - accuracy: 0.9233 - val_loss: 1.2062 - val_accuracy: 0.7023\n",
            "Epoch 23/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.2011 - accuracy: 0.9318 - val_loss: 1.2623 - val_accuracy: 0.6928\n",
            "Epoch 24/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.1823 - accuracy: 0.9385 - val_loss: 1.2418 - val_accuracy: 0.7120\n",
            "Epoch 25/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.1619 - accuracy: 0.9459 - val_loss: 1.3255 - val_accuracy: 0.7097\n",
            "Epoch 26/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.1496 - accuracy: 0.9490 - val_loss: 1.3879 - val_accuracy: 0.7057\n",
            "Epoch 27/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.1453 - accuracy: 0.9498 - val_loss: 1.4932 - val_accuracy: 0.6975\n",
            "Epoch 28/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.1085 - accuracy: 0.9648 - val_loss: 1.5148 - val_accuracy: 0.7066\n",
            "Epoch 29/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.1164 - accuracy: 0.9602 - val_loss: 1.6143 - val_accuracy: 0.7055\n",
            "Epoch 30/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.1033 - accuracy: 0.9649 - val_loss: 1.6060 - val_accuracy: 0.7042\n",
            "Epoch 31/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0865 - accuracy: 0.9718 - val_loss: 1.6967 - val_accuracy: 0.7086\n",
            "Epoch 32/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0758 - accuracy: 0.9754 - val_loss: 1.7962 - val_accuracy: 0.7059\n",
            "Epoch 33/200\n",
            "50000/50000 [==============================] - 2s 38us/sample - loss: 0.0655 - accuracy: 0.9791 - val_loss: 1.9082 - val_accuracy: 0.7019\n",
            "Epoch 34/200\n",
            "50000/50000 [==============================] - 2s 39us/sample - loss: 0.0639 - accuracy: 0.9786 - val_loss: 1.9005 - val_accuracy: 0.7018\n",
            "Epoch 35/200\n",
            "50000/50000 [==============================] - 2s 38us/sample - loss: 0.0564 - accuracy: 0.9817 - val_loss: 2.0372 - val_accuracy: 0.6959\n",
            "Epoch 36/200\n",
            "50000/50000 [==============================] - 2s 38us/sample - loss: 0.0960 - accuracy: 0.9661 - val_loss: 2.3767 - val_accuracy: 0.6652\n",
            "Epoch 37/200\n",
            "50000/50000 [==============================] - 2s 38us/sample - loss: 0.0894 - accuracy: 0.9683 - val_loss: 2.0381 - val_accuracy: 0.6991\n",
            "Epoch 38/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0495 - accuracy: 0.9842 - val_loss: 2.1090 - val_accuracy: 0.7017\n",
            "Epoch 39/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0444 - accuracy: 0.9855 - val_loss: 2.1784 - val_accuracy: 0.7063\n",
            "Epoch 40/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0423 - accuracy: 0.9866 - val_loss: 2.2389 - val_accuracy: 0.7006\n",
            "Epoch 41/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0644 - accuracy: 0.9772 - val_loss: 2.2933 - val_accuracy: 0.6967\n",
            "Epoch 42/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0601 - accuracy: 0.9788 - val_loss: 2.2480 - val_accuracy: 0.6990\n",
            "Epoch 43/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0562 - accuracy: 0.9809 - val_loss: 2.3443 - val_accuracy: 0.6960\n",
            "Epoch 44/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0783 - accuracy: 0.9729 - val_loss: 2.2769 - val_accuracy: 0.6952\n",
            "Epoch 45/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0555 - accuracy: 0.9811 - val_loss: 2.3994 - val_accuracy: 0.7009\n",
            "Epoch 46/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0261 - accuracy: 0.9922 - val_loss: 2.4258 - val_accuracy: 0.7057\n",
            "Epoch 47/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0383 - accuracy: 0.9869 - val_loss: 2.5731 - val_accuracy: 0.6901\n",
            "Epoch 48/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0545 - accuracy: 0.9813 - val_loss: 2.6037 - val_accuracy: 0.6959\n",
            "Epoch 49/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0485 - accuracy: 0.9835 - val_loss: 2.5152 - val_accuracy: 0.6954\n",
            "Epoch 50/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0599 - accuracy: 0.9789 - val_loss: 2.5710 - val_accuracy: 0.6887\n",
            "Epoch 51/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0565 - accuracy: 0.9800 - val_loss: 2.5536 - val_accuracy: 0.6924\n",
            "Epoch 52/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0524 - accuracy: 0.9824 - val_loss: 2.5621 - val_accuracy: 0.6940\n",
            "Epoch 53/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0305 - accuracy: 0.9899 - val_loss: 2.6461 - val_accuracy: 0.7039\n",
            "Epoch 54/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0321 - accuracy: 0.9897 - val_loss: 2.6859 - val_accuracy: 0.6952\n",
            "Epoch 55/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0489 - accuracy: 0.9831 - val_loss: 2.7110 - val_accuracy: 0.6995\n",
            "Epoch 56/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0475 - accuracy: 0.9836 - val_loss: 2.6856 - val_accuracy: 0.7013\n",
            "Epoch 57/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0325 - accuracy: 0.9893 - val_loss: 2.7255 - val_accuracy: 0.6986\n",
            "Epoch 58/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0420 - accuracy: 0.9853 - val_loss: 2.8215 - val_accuracy: 0.6905\n",
            "Epoch 59/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0484 - accuracy: 0.9831 - val_loss: 2.6942 - val_accuracy: 0.6928\n",
            "Epoch 60/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0477 - accuracy: 0.9836 - val_loss: 2.9822 - val_accuracy: 0.6912\n",
            "Epoch 61/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0534 - accuracy: 0.9823 - val_loss: 2.8935 - val_accuracy: 0.6982\n",
            "Epoch 62/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0333 - accuracy: 0.9888 - val_loss: 2.8753 - val_accuracy: 0.7005\n",
            "Epoch 63/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0130 - accuracy: 0.9961 - val_loss: 2.9595 - val_accuracy: 0.6993\n",
            "Epoch 64/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0387 - accuracy: 0.9869 - val_loss: 2.9885 - val_accuracy: 0.6933\n",
            "Epoch 65/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0459 - accuracy: 0.9844 - val_loss: 2.9511 - val_accuracy: 0.6849\n",
            "Epoch 66/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0769 - accuracy: 0.9743 - val_loss: 2.9054 - val_accuracy: 0.6864\n",
            "Epoch 67/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0273 - accuracy: 0.9905 - val_loss: 2.9204 - val_accuracy: 0.6980\n",
            "Epoch 68/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0320 - accuracy: 0.9885 - val_loss: 3.0209 - val_accuracy: 0.6954\n",
            "Epoch 69/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0321 - accuracy: 0.9893 - val_loss: 3.0203 - val_accuracy: 0.6961\n",
            "Epoch 70/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0141 - accuracy: 0.9956 - val_loss: 3.0162 - val_accuracy: 0.7050\n",
            "Epoch 71/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0176 - accuracy: 0.9938 - val_loss: 3.1432 - val_accuracy: 0.6900\n",
            "Epoch 72/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0610 - accuracy: 0.9795 - val_loss: 3.0289 - val_accuracy: 0.6947\n",
            "Epoch 73/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0329 - accuracy: 0.9886 - val_loss: 3.0213 - val_accuracy: 0.6991\n",
            "Epoch 74/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0304 - accuracy: 0.9898 - val_loss: 3.1812 - val_accuracy: 0.6969\n",
            "Epoch 75/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0452 - accuracy: 0.9846 - val_loss: 3.1649 - val_accuracy: 0.6960\n",
            "Epoch 76/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0411 - accuracy: 0.9861 - val_loss: 3.1430 - val_accuracy: 0.6979\n",
            "Epoch 77/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0223 - accuracy: 0.9929 - val_loss: 3.0866 - val_accuracy: 0.6948\n",
            "Epoch 78/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0236 - accuracy: 0.9920 - val_loss: 3.1805 - val_accuracy: 0.6958\n",
            "Epoch 79/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0374 - accuracy: 0.9872 - val_loss: 3.3249 - val_accuracy: 0.6867\n",
            "Epoch 80/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0692 - accuracy: 0.9772 - val_loss: 3.1769 - val_accuracy: 0.6889\n",
            "Epoch 81/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0349 - accuracy: 0.9878 - val_loss: 3.2466 - val_accuracy: 0.6972\n",
            "Epoch 82/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0165 - accuracy: 0.9942 - val_loss: 3.3055 - val_accuracy: 0.6987\n",
            "Epoch 83/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0188 - accuracy: 0.9936 - val_loss: 3.2887 - val_accuracy: 0.6965\n",
            "Epoch 84/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0141 - accuracy: 0.9951 - val_loss: 3.2632 - val_accuracy: 0.6900\n",
            "Epoch 85/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0282 - accuracy: 0.9905 - val_loss: 3.3091 - val_accuracy: 0.6957\n",
            "Epoch 86/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0611 - accuracy: 0.9797 - val_loss: 3.1407 - val_accuracy: 0.6802\n",
            "Epoch 87/200\n",
            "50000/50000 [==============================] - 2s 38us/sample - loss: 0.0419 - accuracy: 0.9857 - val_loss: 3.2266 - val_accuracy: 0.6933\n",
            "Epoch 88/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0184 - accuracy: 0.9941 - val_loss: 3.3188 - val_accuracy: 0.6955\n",
            "Epoch 89/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0206 - accuracy: 0.9929 - val_loss: 3.3968 - val_accuracy: 0.6936\n",
            "Epoch 90/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0197 - accuracy: 0.9933 - val_loss: 3.3272 - val_accuracy: 0.6979\n",
            "Epoch 91/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0278 - accuracy: 0.9908 - val_loss: 3.4994 - val_accuracy: 0.6905\n",
            "Epoch 92/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0526 - accuracy: 0.9827 - val_loss: 3.3726 - val_accuracy: 0.6811\n",
            "Epoch 93/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0348 - accuracy: 0.9882 - val_loss: 3.2858 - val_accuracy: 0.6969\n",
            "Epoch 94/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0234 - accuracy: 0.9918 - val_loss: 3.3894 - val_accuracy: 0.6977\n",
            "Epoch 95/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0296 - accuracy: 0.9904 - val_loss: 3.3617 - val_accuracy: 0.6936\n",
            "Epoch 96/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0221 - accuracy: 0.9924 - val_loss: 3.3865 - val_accuracy: 0.6932\n",
            "Epoch 97/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0081 - accuracy: 0.9975 - val_loss: 3.3769 - val_accuracy: 0.7001\n",
            "Epoch 98/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0237 - accuracy: 0.9927 - val_loss: 3.6186 - val_accuracy: 0.6937\n",
            "Epoch 99/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0745 - accuracy: 0.9772 - val_loss: 3.4057 - val_accuracy: 0.6959\n",
            "Epoch 100/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0335 - accuracy: 0.9893 - val_loss: 3.6106 - val_accuracy: 0.6876\n",
            "Epoch 101/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0268 - accuracy: 0.9910 - val_loss: 3.3986 - val_accuracy: 0.6981\n",
            "Epoch 102/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0155 - accuracy: 0.9949 - val_loss: 3.4128 - val_accuracy: 0.6960\n",
            "Epoch 103/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0194 - accuracy: 0.9934 - val_loss: 3.5106 - val_accuracy: 0.6912\n",
            "Epoch 104/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0167 - accuracy: 0.9944 - val_loss: 3.5861 - val_accuracy: 0.6918\n",
            "Epoch 105/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0315 - accuracy: 0.9900 - val_loss: 3.4428 - val_accuracy: 0.6890\n",
            "Epoch 106/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0495 - accuracy: 0.9839 - val_loss: 3.4246 - val_accuracy: 0.6922\n",
            "Epoch 107/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0337 - accuracy: 0.9893 - val_loss: 3.5305 - val_accuracy: 0.6924\n",
            "Epoch 108/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0157 - accuracy: 0.9948 - val_loss: 3.6130 - val_accuracy: 0.6932\n",
            "Epoch 109/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0132 - accuracy: 0.9953 - val_loss: 3.6121 - val_accuracy: 0.6950\n",
            "Epoch 110/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0235 - accuracy: 0.9923 - val_loss: 3.6071 - val_accuracy: 0.6949\n",
            "Epoch 111/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0321 - accuracy: 0.9898 - val_loss: 3.6421 - val_accuracy: 0.6903\n",
            "Epoch 112/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0242 - accuracy: 0.9923 - val_loss: 3.7836 - val_accuracy: 0.6821\n",
            "Epoch 113/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0329 - accuracy: 0.9889 - val_loss: 3.7457 - val_accuracy: 0.6943\n",
            "Epoch 114/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0291 - accuracy: 0.9906 - val_loss: 3.6934 - val_accuracy: 0.6962\n",
            "Epoch 115/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0172 - accuracy: 0.9942 - val_loss: 3.6778 - val_accuracy: 0.6954\n",
            "Epoch 116/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0094 - accuracy: 0.9968 - val_loss: 3.7417 - val_accuracy: 0.6988\n",
            "Epoch 117/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0129 - accuracy: 0.9958 - val_loss: 3.7993 - val_accuracy: 0.6824\n",
            "Epoch 118/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0327 - accuracy: 0.9896 - val_loss: 3.7681 - val_accuracy: 0.6898\n",
            "Epoch 119/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0574 - accuracy: 0.9824 - val_loss: 3.6157 - val_accuracy: 0.6892\n",
            "Epoch 120/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0282 - accuracy: 0.9904 - val_loss: 3.7549 - val_accuracy: 0.6927\n",
            "Epoch 121/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0130 - accuracy: 0.9959 - val_loss: 3.6434 - val_accuracy: 0.7005\n",
            "Epoch 122/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0188 - accuracy: 0.9939 - val_loss: 3.9131 - val_accuracy: 0.6879\n",
            "Epoch 123/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0247 - accuracy: 0.9921 - val_loss: 3.6277 - val_accuracy: 0.6935\n",
            "Epoch 124/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0237 - accuracy: 0.9923 - val_loss: 3.8742 - val_accuracy: 0.6922\n",
            "Epoch 125/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0263 - accuracy: 0.9912 - val_loss: 3.7489 - val_accuracy: 0.6923\n",
            "Epoch 126/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0233 - accuracy: 0.9924 - val_loss: 3.7617 - val_accuracy: 0.6895\n",
            "Epoch 127/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0320 - accuracy: 0.9897 - val_loss: 3.7991 - val_accuracy: 0.6921\n",
            "Epoch 128/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0171 - accuracy: 0.9948 - val_loss: 3.8594 - val_accuracy: 0.6930\n",
            "Epoch 129/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0262 - accuracy: 0.9915 - val_loss: 3.8611 - val_accuracy: 0.6960\n",
            "Epoch 130/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0328 - accuracy: 0.9896 - val_loss: 3.7688 - val_accuracy: 0.6966\n",
            "Epoch 131/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0328 - accuracy: 0.9893 - val_loss: 3.8470 - val_accuracy: 0.7005\n",
            "Epoch 132/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0247 - accuracy: 0.9919 - val_loss: 3.7176 - val_accuracy: 0.7000\n",
            "Epoch 133/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0194 - accuracy: 0.9937 - val_loss: 4.0342 - val_accuracy: 0.6941\n",
            "Epoch 134/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0151 - accuracy: 0.9953 - val_loss: 3.9928 - val_accuracy: 0.6924\n",
            "Epoch 135/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0179 - accuracy: 0.9941 - val_loss: 3.9800 - val_accuracy: 0.6960\n",
            "Epoch 136/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0203 - accuracy: 0.9936 - val_loss: 3.9488 - val_accuracy: 0.6925\n",
            "Epoch 137/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0273 - accuracy: 0.9911 - val_loss: 4.1113 - val_accuracy: 0.6914\n",
            "Epoch 138/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0250 - accuracy: 0.9922 - val_loss: 3.9715 - val_accuracy: 0.6855\n",
            "Epoch 139/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0243 - accuracy: 0.9922 - val_loss: 3.9321 - val_accuracy: 0.6947\n",
            "Epoch 140/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0135 - accuracy: 0.9953 - val_loss: 3.9419 - val_accuracy: 0.6927\n",
            "Epoch 141/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0135 - accuracy: 0.9957 - val_loss: 3.9689 - val_accuracy: 0.7020\n",
            "Epoch 142/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0132 - accuracy: 0.9955 - val_loss: 4.0739 - val_accuracy: 0.6962\n",
            "Epoch 143/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0364 - accuracy: 0.9886 - val_loss: 4.0111 - val_accuracy: 0.6915\n",
            "Epoch 144/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0349 - accuracy: 0.9896 - val_loss: 3.9700 - val_accuracy: 0.6926\n",
            "Epoch 145/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0271 - accuracy: 0.9915 - val_loss: 4.0651 - val_accuracy: 0.6851\n",
            "Epoch 146/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0234 - accuracy: 0.9924 - val_loss: 3.9573 - val_accuracy: 0.6952\n",
            "Epoch 147/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0160 - accuracy: 0.9947 - val_loss: 4.0466 - val_accuracy: 0.6920\n",
            "Epoch 148/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0164 - accuracy: 0.9946 - val_loss: 4.1013 - val_accuracy: 0.6896\n",
            "Epoch 149/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0152 - accuracy: 0.9949 - val_loss: 4.0582 - val_accuracy: 0.6933\n",
            "Epoch 150/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0163 - accuracy: 0.9944 - val_loss: 4.0951 - val_accuracy: 0.6915\n",
            "Epoch 151/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0270 - accuracy: 0.9912 - val_loss: 4.0829 - val_accuracy: 0.6978\n",
            "Epoch 152/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0222 - accuracy: 0.9929 - val_loss: 4.1368 - val_accuracy: 0.6919\n",
            "Epoch 153/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0237 - accuracy: 0.9925 - val_loss: 3.9905 - val_accuracy: 0.6947\n",
            "Epoch 154/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0186 - accuracy: 0.9936 - val_loss: 4.2359 - val_accuracy: 0.6991\n",
            "Epoch 155/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0186 - accuracy: 0.9943 - val_loss: 4.3101 - val_accuracy: 0.6881\n",
            "Epoch 156/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0357 - accuracy: 0.9888 - val_loss: 4.1623 - val_accuracy: 0.6949\n",
            "Epoch 157/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0234 - accuracy: 0.9925 - val_loss: 4.0369 - val_accuracy: 0.6900\n",
            "Epoch 158/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0135 - accuracy: 0.9954 - val_loss: 4.1199 - val_accuracy: 0.6959\n",
            "Epoch 159/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0163 - accuracy: 0.9948 - val_loss: 4.0024 - val_accuracy: 0.6966\n",
            "Epoch 160/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0112 - accuracy: 0.9964 - val_loss: 4.2475 - val_accuracy: 0.6871\n",
            "Epoch 161/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0242 - accuracy: 0.9922 - val_loss: 4.2991 - val_accuracy: 0.6909\n",
            "Epoch 162/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0263 - accuracy: 0.9919 - val_loss: 4.1333 - val_accuracy: 0.6935\n",
            "Epoch 163/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0178 - accuracy: 0.9940 - val_loss: 4.1095 - val_accuracy: 0.6976\n",
            "Epoch 164/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0102 - accuracy: 0.9966 - val_loss: 4.3684 - val_accuracy: 0.6977\n",
            "Epoch 165/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0147 - accuracy: 0.9950 - val_loss: 4.4280 - val_accuracy: 0.6933\n",
            "Epoch 166/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 0.0287 - accuracy: 0.9909 - val_loss: 4.1278 - val_accuracy: 0.6891\n",
            "Epoch 167/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0327 - accuracy: 0.9902 - val_loss: 4.1337 - val_accuracy: 0.6956\n",
            "Epoch 168/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0200 - accuracy: 0.9937 - val_loss: 4.2809 - val_accuracy: 0.6929\n",
            "Epoch 169/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0135 - accuracy: 0.9954 - val_loss: 4.4371 - val_accuracy: 0.6925\n",
            "Epoch 170/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0165 - accuracy: 0.9950 - val_loss: 4.3103 - val_accuracy: 0.6853\n",
            "Epoch 171/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0186 - accuracy: 0.9939 - val_loss: 4.3494 - val_accuracy: 0.6928\n",
            "Epoch 172/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0265 - accuracy: 0.9921 - val_loss: 4.5496 - val_accuracy: 0.6892\n",
            "Epoch 173/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0234 - accuracy: 0.9930 - val_loss: 4.3046 - val_accuracy: 0.6919\n",
            "Epoch 174/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0363 - accuracy: 0.9888 - val_loss: 4.1871 - val_accuracy: 0.6901\n",
            "Epoch 175/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0167 - accuracy: 0.9949 - val_loss: 4.2531 - val_accuracy: 0.6901\n",
            "Epoch 176/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0106 - accuracy: 0.9963 - val_loss: 4.2802 - val_accuracy: 0.6958\n",
            "Epoch 177/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 0.0022 - accuracy: 0.9992 - val_loss: 4.3790 - val_accuracy: 0.6980\n",
            "Epoch 178/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 5.3769e-04 - accuracy: 0.9999 - val_loss: 4.4177 - val_accuracy: 0.7055\n",
            "Epoch 179/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 9.3217e-05 - accuracy: 1.0000 - val_loss: 4.4117 - val_accuracy: 0.7068\n",
            "Epoch 180/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 4.6293e-05 - accuracy: 1.0000 - val_loss: 4.4252 - val_accuracy: 0.7067\n",
            "Epoch 181/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 3.6692e-05 - accuracy: 1.0000 - val_loss: 4.4375 - val_accuracy: 0.7071\n",
            "Epoch 182/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 3.1728e-05 - accuracy: 1.0000 - val_loss: 4.4505 - val_accuracy: 0.7067\n",
            "Epoch 183/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 2.8131e-05 - accuracy: 1.0000 - val_loss: 4.4619 - val_accuracy: 0.7068\n",
            "Epoch 184/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 2.5372e-05 - accuracy: 1.0000 - val_loss: 4.4725 - val_accuracy: 0.7060\n",
            "Epoch 185/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 2.3080e-05 - accuracy: 1.0000 - val_loss: 4.4839 - val_accuracy: 0.7059\n",
            "Epoch 186/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 2.1194e-05 - accuracy: 1.0000 - val_loss: 4.4947 - val_accuracy: 0.7056\n",
            "Epoch 187/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 1.9486e-05 - accuracy: 1.0000 - val_loss: 4.5054 - val_accuracy: 0.7055\n",
            "Epoch 188/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 1.8039e-05 - accuracy: 1.0000 - val_loss: 4.5182 - val_accuracy: 0.7052\n",
            "Epoch 189/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 1.6650e-05 - accuracy: 1.0000 - val_loss: 4.5261 - val_accuracy: 0.7052\n",
            "Epoch 190/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 1.5480e-05 - accuracy: 1.0000 - val_loss: 4.5381 - val_accuracy: 0.7057\n",
            "Epoch 191/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 1.4349e-05 - accuracy: 1.0000 - val_loss: 4.5500 - val_accuracy: 0.7051\n",
            "Epoch 192/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 1.3320e-05 - accuracy: 1.0000 - val_loss: 4.5595 - val_accuracy: 0.7052\n",
            "Epoch 193/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 1.2406e-05 - accuracy: 1.0000 - val_loss: 4.5726 - val_accuracy: 0.7055\n",
            "Epoch 194/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 1.1482e-05 - accuracy: 1.0000 - val_loss: 4.5846 - val_accuracy: 0.7060\n",
            "Epoch 195/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 1.0708e-05 - accuracy: 1.0000 - val_loss: 4.5981 - val_accuracy: 0.7061\n",
            "Epoch 196/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 9.9464e-06 - accuracy: 1.0000 - val_loss: 4.6091 - val_accuracy: 0.7057\n",
            "Epoch 197/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 9.2787e-06 - accuracy: 1.0000 - val_loss: 4.6207 - val_accuracy: 0.7059\n",
            "Epoch 198/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 8.5839e-06 - accuracy: 1.0000 - val_loss: 4.6374 - val_accuracy: 0.7069\n",
            "Epoch 199/200\n",
            "50000/50000 [==============================] - 2s 37us/sample - loss: 7.9668e-06 - accuracy: 1.0000 - val_loss: 4.6486 - val_accuracy: 0.7068\n",
            "Epoch 200/200\n",
            "50000/50000 [==============================] - 2s 36us/sample - loss: 7.4225e-06 - accuracy: 1.0000 - val_loss: 4.6625 - val_accuracy: 0.7068\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSYgxurKyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puO6NebDG0KB",
        "colab_type": "text"
      },
      "source": [
        "### Complexifying our model with 6 blocks of conv2D - MaxPool2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVjW1dtFqP3Y",
        "colab_type": "code",
        "outputId": "fd50db7b-5b89-4c5f-d599-ba1bffc83d0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.layers import Input, Add, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.activations import relu, softmax\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "\n",
        "def conv_model(dropout_rate = 0.0):\n",
        "    \n",
        "    dropout_rate = dropout_rate\n",
        "    \n",
        "    input = Input((32, 32, 3), name='input')\n",
        "    \n",
        "    conv_1 = Conv2D(64, (3,3), strides=(1, 1), padding='same', activation='relu', name='conv_1')(input)\n",
        "    pool_1 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_1')(conv_1)\n",
        "    \n",
        "    conv_2 = Conv2D(64, (3,3), strides=(1, 1), padding='same', activation='relu', name='conv_2')(pool_1)\n",
        "    pool_2 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_2')(conv_2)\n",
        "\n",
        "    conv_3 = Conv2D(96, (3,3), strides=(1, 1), padding='same', activation='relu', name='conv_3')(pool_2)\n",
        "    pool_3 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_3')(conv_3)\n",
        "\n",
        "    conv_4 = Conv2D(96, (3,3), strides=(1, 1), padding='same', activation='relu', name='conv_4')(pool_3)\n",
        "    pool_4 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_4')(conv_4)\n",
        "\n",
        "    conv_5 = Conv2D(96, (3,3), strides=(1, 1), padding='same', activation='relu', name='conv_5')(pool_4)\n",
        "    pool_5 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_5')(conv_5)\n",
        "\n",
        "    conv_6 = Conv2D(96, (3,3), strides=(1, 1), padding='same', activation='relu', name='conv_6')(pool_5)\n",
        "    pool_6 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_6')(conv_6)\n",
        "    \n",
        "    flatten = Flatten(name='flatten')(pool_6)\n",
        "    \n",
        "    fc_1 = Dense(120, activation='relu', name='fc_1')(flatten)\n",
        "    fc_2 = Dense(80, activation='relu', name='fc_2')(fc_1)\n",
        "    \n",
        "    output = Dense(10, activation='softmax', name='output')(fc_2)\n",
        "    model = Model(input, output)\n",
        "    \n",
        "    plot_model(model, 'CNN_2.png')\n",
        "    \n",
        "    model.compile(\n",
        "      optimizer=Adam(learning_rate=0.001),\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "    )\n",
        "\n",
        "    \n",
        "    hist = model.fit(x_train, y_train , epochs=200,\n",
        "                     batch_size=256,\n",
        "                     validation_data=(x_test, y_test))\n",
        "    \n",
        "    history_model(hist.history)\n",
        "\n",
        "conv_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "50000/50000 [==============================] - 3s 59us/sample - loss: 1.8290 - accuracy: 0.2983 - val_loss: 1.5254 - val_accuracy: 0.4186\n",
            "Epoch 2/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 1.4158 - accuracy: 0.4695 - val_loss: 1.2635 - val_accuracy: 0.5310\n",
            "Epoch 3/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 1.2054 - accuracy: 0.5600 - val_loss: 1.1382 - val_accuracy: 0.5893\n",
            "Epoch 4/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 1.0590 - accuracy: 0.6150 - val_loss: 1.0583 - val_accuracy: 0.6188\n",
            "Epoch 5/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.9412 - accuracy: 0.6605 - val_loss: 0.9825 - val_accuracy: 0.6499\n",
            "Epoch 6/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8480 - accuracy: 0.6975 - val_loss: 0.8870 - val_accuracy: 0.6897\n",
            "Epoch 7/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.7722 - accuracy: 0.7264 - val_loss: 0.8419 - val_accuracy: 0.7068\n",
            "Epoch 8/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.7194 - accuracy: 0.7449 - val_loss: 0.8558 - val_accuracy: 0.7019\n",
            "Epoch 9/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.6522 - accuracy: 0.7700 - val_loss: 0.8363 - val_accuracy: 0.7121\n",
            "Epoch 10/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.5835 - accuracy: 0.7927 - val_loss: 0.7813 - val_accuracy: 0.7338\n",
            "Epoch 11/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.5309 - accuracy: 0.8127 - val_loss: 0.8267 - val_accuracy: 0.7252\n",
            "Epoch 12/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.4741 - accuracy: 0.8335 - val_loss: 0.8762 - val_accuracy: 0.7259\n",
            "Epoch 13/200\n",
            "50000/50000 [==============================] - 2s 46us/sample - loss: 0.4328 - accuracy: 0.8476 - val_loss: 0.8265 - val_accuracy: 0.7398\n",
            "Epoch 14/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3928 - accuracy: 0.8608 - val_loss: 0.8390 - val_accuracy: 0.7429\n",
            "Epoch 15/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.3553 - accuracy: 0.8753 - val_loss: 0.8816 - val_accuracy: 0.7451\n",
            "Epoch 16/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.3108 - accuracy: 0.8920 - val_loss: 0.9817 - val_accuracy: 0.7233\n",
            "Epoch 17/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.2893 - accuracy: 0.8987 - val_loss: 0.9332 - val_accuracy: 0.7444\n",
            "Epoch 18/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.2419 - accuracy: 0.9160 - val_loss: 1.0340 - val_accuracy: 0.7369\n",
            "Epoch 19/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.2225 - accuracy: 0.9230 - val_loss: 1.0685 - val_accuracy: 0.7336\n",
            "Epoch 20/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.2155 - accuracy: 0.9232 - val_loss: 1.0503 - val_accuracy: 0.7458\n",
            "Epoch 21/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.1804 - accuracy: 0.9375 - val_loss: 1.2291 - val_accuracy: 0.7092\n",
            "Epoch 22/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.1608 - accuracy: 0.9440 - val_loss: 1.2726 - val_accuracy: 0.7185\n",
            "Epoch 23/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.1693 - accuracy: 0.9401 - val_loss: 1.1574 - val_accuracy: 0.7448\n",
            "Epoch 24/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.1413 - accuracy: 0.9507 - val_loss: 1.2062 - val_accuracy: 0.7338\n",
            "Epoch 25/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.1288 - accuracy: 0.9543 - val_loss: 1.3453 - val_accuracy: 0.7303\n",
            "Epoch 26/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.1217 - accuracy: 0.9567 - val_loss: 1.3896 - val_accuracy: 0.7285\n",
            "Epoch 27/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.1193 - accuracy: 0.9582 - val_loss: 1.3537 - val_accuracy: 0.7398\n",
            "Epoch 28/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0993 - accuracy: 0.9648 - val_loss: 1.4274 - val_accuracy: 0.7335\n",
            "Epoch 29/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.1084 - accuracy: 0.9623 - val_loss: 1.4831 - val_accuracy: 0.7290\n",
            "Epoch 30/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0951 - accuracy: 0.9669 - val_loss: 1.4987 - val_accuracy: 0.7363\n",
            "Epoch 31/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.1078 - accuracy: 0.9625 - val_loss: 1.4143 - val_accuracy: 0.7334\n",
            "Epoch 32/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0866 - accuracy: 0.9697 - val_loss: 1.5467 - val_accuracy: 0.7226\n",
            "Epoch 33/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0796 - accuracy: 0.9721 - val_loss: 1.6403 - val_accuracy: 0.7221\n",
            "Epoch 34/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0917 - accuracy: 0.9673 - val_loss: 1.5141 - val_accuracy: 0.7329\n",
            "Epoch 35/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0811 - accuracy: 0.9713 - val_loss: 1.5582 - val_accuracy: 0.7187\n",
            "Epoch 36/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0724 - accuracy: 0.9747 - val_loss: 1.6000 - val_accuracy: 0.7319\n",
            "Epoch 37/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0789 - accuracy: 0.9728 - val_loss: 1.6348 - val_accuracy: 0.7238\n",
            "Epoch 38/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0634 - accuracy: 0.9780 - val_loss: 1.7590 - val_accuracy: 0.7361\n",
            "Epoch 39/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0713 - accuracy: 0.9753 - val_loss: 1.6277 - val_accuracy: 0.7251\n",
            "Epoch 40/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0630 - accuracy: 0.9784 - val_loss: 1.6994 - val_accuracy: 0.7320\n",
            "Epoch 41/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0827 - accuracy: 0.9710 - val_loss: 1.5003 - val_accuracy: 0.7336\n",
            "Epoch 42/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0726 - accuracy: 0.9747 - val_loss: 1.5265 - val_accuracy: 0.7343\n",
            "Epoch 43/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0537 - accuracy: 0.9812 - val_loss: 1.7474 - val_accuracy: 0.7329\n",
            "Epoch 44/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0582 - accuracy: 0.9792 - val_loss: 1.6465 - val_accuracy: 0.7342\n",
            "Epoch 45/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0643 - accuracy: 0.9786 - val_loss: 1.6180 - val_accuracy: 0.7195\n",
            "Epoch 46/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0562 - accuracy: 0.9809 - val_loss: 1.7189 - val_accuracy: 0.7249\n",
            "Epoch 47/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0654 - accuracy: 0.9774 - val_loss: 1.6350 - val_accuracy: 0.7243\n",
            "Epoch 48/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0575 - accuracy: 0.9795 - val_loss: 1.7711 - val_accuracy: 0.7251\n",
            "Epoch 49/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0619 - accuracy: 0.9784 - val_loss: 1.6641 - val_accuracy: 0.7379\n",
            "Epoch 50/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0567 - accuracy: 0.9806 - val_loss: 1.8088 - val_accuracy: 0.7298\n",
            "Epoch 51/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0511 - accuracy: 0.9831 - val_loss: 1.8239 - val_accuracy: 0.7308\n",
            "Epoch 52/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0588 - accuracy: 0.9802 - val_loss: 1.7098 - val_accuracy: 0.7290\n",
            "Epoch 53/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0531 - accuracy: 0.9830 - val_loss: 1.6630 - val_accuracy: 0.7289\n",
            "Epoch 54/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0559 - accuracy: 0.9814 - val_loss: 1.5398 - val_accuracy: 0.7271\n",
            "Epoch 55/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0456 - accuracy: 0.9851 - val_loss: 1.8605 - val_accuracy: 0.7365\n",
            "Epoch 56/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0475 - accuracy: 0.9840 - val_loss: 1.7390 - val_accuracy: 0.7329\n",
            "Epoch 57/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0510 - accuracy: 0.9823 - val_loss: 1.7781 - val_accuracy: 0.7269\n",
            "Epoch 58/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0469 - accuracy: 0.9838 - val_loss: 1.6900 - val_accuracy: 0.7350\n",
            "Epoch 59/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0478 - accuracy: 0.9831 - val_loss: 1.8413 - val_accuracy: 0.7350\n",
            "Epoch 60/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0545 - accuracy: 0.9808 - val_loss: 1.6605 - val_accuracy: 0.7344\n",
            "Epoch 61/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0345 - accuracy: 0.9880 - val_loss: 1.7941 - val_accuracy: 0.7375\n",
            "Epoch 62/200\n",
            "50000/50000 [==============================] - 2s 46us/sample - loss: 0.0539 - accuracy: 0.9818 - val_loss: 1.7959 - val_accuracy: 0.7369\n",
            "Epoch 63/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0473 - accuracy: 0.9838 - val_loss: 1.7360 - val_accuracy: 0.7355\n",
            "Epoch 64/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0372 - accuracy: 0.9878 - val_loss: 1.8583 - val_accuracy: 0.7336\n",
            "Epoch 65/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.0412 - accuracy: 0.9863 - val_loss: 1.9358 - val_accuracy: 0.7358\n",
            "Epoch 66/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0515 - accuracy: 0.9825 - val_loss: 1.6818 - val_accuracy: 0.7366\n",
            "Epoch 67/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0373 - accuracy: 0.9874 - val_loss: 1.8188 - val_accuracy: 0.7223\n",
            "Epoch 68/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0428 - accuracy: 0.9853 - val_loss: 1.6124 - val_accuracy: 0.7343\n",
            "Epoch 69/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0420 - accuracy: 0.9857 - val_loss: 1.8630 - val_accuracy: 0.7363\n",
            "Epoch 70/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0382 - accuracy: 0.9871 - val_loss: 1.8135 - val_accuracy: 0.7300\n",
            "Epoch 71/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0360 - accuracy: 0.9877 - val_loss: 1.9041 - val_accuracy: 0.7345\n",
            "Epoch 72/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0503 - accuracy: 0.9835 - val_loss: 1.7895 - val_accuracy: 0.7348\n",
            "Epoch 73/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0338 - accuracy: 0.9893 - val_loss: 1.7281 - val_accuracy: 0.7402\n",
            "Epoch 74/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0423 - accuracy: 0.9859 - val_loss: 1.7178 - val_accuracy: 0.7380\n",
            "Epoch 75/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0384 - accuracy: 0.9867 - val_loss: 1.7663 - val_accuracy: 0.7334\n",
            "Epoch 76/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0384 - accuracy: 0.9869 - val_loss: 1.7959 - val_accuracy: 0.7412\n",
            "Epoch 77/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0436 - accuracy: 0.9853 - val_loss: 1.7559 - val_accuracy: 0.7327\n",
            "Epoch 78/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0342 - accuracy: 0.9882 - val_loss: 1.8781 - val_accuracy: 0.7362\n",
            "Epoch 79/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0435 - accuracy: 0.9858 - val_loss: 1.7077 - val_accuracy: 0.7430\n",
            "Epoch 80/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0352 - accuracy: 0.9879 - val_loss: 1.8237 - val_accuracy: 0.7347\n",
            "Epoch 81/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0343 - accuracy: 0.9886 - val_loss: 1.8445 - val_accuracy: 0.7394\n",
            "Epoch 82/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0384 - accuracy: 0.9868 - val_loss: 1.8368 - val_accuracy: 0.7405\n",
            "Epoch 83/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0372 - accuracy: 0.9878 - val_loss: 1.8693 - val_accuracy: 0.7404\n",
            "Epoch 84/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0333 - accuracy: 0.9890 - val_loss: 1.8310 - val_accuracy: 0.7341\n",
            "Epoch 85/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0280 - accuracy: 0.9902 - val_loss: 2.0457 - val_accuracy: 0.7365\n",
            "Epoch 86/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0392 - accuracy: 0.9865 - val_loss: 1.8180 - val_accuracy: 0.7325\n",
            "Epoch 87/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0397 - accuracy: 0.9871 - val_loss: 1.9166 - val_accuracy: 0.7329\n",
            "Epoch 88/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0289 - accuracy: 0.9904 - val_loss: 1.9454 - val_accuracy: 0.7407\n",
            "Epoch 89/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0217 - accuracy: 0.9931 - val_loss: 1.9454 - val_accuracy: 0.7400\n",
            "Epoch 90/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.0391 - accuracy: 0.9864 - val_loss: 1.7467 - val_accuracy: 0.7394\n",
            "Epoch 91/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0322 - accuracy: 0.9890 - val_loss: 1.8412 - val_accuracy: 0.7319\n",
            "Epoch 92/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.0424 - accuracy: 0.9853 - val_loss: 1.7445 - val_accuracy: 0.7260\n",
            "Epoch 93/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0297 - accuracy: 0.9899 - val_loss: 1.8980 - val_accuracy: 0.7371\n",
            "Epoch 94/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0353 - accuracy: 0.9879 - val_loss: 1.7955 - val_accuracy: 0.7379\n",
            "Epoch 95/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0398 - accuracy: 0.9870 - val_loss: 1.8257 - val_accuracy: 0.7336\n",
            "Epoch 96/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0198 - accuracy: 0.9937 - val_loss: 1.9454 - val_accuracy: 0.7408\n",
            "Epoch 97/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0207 - accuracy: 0.9932 - val_loss: 2.0874 - val_accuracy: 0.7382\n",
            "Epoch 98/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0416 - accuracy: 0.9862 - val_loss: 1.8342 - val_accuracy: 0.7457\n",
            "Epoch 99/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0309 - accuracy: 0.9896 - val_loss: 1.7945 - val_accuracy: 0.7412\n",
            "Epoch 100/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0231 - accuracy: 0.9919 - val_loss: 2.0573 - val_accuracy: 0.7444\n",
            "Epoch 101/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0300 - accuracy: 0.9899 - val_loss: 1.9638 - val_accuracy: 0.7333\n",
            "Epoch 102/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0214 - accuracy: 0.9930 - val_loss: 2.0491 - val_accuracy: 0.7314\n",
            "Epoch 103/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0332 - accuracy: 0.9894 - val_loss: 1.8376 - val_accuracy: 0.7441\n",
            "Epoch 104/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0326 - accuracy: 0.9890 - val_loss: 1.8166 - val_accuracy: 0.7412\n",
            "Epoch 105/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0221 - accuracy: 0.9922 - val_loss: 2.0004 - val_accuracy: 0.7454\n",
            "Epoch 106/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0339 - accuracy: 0.9888 - val_loss: 1.9585 - val_accuracy: 0.7383\n",
            "Epoch 107/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0200 - accuracy: 0.9931 - val_loss: 2.0896 - val_accuracy: 0.7393\n",
            "Epoch 108/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0319 - accuracy: 0.9892 - val_loss: 1.9645 - val_accuracy: 0.7278\n",
            "Epoch 109/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0280 - accuracy: 0.9906 - val_loss: 2.0833 - val_accuracy: 0.7404\n",
            "Epoch 110/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0330 - accuracy: 0.9885 - val_loss: 1.8324 - val_accuracy: 0.7336\n",
            "Epoch 111/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.0257 - accuracy: 0.9914 - val_loss: 1.9053 - val_accuracy: 0.7348\n",
            "Epoch 112/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.0254 - accuracy: 0.9916 - val_loss: 1.8974 - val_accuracy: 0.7474\n",
            "Epoch 113/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.0267 - accuracy: 0.9913 - val_loss: 2.0710 - val_accuracy: 0.7378\n",
            "Epoch 114/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.0232 - accuracy: 0.9921 - val_loss: 2.1715 - val_accuracy: 0.7437\n",
            "Epoch 115/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0232 - accuracy: 0.9921 - val_loss: 2.1069 - val_accuracy: 0.7388\n",
            "Epoch 116/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0312 - accuracy: 0.9902 - val_loss: 1.9157 - val_accuracy: 0.7398\n",
            "Epoch 117/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0233 - accuracy: 0.9921 - val_loss: 2.1958 - val_accuracy: 0.7366\n",
            "Epoch 118/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.0212 - accuracy: 0.9927 - val_loss: 2.1568 - val_accuracy: 0.7326\n",
            "Epoch 119/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0338 - accuracy: 0.9885 - val_loss: 1.9198 - val_accuracy: 0.7361\n",
            "Epoch 120/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0235 - accuracy: 0.9926 - val_loss: 1.9964 - val_accuracy: 0.7354\n",
            "Epoch 121/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0271 - accuracy: 0.9911 - val_loss: 1.9636 - val_accuracy: 0.7397\n",
            "Epoch 122/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0229 - accuracy: 0.9923 - val_loss: 2.1155 - val_accuracy: 0.7432\n",
            "Epoch 123/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0296 - accuracy: 0.9901 - val_loss: 2.0854 - val_accuracy: 0.7404\n",
            "Epoch 124/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0234 - accuracy: 0.9925 - val_loss: 2.0576 - val_accuracy: 0.7321\n",
            "Epoch 125/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0238 - accuracy: 0.9926 - val_loss: 2.2461 - val_accuracy: 0.7390\n",
            "Epoch 126/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0268 - accuracy: 0.9912 - val_loss: 1.9648 - val_accuracy: 0.7346\n",
            "Epoch 127/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0205 - accuracy: 0.9933 - val_loss: 2.0281 - val_accuracy: 0.7358\n",
            "Epoch 128/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0229 - accuracy: 0.9926 - val_loss: 2.0098 - val_accuracy: 0.7416\n",
            "Epoch 129/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0236 - accuracy: 0.9925 - val_loss: 2.1134 - val_accuracy: 0.7351\n",
            "Epoch 130/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0253 - accuracy: 0.9910 - val_loss: 1.9096 - val_accuracy: 0.7405\n",
            "Epoch 131/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0163 - accuracy: 0.9946 - val_loss: 2.1033 - val_accuracy: 0.7409\n",
            "Epoch 132/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0175 - accuracy: 0.9943 - val_loss: 2.1120 - val_accuracy: 0.7420\n",
            "Epoch 133/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0197 - accuracy: 0.9930 - val_loss: 2.2523 - val_accuracy: 0.7309\n",
            "Epoch 134/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0261 - accuracy: 0.9913 - val_loss: 2.1359 - val_accuracy: 0.7284\n",
            "Epoch 135/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0303 - accuracy: 0.9901 - val_loss: 2.0647 - val_accuracy: 0.7374\n",
            "Epoch 136/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.0248 - accuracy: 0.9919 - val_loss: 2.0439 - val_accuracy: 0.7350\n",
            "Epoch 137/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.0099 - accuracy: 0.9966 - val_loss: 2.3325 - val_accuracy: 0.7383\n",
            "Epoch 138/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0242 - accuracy: 0.9923 - val_loss: 2.1415 - val_accuracy: 0.7347\n",
            "Epoch 139/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0194 - accuracy: 0.9936 - val_loss: 2.2754 - val_accuracy: 0.7210\n",
            "Epoch 140/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0269 - accuracy: 0.9912 - val_loss: 1.9501 - val_accuracy: 0.7351\n",
            "Epoch 141/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.0216 - accuracy: 0.9927 - val_loss: 2.0023 - val_accuracy: 0.7349\n",
            "Epoch 142/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0246 - accuracy: 0.9919 - val_loss: 1.9934 - val_accuracy: 0.7456\n",
            "Epoch 143/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0152 - accuracy: 0.9947 - val_loss: 2.1472 - val_accuracy: 0.7338\n",
            "Epoch 144/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0197 - accuracy: 0.9938 - val_loss: 2.3177 - val_accuracy: 0.7362\n",
            "Epoch 145/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0285 - accuracy: 0.9912 - val_loss: 1.9362 - val_accuracy: 0.7348\n",
            "Epoch 146/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0252 - accuracy: 0.9918 - val_loss: 2.0539 - val_accuracy: 0.7380\n",
            "Epoch 147/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0219 - accuracy: 0.9929 - val_loss: 2.0733 - val_accuracy: 0.7338\n",
            "Epoch 148/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0230 - accuracy: 0.9921 - val_loss: 2.0614 - val_accuracy: 0.7414\n",
            "Epoch 149/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0209 - accuracy: 0.9939 - val_loss: 1.9359 - val_accuracy: 0.7380\n",
            "Epoch 150/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0184 - accuracy: 0.9942 - val_loss: 2.1455 - val_accuracy: 0.7430\n",
            "Epoch 151/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0156 - accuracy: 0.9946 - val_loss: 2.1611 - val_accuracy: 0.7489\n",
            "Epoch 152/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0183 - accuracy: 0.9938 - val_loss: 2.1633 - val_accuracy: 0.7258\n",
            "Epoch 153/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0249 - accuracy: 0.9919 - val_loss: 2.1045 - val_accuracy: 0.7376\n",
            "Epoch 154/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0168 - accuracy: 0.9944 - val_loss: 2.1947 - val_accuracy: 0.7373\n",
            "Epoch 155/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0205 - accuracy: 0.9932 - val_loss: 2.3637 - val_accuracy: 0.7406\n",
            "Epoch 156/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0275 - accuracy: 0.9911 - val_loss: 1.8632 - val_accuracy: 0.7417\n",
            "Epoch 157/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0142 - accuracy: 0.9954 - val_loss: 2.2354 - val_accuracy: 0.7402\n",
            "Epoch 158/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0203 - accuracy: 0.9932 - val_loss: 2.2131 - val_accuracy: 0.7386\n",
            "Epoch 159/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0241 - accuracy: 0.9930 - val_loss: 1.9822 - val_accuracy: 0.7438\n",
            "Epoch 160/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0208 - accuracy: 0.9928 - val_loss: 2.1608 - val_accuracy: 0.7429\n",
            "Epoch 161/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0155 - accuracy: 0.9950 - val_loss: 2.1368 - val_accuracy: 0.7387\n",
            "Epoch 162/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0205 - accuracy: 0.9934 - val_loss: 2.0819 - val_accuracy: 0.7295\n",
            "Epoch 163/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0185 - accuracy: 0.9939 - val_loss: 2.1905 - val_accuracy: 0.7373\n",
            "Epoch 164/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0220 - accuracy: 0.9927 - val_loss: 2.0683 - val_accuracy: 0.7397\n",
            "Epoch 165/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0179 - accuracy: 0.9941 - val_loss: 2.2399 - val_accuracy: 0.7455\n",
            "Epoch 166/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0234 - accuracy: 0.9925 - val_loss: 2.1063 - val_accuracy: 0.7411\n",
            "Epoch 167/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.0162 - accuracy: 0.9949 - val_loss: 2.2943 - val_accuracy: 0.7435\n",
            "Epoch 168/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0124 - accuracy: 0.9958 - val_loss: 2.3633 - val_accuracy: 0.7424\n",
            "Epoch 169/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.0212 - accuracy: 0.9930 - val_loss: 2.3929 - val_accuracy: 0.7331\n",
            "Epoch 170/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0237 - accuracy: 0.9925 - val_loss: 2.1115 - val_accuracy: 0.7343\n",
            "Epoch 171/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0179 - accuracy: 0.9947 - val_loss: 2.1542 - val_accuracy: 0.7396\n",
            "Epoch 172/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0059 - accuracy: 0.9979 - val_loss: 2.8289 - val_accuracy: 0.7393\n",
            "Epoch 173/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0240 - accuracy: 0.9924 - val_loss: 2.3754 - val_accuracy: 0.7360\n",
            "Epoch 174/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0256 - accuracy: 0.9919 - val_loss: 2.0054 - val_accuracy: 0.7402\n",
            "Epoch 175/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0143 - accuracy: 0.9952 - val_loss: 2.3320 - val_accuracy: 0.7377\n",
            "Epoch 176/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0136 - accuracy: 0.9954 - val_loss: 2.2952 - val_accuracy: 0.7306\n",
            "Epoch 177/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0244 - accuracy: 0.9926 - val_loss: 2.2330 - val_accuracy: 0.7214\n",
            "Epoch 178/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0191 - accuracy: 0.9934 - val_loss: 2.3957 - val_accuracy: 0.7348\n",
            "Epoch 179/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0194 - accuracy: 0.9939 - val_loss: 2.3722 - val_accuracy: 0.7443\n",
            "Epoch 180/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0209 - accuracy: 0.9933 - val_loss: 2.2182 - val_accuracy: 0.7394\n",
            "Epoch 181/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0094 - accuracy: 0.9969 - val_loss: 2.5487 - val_accuracy: 0.7457\n",
            "Epoch 182/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0224 - accuracy: 0.9927 - val_loss: 2.2034 - val_accuracy: 0.7437\n",
            "Epoch 183/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0120 - accuracy: 0.9960 - val_loss: 2.3722 - val_accuracy: 0.7384\n",
            "Epoch 184/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0214 - accuracy: 0.9930 - val_loss: 2.0932 - val_accuracy: 0.7387\n",
            "Epoch 185/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0143 - accuracy: 0.9955 - val_loss: 2.3227 - val_accuracy: 0.7456\n",
            "Epoch 186/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0201 - accuracy: 0.9937 - val_loss: 2.1426 - val_accuracy: 0.7411\n",
            "Epoch 187/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0156 - accuracy: 0.9948 - val_loss: 2.3596 - val_accuracy: 0.7414\n",
            "Epoch 188/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0236 - accuracy: 0.9922 - val_loss: 2.3531 - val_accuracy: 0.7313\n",
            "Epoch 189/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0169 - accuracy: 0.9946 - val_loss: 2.1797 - val_accuracy: 0.7374\n",
            "Epoch 190/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0155 - accuracy: 0.9949 - val_loss: 2.2393 - val_accuracy: 0.7378\n",
            "Epoch 191/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0211 - accuracy: 0.9933 - val_loss: 2.1028 - val_accuracy: 0.7357\n",
            "Epoch 192/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0248 - accuracy: 0.9924 - val_loss: 2.1734 - val_accuracy: 0.7418\n",
            "Epoch 193/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0160 - accuracy: 0.9948 - val_loss: 2.2469 - val_accuracy: 0.7435\n",
            "Epoch 194/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0085 - accuracy: 0.9973 - val_loss: 2.7269 - val_accuracy: 0.7412\n",
            "Epoch 195/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0128 - accuracy: 0.9956 - val_loss: 2.9034 - val_accuracy: 0.7315\n",
            "Epoch 196/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0203 - accuracy: 0.9935 - val_loss: 2.3448 - val_accuracy: 0.7376\n",
            "Epoch 197/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0117 - accuracy: 0.9964 - val_loss: 2.4820 - val_accuracy: 0.7263\n",
            "Epoch 198/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0195 - accuracy: 0.9943 - val_loss: 2.2391 - val_accuracy: 0.7333\n",
            "Epoch 199/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0106 - accuracy: 0.9968 - val_loss: 2.5850 - val_accuracy: 0.7368\n",
            "Epoch 200/200\n",
            "50000/50000 [==============================] - 2s 47us/sample - loss: 0.0211 - accuracy: 0.9929 - val_loss: 2.1190 - val_accuracy: 0.7391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKBhjjIn5f9p6M/ZmLDrPAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMxTE-Om08uF",
        "colab_type": "text"
      },
      "source": [
        "### Adding Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nthIr1wF4Z_3",
        "colab_type": "text"
      },
      "source": [
        "#### dropout = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pbo5PEZTzR0-",
        "colab_type": "code",
        "outputId": "0f941b7c-0945-46ad-b066-83dd65f5e9fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.layers import Input, Add, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.activations import relu, softmax\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "\n",
        "def conv_model(dropout_rate = 0.0, epochs= epochs):\n",
        "    \n",
        "    dropout_rate = dropout_rate\n",
        "    \n",
        "    input = Input((32, 32, 3), name='input')\n",
        "    \n",
        "    conv_1 = Conv2D(64, (3,3), strides=(1, 1), padding='same', activation='relu', name='conv_1')(input)\n",
        "    pool_1 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_1')(conv_1)\n",
        "    dropout_1 = Dropout(dropout_rate, name='dropout_1')(pool_1)\n",
        "    \n",
        "    conv_2 = Conv2D(64, (3,3), strides=(1, 1), padding='same', activation='relu', name='conv_2')(dropout_1)\n",
        "    pool_2 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_2')(conv_2)\n",
        "    dropout_2 = Dropout(dropout_rate, name='dropout_2')(pool_2)\n",
        "\n",
        "    conv_3 = Conv2D(96, (3,3), strides=(1, 1), padding='same', activation='relu', name='conv_3')(dropout_2)\n",
        "    pool_3 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_3')(conv_3)\n",
        "    dropout_3 = Dropout(dropout_rate, name='dropout_3')(pool_3)\n",
        "\n",
        "    conv_4 = Conv2D(96, (3,3), strides=(1, 1), padding='same', activation='relu', name='conv_4')(dropout_3)\n",
        "    pool_4 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_4')(conv_4)\n",
        "    dropout_4 = Dropout(dropout_rate, name='dropout_4')(pool_4)\n",
        "\n",
        "    conv_5 = Conv2D(96, (3,3), strides=(1, 1), padding='same', activation='relu', name='conv_5')(dropout_4)\n",
        "    pool_5 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_5')(conv_5)\n",
        "    dropout_5 = Dropout(dropout_rate, name='dropout_5')(pool_5)\n",
        "    \n",
        "    flatten = Flatten(name='flatten')(dropout_5)\n",
        "    \n",
        "    fc_1 = Dense(120, activation='relu', name='fc_1')(flatten)\n",
        "    dropout_6 = Dropout(dropout_rate, name='dropout_6')(fc_1)\n",
        "    fc_2 = Dense(80, activation='relu', name='fc_2')(dropout_6)\n",
        "    dropout_7 = Dropout(dropout_rate, name='dropout_7')(fc_2)\n",
        "    \n",
        "    output = Dense(10, activation='softmax', name='output')(dropout_7)\n",
        "    model = Model(input, output)\n",
        "    \n",
        "    plot_model(model, 'CNN_2.png')\n",
        "    \n",
        "    model.compile(\n",
        "      optimizer=Adam(learning_rate=0.001),\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "    )\n",
        "\n",
        "    \n",
        "    hist = model.fit(x_train, y_train , epochs=epochs,\n",
        "                     batch_size=256,\n",
        "                     validation_data=(x_test, y_test))\n",
        "    \n",
        "    history_model(hist.history)\n",
        "\n",
        "conv_model(0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "50000/50000 [==============================] - 3s 68us/sample - loss: 2.0030 - accuracy: 0.2295 - val_loss: 1.6973 - val_accuracy: 0.3715\n",
            "Epoch 2/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5791 - accuracy: 0.4094 - val_loss: 1.4270 - val_accuracy: 0.4752\n",
            "Epoch 3/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3609 - accuracy: 0.5021 - val_loss: 1.1723 - val_accuracy: 0.5843\n",
            "Epoch 4/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.2146 - accuracy: 0.5641 - val_loss: 1.0608 - val_accuracy: 0.6183\n",
            "Epoch 5/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.1262 - accuracy: 0.5969 - val_loss: 0.9675 - val_accuracy: 0.6597\n",
            "Epoch 6/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.0650 - accuracy: 0.6228 - val_loss: 0.9616 - val_accuracy: 0.6663\n",
            "Epoch 7/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.0028 - accuracy: 0.6498 - val_loss: 0.9572 - val_accuracy: 0.6569\n",
            "Epoch 8/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.9478 - accuracy: 0.6679 - val_loss: 0.8298 - val_accuracy: 0.7130\n",
            "Epoch 9/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.9213 - accuracy: 0.6785 - val_loss: 0.8196 - val_accuracy: 0.7189\n",
            "Epoch 10/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.8889 - accuracy: 0.6915 - val_loss: 0.7783 - val_accuracy: 0.7304\n",
            "Epoch 11/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.8557 - accuracy: 0.7035 - val_loss: 0.8191 - val_accuracy: 0.7159\n",
            "Epoch 12/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.8242 - accuracy: 0.7147 - val_loss: 0.7473 - val_accuracy: 0.7393\n",
            "Epoch 13/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.8013 - accuracy: 0.7230 - val_loss: 0.7310 - val_accuracy: 0.7480\n",
            "Epoch 14/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7827 - accuracy: 0.7292 - val_loss: 0.7528 - val_accuracy: 0.7405\n",
            "Epoch 15/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.7606 - accuracy: 0.7404 - val_loss: 0.7137 - val_accuracy: 0.7550\n",
            "Epoch 16/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7489 - accuracy: 0.7403 - val_loss: 0.7209 - val_accuracy: 0.7551\n",
            "Epoch 17/200\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 0.7299 - accuracy: 0.7502 - val_loss: 0.7003 - val_accuracy: 0.7584\n",
            "Epoch 18/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7178 - accuracy: 0.7537 - val_loss: 0.6767 - val_accuracy: 0.7674\n",
            "Epoch 19/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7029 - accuracy: 0.7597 - val_loss: 0.6894 - val_accuracy: 0.7656\n",
            "Epoch 20/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6842 - accuracy: 0.7643 - val_loss: 0.6679 - val_accuracy: 0.7670\n",
            "Epoch 21/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6895 - accuracy: 0.7634 - val_loss: 0.7032 - val_accuracy: 0.7573\n",
            "Epoch 22/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6715 - accuracy: 0.7690 - val_loss: 0.6721 - val_accuracy: 0.7674\n",
            "Epoch 23/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6584 - accuracy: 0.7742 - val_loss: 0.6541 - val_accuracy: 0.7716\n",
            "Epoch 24/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6516 - accuracy: 0.7756 - val_loss: 0.6352 - val_accuracy: 0.7786\n",
            "Epoch 25/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.6334 - accuracy: 0.7841 - val_loss: 0.6823 - val_accuracy: 0.7653\n",
            "Epoch 26/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6290 - accuracy: 0.7853 - val_loss: 0.6560 - val_accuracy: 0.7735\n",
            "Epoch 27/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.6184 - accuracy: 0.7885 - val_loss: 0.6478 - val_accuracy: 0.7793\n",
            "Epoch 28/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.6139 - accuracy: 0.7917 - val_loss: 0.6455 - val_accuracy: 0.7807\n",
            "Epoch 29/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.5993 - accuracy: 0.7944 - val_loss: 0.6339 - val_accuracy: 0.7820\n",
            "Epoch 30/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5971 - accuracy: 0.7959 - val_loss: 0.6272 - val_accuracy: 0.7880\n",
            "Epoch 31/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5872 - accuracy: 0.7992 - val_loss: 0.6280 - val_accuracy: 0.7859\n",
            "Epoch 32/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5891 - accuracy: 0.7992 - val_loss: 0.6173 - val_accuracy: 0.7882\n",
            "Epoch 33/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5841 - accuracy: 0.7967 - val_loss: 0.6151 - val_accuracy: 0.7929\n",
            "Epoch 34/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5768 - accuracy: 0.8037 - val_loss: 0.6104 - val_accuracy: 0.7906\n",
            "Epoch 35/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5717 - accuracy: 0.8023 - val_loss: 0.6071 - val_accuracy: 0.7926\n",
            "Epoch 36/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.5645 - accuracy: 0.8065 - val_loss: 0.6251 - val_accuracy: 0.7877\n",
            "Epoch 37/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5495 - accuracy: 0.8130 - val_loss: 0.6532 - val_accuracy: 0.7817\n",
            "Epoch 38/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5523 - accuracy: 0.8103 - val_loss: 0.6099 - val_accuracy: 0.7939\n",
            "Epoch 39/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5505 - accuracy: 0.8113 - val_loss: 0.6073 - val_accuracy: 0.7972\n",
            "Epoch 40/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5461 - accuracy: 0.8131 - val_loss: 0.5911 - val_accuracy: 0.8002\n",
            "Epoch 41/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5419 - accuracy: 0.8161 - val_loss: 0.6050 - val_accuracy: 0.7972\n",
            "Epoch 42/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.5379 - accuracy: 0.8167 - val_loss: 0.5930 - val_accuracy: 0.7977\n",
            "Epoch 43/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5273 - accuracy: 0.8176 - val_loss: 0.5946 - val_accuracy: 0.8013\n",
            "Epoch 44/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5270 - accuracy: 0.8205 - val_loss: 0.5814 - val_accuracy: 0.8021\n",
            "Epoch 45/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5209 - accuracy: 0.8225 - val_loss: 0.6056 - val_accuracy: 0.7948\n",
            "Epoch 46/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.5191 - accuracy: 0.8217 - val_loss: 0.5874 - val_accuracy: 0.8043\n",
            "Epoch 47/200\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 0.5068 - accuracy: 0.8257 - val_loss: 0.5788 - val_accuracy: 0.8051\n",
            "Epoch 48/200\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 0.5168 - accuracy: 0.8228 - val_loss: 0.6257 - val_accuracy: 0.7900\n",
            "Epoch 49/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.5145 - accuracy: 0.8226 - val_loss: 0.5811 - val_accuracy: 0.8043\n",
            "Epoch 50/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.5062 - accuracy: 0.8268 - val_loss: 0.5822 - val_accuracy: 0.8076\n",
            "Epoch 51/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5076 - accuracy: 0.8271 - val_loss: 0.6253 - val_accuracy: 0.7950\n",
            "Epoch 52/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4959 - accuracy: 0.8302 - val_loss: 0.5905 - val_accuracy: 0.8012\n",
            "Epoch 53/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4968 - accuracy: 0.8299 - val_loss: 0.6025 - val_accuracy: 0.8039\n",
            "Epoch 54/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4970 - accuracy: 0.8286 - val_loss: 0.6165 - val_accuracy: 0.7950\n",
            "Epoch 55/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4940 - accuracy: 0.8307 - val_loss: 0.5882 - val_accuracy: 0.8040\n",
            "Epoch 56/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4902 - accuracy: 0.8310 - val_loss: 0.5802 - val_accuracy: 0.8076\n",
            "Epoch 57/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4825 - accuracy: 0.8352 - val_loss: 0.6201 - val_accuracy: 0.7976\n",
            "Epoch 58/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4817 - accuracy: 0.8325 - val_loss: 0.5792 - val_accuracy: 0.8100\n",
            "Epoch 59/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4774 - accuracy: 0.8365 - val_loss: 0.5716 - val_accuracy: 0.8116\n",
            "Epoch 60/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4811 - accuracy: 0.8353 - val_loss: 0.5802 - val_accuracy: 0.8063\n",
            "Epoch 61/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4803 - accuracy: 0.8375 - val_loss: 0.5768 - val_accuracy: 0.8112\n",
            "Epoch 62/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.4681 - accuracy: 0.8393 - val_loss: 0.5823 - val_accuracy: 0.8079\n",
            "Epoch 63/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.4713 - accuracy: 0.8370 - val_loss: 0.5739 - val_accuracy: 0.8098\n",
            "Epoch 64/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4642 - accuracy: 0.8402 - val_loss: 0.5824 - val_accuracy: 0.8080\n",
            "Epoch 65/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4708 - accuracy: 0.8377 - val_loss: 0.5811 - val_accuracy: 0.8079\n",
            "Epoch 66/200\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4553 - accuracy: 0.8428 - val_loss: 0.5857 - val_accuracy: 0.8095\n",
            "Epoch 67/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4648 - accuracy: 0.8407 - val_loss: 0.5810 - val_accuracy: 0.8058\n",
            "Epoch 68/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4669 - accuracy: 0.8396 - val_loss: 0.5673 - val_accuracy: 0.8168\n",
            "Epoch 69/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4564 - accuracy: 0.8436 - val_loss: 0.5728 - val_accuracy: 0.8106\n",
            "Epoch 70/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4619 - accuracy: 0.8416 - val_loss: 0.5844 - val_accuracy: 0.8032\n",
            "Epoch 71/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4480 - accuracy: 0.8461 - val_loss: 0.5872 - val_accuracy: 0.8050\n",
            "Epoch 72/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.4486 - accuracy: 0.8453 - val_loss: 0.5672 - val_accuracy: 0.8144\n",
            "Epoch 73/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4479 - accuracy: 0.8472 - val_loss: 0.6030 - val_accuracy: 0.8068\n",
            "Epoch 74/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4486 - accuracy: 0.8469 - val_loss: 0.5841 - val_accuracy: 0.8091\n",
            "Epoch 75/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.4447 - accuracy: 0.8469 - val_loss: 0.5569 - val_accuracy: 0.8165\n",
            "Epoch 76/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4400 - accuracy: 0.8488 - val_loss: 0.5788 - val_accuracy: 0.8106\n",
            "Epoch 77/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4393 - accuracy: 0.8499 - val_loss: 0.5625 - val_accuracy: 0.8146\n",
            "Epoch 78/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.4387 - accuracy: 0.8492 - val_loss: 0.5655 - val_accuracy: 0.8175\n",
            "Epoch 79/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4322 - accuracy: 0.8524 - val_loss: 0.5683 - val_accuracy: 0.8128\n",
            "Epoch 80/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4388 - accuracy: 0.8487 - val_loss: 0.5536 - val_accuracy: 0.8147\n",
            "Epoch 81/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4337 - accuracy: 0.8513 - val_loss: 0.5867 - val_accuracy: 0.8122\n",
            "Epoch 82/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4323 - accuracy: 0.8523 - val_loss: 0.5535 - val_accuracy: 0.8200\n",
            "Epoch 83/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4216 - accuracy: 0.8553 - val_loss: 0.5645 - val_accuracy: 0.8147\n",
            "Epoch 84/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4312 - accuracy: 0.8521 - val_loss: 0.5785 - val_accuracy: 0.8133\n",
            "Epoch 85/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4220 - accuracy: 0.8550 - val_loss: 0.5667 - val_accuracy: 0.8188\n",
            "Epoch 86/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4264 - accuracy: 0.8540 - val_loss: 0.5763 - val_accuracy: 0.8155\n",
            "Epoch 87/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4313 - accuracy: 0.8518 - val_loss: 0.5808 - val_accuracy: 0.8116\n",
            "Epoch 88/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4229 - accuracy: 0.8560 - val_loss: 0.5642 - val_accuracy: 0.8156\n",
            "Epoch 89/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4307 - accuracy: 0.8525 - val_loss: 0.5619 - val_accuracy: 0.8177\n",
            "Epoch 90/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4207 - accuracy: 0.8561 - val_loss: 0.5895 - val_accuracy: 0.8124\n",
            "Epoch 91/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4153 - accuracy: 0.8573 - val_loss: 0.5491 - val_accuracy: 0.8228\n",
            "Epoch 92/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.4141 - accuracy: 0.8575 - val_loss: 0.5683 - val_accuracy: 0.8185\n",
            "Epoch 93/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4125 - accuracy: 0.8575 - val_loss: 0.5879 - val_accuracy: 0.8076\n",
            "Epoch 94/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4161 - accuracy: 0.8579 - val_loss: 0.5555 - val_accuracy: 0.8214\n",
            "Epoch 95/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.4133 - accuracy: 0.8597 - val_loss: 0.5607 - val_accuracy: 0.8165\n",
            "Epoch 96/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4155 - accuracy: 0.8574 - val_loss: 0.5821 - val_accuracy: 0.8147\n",
            "Epoch 97/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4147 - accuracy: 0.8567 - val_loss: 0.5791 - val_accuracy: 0.8130\n",
            "Epoch 98/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4111 - accuracy: 0.8602 - val_loss: 0.5691 - val_accuracy: 0.8178\n",
            "Epoch 99/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4009 - accuracy: 0.8633 - val_loss: 0.5691 - val_accuracy: 0.8187\n",
            "Epoch 100/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4056 - accuracy: 0.8612 - val_loss: 0.5734 - val_accuracy: 0.8120\n",
            "Epoch 101/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4146 - accuracy: 0.8590 - val_loss: 0.5561 - val_accuracy: 0.8213\n",
            "Epoch 102/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4026 - accuracy: 0.8614 - val_loss: 0.5685 - val_accuracy: 0.8181\n",
            "Epoch 103/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3974 - accuracy: 0.8636 - val_loss: 0.5561 - val_accuracy: 0.8245\n",
            "Epoch 104/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4072 - accuracy: 0.8608 - val_loss: 0.6013 - val_accuracy: 0.8099\n",
            "Epoch 105/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4002 - accuracy: 0.8612 - val_loss: 0.5607 - val_accuracy: 0.8211\n",
            "Epoch 106/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3973 - accuracy: 0.8652 - val_loss: 0.5720 - val_accuracy: 0.8189\n",
            "Epoch 107/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4000 - accuracy: 0.8627 - val_loss: 0.5597 - val_accuracy: 0.8209\n",
            "Epoch 108/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3909 - accuracy: 0.8655 - val_loss: 0.5841 - val_accuracy: 0.8193\n",
            "Epoch 109/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.4063 - accuracy: 0.8607 - val_loss: 0.5712 - val_accuracy: 0.8179\n",
            "Epoch 110/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3891 - accuracy: 0.8665 - val_loss: 0.5656 - val_accuracy: 0.8246\n",
            "Epoch 111/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3918 - accuracy: 0.8652 - val_loss: 0.5727 - val_accuracy: 0.8162\n",
            "Epoch 112/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3937 - accuracy: 0.8642 - val_loss: 0.6197 - val_accuracy: 0.8049\n",
            "Epoch 113/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.4014 - accuracy: 0.8624 - val_loss: 0.5595 - val_accuracy: 0.8218\n",
            "Epoch 114/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3870 - accuracy: 0.8663 - val_loss: 0.5713 - val_accuracy: 0.8182\n",
            "Epoch 115/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.3941 - accuracy: 0.8641 - val_loss: 0.5639 - val_accuracy: 0.8193\n",
            "Epoch 116/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3910 - accuracy: 0.8642 - val_loss: 0.5591 - val_accuracy: 0.8226\n",
            "Epoch 117/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3865 - accuracy: 0.8687 - val_loss: 0.5631 - val_accuracy: 0.8208\n",
            "Epoch 118/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3900 - accuracy: 0.8654 - val_loss: 0.5558 - val_accuracy: 0.8253\n",
            "Epoch 119/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3891 - accuracy: 0.8676 - val_loss: 0.5636 - val_accuracy: 0.8187\n",
            "Epoch 120/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3826 - accuracy: 0.8689 - val_loss: 0.5735 - val_accuracy: 0.8147\n",
            "Epoch 121/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3791 - accuracy: 0.8693 - val_loss: 0.5851 - val_accuracy: 0.8172\n",
            "Epoch 122/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3801 - accuracy: 0.8695 - val_loss: 0.5605 - val_accuracy: 0.8182\n",
            "Epoch 123/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3841 - accuracy: 0.8678 - val_loss: 0.5702 - val_accuracy: 0.8143\n",
            "Epoch 124/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3852 - accuracy: 0.8687 - val_loss: 0.5582 - val_accuracy: 0.8231\n",
            "Epoch 125/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3775 - accuracy: 0.8688 - val_loss: 0.5818 - val_accuracy: 0.8186\n",
            "Epoch 126/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3765 - accuracy: 0.8711 - val_loss: 0.5974 - val_accuracy: 0.8095\n",
            "Epoch 127/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3795 - accuracy: 0.8709 - val_loss: 0.5619 - val_accuracy: 0.8236\n",
            "Epoch 128/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3706 - accuracy: 0.8728 - val_loss: 0.5513 - val_accuracy: 0.8218\n",
            "Epoch 129/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3838 - accuracy: 0.8692 - val_loss: 0.5562 - val_accuracy: 0.8204\n",
            "Epoch 130/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3841 - accuracy: 0.8689 - val_loss: 0.5588 - val_accuracy: 0.8177\n",
            "Epoch 131/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3737 - accuracy: 0.8725 - val_loss: 0.5864 - val_accuracy: 0.8154\n",
            "Epoch 132/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3740 - accuracy: 0.8713 - val_loss: 0.5592 - val_accuracy: 0.8235\n",
            "Epoch 133/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3732 - accuracy: 0.8708 - val_loss: 0.5666 - val_accuracy: 0.8203\n",
            "Epoch 134/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3813 - accuracy: 0.8705 - val_loss: 0.5720 - val_accuracy: 0.8159\n",
            "Epoch 135/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3780 - accuracy: 0.8727 - val_loss: 0.5567 - val_accuracy: 0.8205\n",
            "Epoch 136/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3758 - accuracy: 0.8720 - val_loss: 0.5624 - val_accuracy: 0.8222\n",
            "Epoch 137/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3658 - accuracy: 0.8754 - val_loss: 0.5485 - val_accuracy: 0.8228\n",
            "Epoch 138/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3725 - accuracy: 0.8727 - val_loss: 0.5548 - val_accuracy: 0.8216\n",
            "Epoch 139/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3681 - accuracy: 0.8734 - val_loss: 0.5774 - val_accuracy: 0.8186\n",
            "Epoch 140/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.3766 - accuracy: 0.8717 - val_loss: 0.5620 - val_accuracy: 0.8233\n",
            "Epoch 141/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3656 - accuracy: 0.8755 - val_loss: 0.5659 - val_accuracy: 0.8204\n",
            "Epoch 142/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3648 - accuracy: 0.8744 - val_loss: 0.5734 - val_accuracy: 0.8186\n",
            "Epoch 143/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3688 - accuracy: 0.8743 - val_loss: 0.5834 - val_accuracy: 0.8163\n",
            "Epoch 144/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3657 - accuracy: 0.8748 - val_loss: 0.5620 - val_accuracy: 0.8257\n",
            "Epoch 145/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3576 - accuracy: 0.8783 - val_loss: 0.5559 - val_accuracy: 0.8268\n",
            "Epoch 146/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3583 - accuracy: 0.8778 - val_loss: 0.5737 - val_accuracy: 0.8249\n",
            "Epoch 147/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3607 - accuracy: 0.8760 - val_loss: 0.5604 - val_accuracy: 0.8230\n",
            "Epoch 148/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3687 - accuracy: 0.8745 - val_loss: 0.5769 - val_accuracy: 0.8170\n",
            "Epoch 149/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3628 - accuracy: 0.8753 - val_loss: 0.5623 - val_accuracy: 0.8204\n",
            "Epoch 150/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.3537 - accuracy: 0.8791 - val_loss: 0.5726 - val_accuracy: 0.8231\n",
            "Epoch 151/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3611 - accuracy: 0.8786 - val_loss: 0.5759 - val_accuracy: 0.8195\n",
            "Epoch 152/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3587 - accuracy: 0.8787 - val_loss: 0.5600 - val_accuracy: 0.8240\n",
            "Epoch 153/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3622 - accuracy: 0.8761 - val_loss: 0.5669 - val_accuracy: 0.8192\n",
            "Epoch 154/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3630 - accuracy: 0.8771 - val_loss: 0.5881 - val_accuracy: 0.8174\n",
            "Epoch 155/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3667 - accuracy: 0.8752 - val_loss: 0.5692 - val_accuracy: 0.8245\n",
            "Epoch 156/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3588 - accuracy: 0.8774 - val_loss: 0.5496 - val_accuracy: 0.8284\n",
            "Epoch 157/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3498 - accuracy: 0.8800 - val_loss: 0.5616 - val_accuracy: 0.8262\n",
            "Epoch 158/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3582 - accuracy: 0.8784 - val_loss: 0.5520 - val_accuracy: 0.8216\n",
            "Epoch 159/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3495 - accuracy: 0.8828 - val_loss: 0.5853 - val_accuracy: 0.8194\n",
            "Epoch 160/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3532 - accuracy: 0.8797 - val_loss: 0.5553 - val_accuracy: 0.8255\n",
            "Epoch 161/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3539 - accuracy: 0.8791 - val_loss: 0.5611 - val_accuracy: 0.8210\n",
            "Epoch 162/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3569 - accuracy: 0.8787 - val_loss: 0.5547 - val_accuracy: 0.8273\n",
            "Epoch 163/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3501 - accuracy: 0.8805 - val_loss: 0.5643 - val_accuracy: 0.8255\n",
            "Epoch 164/200\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 0.3507 - accuracy: 0.8800 - val_loss: 0.5552 - val_accuracy: 0.8208\n",
            "Epoch 165/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3526 - accuracy: 0.8793 - val_loss: 0.5628 - val_accuracy: 0.8247\n",
            "Epoch 166/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3542 - accuracy: 0.8797 - val_loss: 0.5633 - val_accuracy: 0.8228\n",
            "Epoch 167/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3506 - accuracy: 0.8794 - val_loss: 0.5659 - val_accuracy: 0.8223\n",
            "Epoch 168/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3534 - accuracy: 0.8789 - val_loss: 0.5719 - val_accuracy: 0.8197\n",
            "Epoch 169/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3602 - accuracy: 0.8776 - val_loss: 0.5661 - val_accuracy: 0.8191\n",
            "Epoch 170/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3544 - accuracy: 0.8802 - val_loss: 0.5644 - val_accuracy: 0.8262\n",
            "Epoch 171/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.3508 - accuracy: 0.8802 - val_loss: 0.5656 - val_accuracy: 0.8256\n",
            "Epoch 172/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.3433 - accuracy: 0.8850 - val_loss: 0.5508 - val_accuracy: 0.8311\n",
            "Epoch 173/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3401 - accuracy: 0.8846 - val_loss: 0.5727 - val_accuracy: 0.8240\n",
            "Epoch 174/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.3476 - accuracy: 0.8801 - val_loss: 0.5602 - val_accuracy: 0.8270\n",
            "Epoch 175/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.3461 - accuracy: 0.8817 - val_loss: 0.5580 - val_accuracy: 0.8232\n",
            "Epoch 176/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.3481 - accuracy: 0.8805 - val_loss: 0.5573 - val_accuracy: 0.8233\n",
            "Epoch 177/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.3477 - accuracy: 0.8813 - val_loss: 0.5532 - val_accuracy: 0.8277\n",
            "Epoch 178/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3498 - accuracy: 0.8814 - val_loss: 0.5725 - val_accuracy: 0.8239\n",
            "Epoch 179/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3432 - accuracy: 0.8836 - val_loss: 0.5671 - val_accuracy: 0.8256\n",
            "Epoch 180/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3516 - accuracy: 0.8805 - val_loss: 0.5516 - val_accuracy: 0.8238\n",
            "Epoch 181/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3380 - accuracy: 0.8840 - val_loss: 0.5772 - val_accuracy: 0.8211\n",
            "Epoch 182/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3441 - accuracy: 0.8821 - val_loss: 0.5695 - val_accuracy: 0.8214\n",
            "Epoch 183/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3401 - accuracy: 0.8831 - val_loss: 0.5582 - val_accuracy: 0.8252\n",
            "Epoch 184/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3345 - accuracy: 0.8855 - val_loss: 0.5597 - val_accuracy: 0.8268\n",
            "Epoch 185/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3442 - accuracy: 0.8810 - val_loss: 0.5668 - val_accuracy: 0.8220\n",
            "Epoch 186/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3400 - accuracy: 0.8837 - val_loss: 0.5578 - val_accuracy: 0.8267\n",
            "Epoch 187/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3396 - accuracy: 0.8841 - val_loss: 0.5594 - val_accuracy: 0.8220\n",
            "Epoch 188/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.3415 - accuracy: 0.8833 - val_loss: 0.5460 - val_accuracy: 0.8270\n",
            "Epoch 189/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.3425 - accuracy: 0.8824 - val_loss: 0.5583 - val_accuracy: 0.8235\n",
            "Epoch 190/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3331 - accuracy: 0.8872 - val_loss: 0.5589 - val_accuracy: 0.8289\n",
            "Epoch 191/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3337 - accuracy: 0.8861 - val_loss: 0.5683 - val_accuracy: 0.8248\n",
            "Epoch 192/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3444 - accuracy: 0.8834 - val_loss: 0.5595 - val_accuracy: 0.8280\n",
            "Epoch 193/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3402 - accuracy: 0.8830 - val_loss: 0.5703 - val_accuracy: 0.8244\n",
            "Epoch 194/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3424 - accuracy: 0.8838 - val_loss: 0.5609 - val_accuracy: 0.8284\n",
            "Epoch 195/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3394 - accuracy: 0.8854 - val_loss: 0.5736 - val_accuracy: 0.8194\n",
            "Epoch 196/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3411 - accuracy: 0.8841 - val_loss: 0.5573 - val_accuracy: 0.8252\n",
            "Epoch 197/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3333 - accuracy: 0.8876 - val_loss: 0.5405 - val_accuracy: 0.8279\n",
            "Epoch 198/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.3366 - accuracy: 0.8861 - val_loss: 0.5490 - val_accuracy: 0.8261\n",
            "Epoch 199/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3392 - accuracy: 0.8853 - val_loss: 0.5561 - val_accuracy: 0.8232\n",
            "Epoch 200/200\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 0.3314 - accuracy: 0.8881 - val_loss: 0.5503 - val_accuracy: 0.8288\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfPmaGyP4enc",
        "colab_type": "text"
      },
      "source": [
        "#### dropout = 0.6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Frzjz9y0f7Y",
        "colab_type": "code",
        "outputId": "3005efe4-2483-4583-baae-da56efa4cd02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "conv_model(0.6, 400)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/400\n",
            "50000/50000 [==============================] - 3s 64us/sample - loss: 2.2818 - accuracy: 0.1300 - val_loss: 2.2970 - val_accuracy: 0.1059\n",
            "Epoch 2/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 2.1180 - accuracy: 0.1794 - val_loss: 2.1005 - val_accuracy: 0.1701\n",
            "Epoch 3/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.9919 - accuracy: 0.1859 - val_loss: 2.0778 - val_accuracy: 0.1835\n",
            "Epoch 4/400\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 1.9519 - accuracy: 0.1976 - val_loss: 2.3297 - val_accuracy: 0.1362\n",
            "Epoch 5/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.9283 - accuracy: 0.2026 - val_loss: 2.1175 - val_accuracy: 0.1607\n",
            "Epoch 6/400\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 1.9095 - accuracy: 0.2058 - val_loss: 1.9994 - val_accuracy: 0.1821\n",
            "Epoch 7/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.8928 - accuracy: 0.2182 - val_loss: 2.2022 - val_accuracy: 0.1672\n",
            "Epoch 8/400\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 1.8569 - accuracy: 0.2509 - val_loss: 1.9171 - val_accuracy: 0.2405\n",
            "Epoch 9/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.8117 - accuracy: 0.2750 - val_loss: 1.9193 - val_accuracy: 0.2281\n",
            "Epoch 10/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.7834 - accuracy: 0.2862 - val_loss: 1.8933 - val_accuracy: 0.2367\n",
            "Epoch 11/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.7626 - accuracy: 0.2988 - val_loss: 1.8320 - val_accuracy: 0.2728\n",
            "Epoch 12/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.7410 - accuracy: 0.3101 - val_loss: 1.8613 - val_accuracy: 0.2577\n",
            "Epoch 13/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.7232 - accuracy: 0.3132 - val_loss: 1.8932 - val_accuracy: 0.2364\n",
            "Epoch 14/400\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 1.7152 - accuracy: 0.3243 - val_loss: 2.0051 - val_accuracy: 0.2429\n",
            "Epoch 15/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.7008 - accuracy: 0.3284 - val_loss: 1.9018 - val_accuracy: 0.2658\n",
            "Epoch 16/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.6883 - accuracy: 0.3364 - val_loss: 1.8927 - val_accuracy: 0.2674\n",
            "Epoch 17/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.6724 - accuracy: 0.3431 - val_loss: 1.8477 - val_accuracy: 0.2801\n",
            "Epoch 18/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.6675 - accuracy: 0.3457 - val_loss: 1.8526 - val_accuracy: 0.2914\n",
            "Epoch 19/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.6499 - accuracy: 0.3591 - val_loss: 1.7194 - val_accuracy: 0.3215\n",
            "Epoch 20/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.6406 - accuracy: 0.3585 - val_loss: 1.9744 - val_accuracy: 0.2643\n",
            "Epoch 21/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.6414 - accuracy: 0.3629 - val_loss: 1.7192 - val_accuracy: 0.3077\n",
            "Epoch 22/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.6287 - accuracy: 0.3658 - val_loss: 1.8446 - val_accuracy: 0.2939\n",
            "Epoch 23/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.6226 - accuracy: 0.3686 - val_loss: 1.8678 - val_accuracy: 0.2864\n",
            "Epoch 24/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.6110 - accuracy: 0.3761 - val_loss: 1.8685 - val_accuracy: 0.3031\n",
            "Epoch 25/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.6114 - accuracy: 0.3764 - val_loss: 1.8404 - val_accuracy: 0.2979\n",
            "Epoch 26/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5984 - accuracy: 0.3825 - val_loss: 1.6430 - val_accuracy: 0.3499\n",
            "Epoch 27/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.6037 - accuracy: 0.3825 - val_loss: 1.6606 - val_accuracy: 0.3495\n",
            "Epoch 28/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5921 - accuracy: 0.3854 - val_loss: 1.6979 - val_accuracy: 0.3332\n",
            "Epoch 29/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5845 - accuracy: 0.3890 - val_loss: 1.6601 - val_accuracy: 0.3456\n",
            "Epoch 30/400\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 1.5788 - accuracy: 0.3942 - val_loss: 1.6610 - val_accuracy: 0.3576\n",
            "Epoch 31/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5768 - accuracy: 0.3959 - val_loss: 1.6358 - val_accuracy: 0.3559\n",
            "Epoch 32/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5676 - accuracy: 0.4017 - val_loss: 1.6276 - val_accuracy: 0.3889\n",
            "Epoch 33/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.5613 - accuracy: 0.4032 - val_loss: 1.6311 - val_accuracy: 0.3611\n",
            "Epoch 34/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.5532 - accuracy: 0.4096 - val_loss: 1.7303 - val_accuracy: 0.3374\n",
            "Epoch 35/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5510 - accuracy: 0.4182 - val_loss: 1.6522 - val_accuracy: 0.3545\n",
            "Epoch 36/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5414 - accuracy: 0.4208 - val_loss: 1.6368 - val_accuracy: 0.3823\n",
            "Epoch 37/400\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 1.5328 - accuracy: 0.4220 - val_loss: 1.6269 - val_accuracy: 0.3858\n",
            "Epoch 38/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5232 - accuracy: 0.4273 - val_loss: 1.5790 - val_accuracy: 0.3957\n",
            "Epoch 39/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5255 - accuracy: 0.4288 - val_loss: 1.5559 - val_accuracy: 0.4075\n",
            "Epoch 40/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5200 - accuracy: 0.4313 - val_loss: 1.5119 - val_accuracy: 0.4272\n",
            "Epoch 41/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5153 - accuracy: 0.4342 - val_loss: 1.4576 - val_accuracy: 0.4394\n",
            "Epoch 42/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5054 - accuracy: 0.4365 - val_loss: 1.6118 - val_accuracy: 0.4100\n",
            "Epoch 43/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5102 - accuracy: 0.4401 - val_loss: 1.4514 - val_accuracy: 0.4578\n",
            "Epoch 44/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5021 - accuracy: 0.4399 - val_loss: 1.5036 - val_accuracy: 0.4353\n",
            "Epoch 45/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4925 - accuracy: 0.4471 - val_loss: 1.4874 - val_accuracy: 0.4353\n",
            "Epoch 46/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4911 - accuracy: 0.4457 - val_loss: 1.6344 - val_accuracy: 0.4094\n",
            "Epoch 47/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4901 - accuracy: 0.4472 - val_loss: 1.4937 - val_accuracy: 0.4554\n",
            "Epoch 48/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4889 - accuracy: 0.4502 - val_loss: 1.4821 - val_accuracy: 0.4523\n",
            "Epoch 49/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4785 - accuracy: 0.4522 - val_loss: 1.4475 - val_accuracy: 0.4697\n",
            "Epoch 50/400\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 1.4756 - accuracy: 0.4579 - val_loss: 1.5880 - val_accuracy: 0.4283\n",
            "Epoch 51/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4721 - accuracy: 0.4589 - val_loss: 1.4458 - val_accuracy: 0.4752\n",
            "Epoch 52/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4655 - accuracy: 0.4640 - val_loss: 1.6407 - val_accuracy: 0.4174\n",
            "Epoch 53/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4620 - accuracy: 0.4638 - val_loss: 1.5965 - val_accuracy: 0.4152\n",
            "Epoch 54/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4675 - accuracy: 0.4616 - val_loss: 1.3907 - val_accuracy: 0.5053\n",
            "Epoch 55/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4457 - accuracy: 0.4701 - val_loss: 1.6159 - val_accuracy: 0.4274\n",
            "Epoch 56/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4536 - accuracy: 0.4671 - val_loss: 1.3869 - val_accuracy: 0.4949\n",
            "Epoch 57/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4508 - accuracy: 0.4738 - val_loss: 1.3412 - val_accuracy: 0.5194\n",
            "Epoch 58/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.4513 - accuracy: 0.4694 - val_loss: 1.4441 - val_accuracy: 0.4937\n",
            "Epoch 59/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4504 - accuracy: 0.4735 - val_loss: 1.4141 - val_accuracy: 0.4863\n",
            "Epoch 60/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4395 - accuracy: 0.4801 - val_loss: 1.5815 - val_accuracy: 0.4458\n",
            "Epoch 61/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4373 - accuracy: 0.4802 - val_loss: 1.4731 - val_accuracy: 0.4747\n",
            "Epoch 62/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4382 - accuracy: 0.4789 - val_loss: 1.3765 - val_accuracy: 0.5170\n",
            "Epoch 63/400\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 1.4334 - accuracy: 0.4808 - val_loss: 1.4182 - val_accuracy: 0.4912\n",
            "Epoch 64/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4270 - accuracy: 0.4864 - val_loss: 1.3071 - val_accuracy: 0.5306\n",
            "Epoch 65/400\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 1.4263 - accuracy: 0.4838 - val_loss: 1.2891 - val_accuracy: 0.5458\n",
            "Epoch 66/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4283 - accuracy: 0.4884 - val_loss: 1.3913 - val_accuracy: 0.5053\n",
            "Epoch 67/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4227 - accuracy: 0.4913 - val_loss: 1.4411 - val_accuracy: 0.4912\n",
            "Epoch 68/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4189 - accuracy: 0.4923 - val_loss: 1.3271 - val_accuracy: 0.5304\n",
            "Epoch 69/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.4099 - accuracy: 0.4972 - val_loss: 1.2853 - val_accuracy: 0.5380\n",
            "Epoch 70/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4104 - accuracy: 0.4962 - val_loss: 1.4837 - val_accuracy: 0.4708\n",
            "Epoch 71/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4154 - accuracy: 0.4977 - val_loss: 1.4290 - val_accuracy: 0.5113\n",
            "Epoch 72/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.4130 - accuracy: 0.4996 - val_loss: 1.3858 - val_accuracy: 0.5206\n",
            "Epoch 73/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4126 - accuracy: 0.4984 - val_loss: 1.3619 - val_accuracy: 0.5152\n",
            "Epoch 74/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4042 - accuracy: 0.4989 - val_loss: 1.3821 - val_accuracy: 0.5192\n",
            "Epoch 75/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.4093 - accuracy: 0.5004 - val_loss: 1.2985 - val_accuracy: 0.5325\n",
            "Epoch 76/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3956 - accuracy: 0.5051 - val_loss: 1.3235 - val_accuracy: 0.5336\n",
            "Epoch 77/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.4096 - accuracy: 0.5008 - val_loss: 1.3163 - val_accuracy: 0.5308\n",
            "Epoch 78/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3985 - accuracy: 0.5044 - val_loss: 1.3338 - val_accuracy: 0.5303\n",
            "Epoch 79/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3902 - accuracy: 0.5062 - val_loss: 1.3305 - val_accuracy: 0.5395\n",
            "Epoch 80/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3962 - accuracy: 0.5062 - val_loss: 1.3128 - val_accuracy: 0.5348\n",
            "Epoch 81/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3968 - accuracy: 0.5055 - val_loss: 1.4838 - val_accuracy: 0.4782\n",
            "Epoch 82/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3933 - accuracy: 0.5118 - val_loss: 1.4726 - val_accuracy: 0.4882\n",
            "Epoch 83/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3821 - accuracy: 0.5108 - val_loss: 1.3820 - val_accuracy: 0.5098\n",
            "Epoch 84/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3972 - accuracy: 0.5061 - val_loss: 1.2085 - val_accuracy: 0.5749\n",
            "Epoch 85/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3892 - accuracy: 0.5109 - val_loss: 1.2611 - val_accuracy: 0.5617\n",
            "Epoch 86/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3908 - accuracy: 0.5116 - val_loss: 1.4382 - val_accuracy: 0.4953\n",
            "Epoch 87/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3804 - accuracy: 0.5137 - val_loss: 1.4871 - val_accuracy: 0.4941\n",
            "Epoch 88/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3818 - accuracy: 0.5135 - val_loss: 1.2066 - val_accuracy: 0.5805\n",
            "Epoch 89/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3885 - accuracy: 0.5078 - val_loss: 1.2851 - val_accuracy: 0.5426\n",
            "Epoch 90/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3798 - accuracy: 0.5150 - val_loss: 1.4004 - val_accuracy: 0.5238\n",
            "Epoch 91/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3842 - accuracy: 0.5117 - val_loss: 1.2925 - val_accuracy: 0.5364\n",
            "Epoch 92/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3758 - accuracy: 0.5145 - val_loss: 1.4859 - val_accuracy: 0.4685\n",
            "Epoch 93/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3798 - accuracy: 0.5142 - val_loss: 1.2839 - val_accuracy: 0.5441\n",
            "Epoch 94/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3765 - accuracy: 0.5166 - val_loss: 1.2752 - val_accuracy: 0.5497\n",
            "Epoch 95/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3710 - accuracy: 0.5200 - val_loss: 1.1874 - val_accuracy: 0.5879\n",
            "Epoch 96/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3689 - accuracy: 0.5207 - val_loss: 1.2637 - val_accuracy: 0.5560\n",
            "Epoch 97/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3700 - accuracy: 0.5198 - val_loss: 1.1790 - val_accuracy: 0.5898\n",
            "Epoch 98/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3732 - accuracy: 0.5204 - val_loss: 1.1708 - val_accuracy: 0.6024\n",
            "Epoch 99/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3681 - accuracy: 0.5244 - val_loss: 1.2210 - val_accuracy: 0.5653\n",
            "Epoch 100/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3675 - accuracy: 0.5223 - val_loss: 1.2687 - val_accuracy: 0.5449\n",
            "Epoch 101/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3706 - accuracy: 0.5207 - val_loss: 1.3182 - val_accuracy: 0.5352\n",
            "Epoch 102/400\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 1.3693 - accuracy: 0.5236 - val_loss: 1.1964 - val_accuracy: 0.5851\n",
            "Epoch 103/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3598 - accuracy: 0.5243 - val_loss: 1.3339 - val_accuracy: 0.5175\n",
            "Epoch 104/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3655 - accuracy: 0.5238 - val_loss: 1.3012 - val_accuracy: 0.5468\n",
            "Epoch 105/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3684 - accuracy: 0.5234 - val_loss: 1.4301 - val_accuracy: 0.5027\n",
            "Epoch 106/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3641 - accuracy: 0.5257 - val_loss: 1.1397 - val_accuracy: 0.5935\n",
            "Epoch 107/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3608 - accuracy: 0.5285 - val_loss: 1.2496 - val_accuracy: 0.5731\n",
            "Epoch 108/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3611 - accuracy: 0.5254 - val_loss: 1.1953 - val_accuracy: 0.5860\n",
            "Epoch 109/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3594 - accuracy: 0.5256 - val_loss: 1.1800 - val_accuracy: 0.5919\n",
            "Epoch 110/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3568 - accuracy: 0.5281 - val_loss: 1.1716 - val_accuracy: 0.5882\n",
            "Epoch 111/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3587 - accuracy: 0.5287 - val_loss: 1.2883 - val_accuracy: 0.5606\n",
            "Epoch 112/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3740 - accuracy: 0.5222 - val_loss: 1.2109 - val_accuracy: 0.5656\n",
            "Epoch 113/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3549 - accuracy: 0.5320 - val_loss: 1.1784 - val_accuracy: 0.6055\n",
            "Epoch 114/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3509 - accuracy: 0.5319 - val_loss: 1.2306 - val_accuracy: 0.5661\n",
            "Epoch 115/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3372 - accuracy: 0.5369 - val_loss: 1.1780 - val_accuracy: 0.5825\n",
            "Epoch 116/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3492 - accuracy: 0.5348 - val_loss: 1.1840 - val_accuracy: 0.5864\n",
            "Epoch 117/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3481 - accuracy: 0.5357 - val_loss: 1.1834 - val_accuracy: 0.5895\n",
            "Epoch 118/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3503 - accuracy: 0.5330 - val_loss: 1.2558 - val_accuracy: 0.5521\n",
            "Epoch 119/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3500 - accuracy: 0.5310 - val_loss: 1.3269 - val_accuracy: 0.5195\n",
            "Epoch 120/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3500 - accuracy: 0.5328 - val_loss: 1.3787 - val_accuracy: 0.5111\n",
            "Epoch 121/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3518 - accuracy: 0.5326 - val_loss: 1.2085 - val_accuracy: 0.5780\n",
            "Epoch 122/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3427 - accuracy: 0.5342 - val_loss: 1.3176 - val_accuracy: 0.5152\n",
            "Epoch 123/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3454 - accuracy: 0.5348 - val_loss: 1.3464 - val_accuracy: 0.5139\n",
            "Epoch 124/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3426 - accuracy: 0.5356 - val_loss: 1.1895 - val_accuracy: 0.5834\n",
            "Epoch 125/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3344 - accuracy: 0.5385 - val_loss: 1.1645 - val_accuracy: 0.5881\n",
            "Epoch 126/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3383 - accuracy: 0.5339 - val_loss: 1.1073 - val_accuracy: 0.6139\n",
            "Epoch 127/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3413 - accuracy: 0.5377 - val_loss: 1.1628 - val_accuracy: 0.5891\n",
            "Epoch 128/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3383 - accuracy: 0.5403 - val_loss: 1.2055 - val_accuracy: 0.5693\n",
            "Epoch 129/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3415 - accuracy: 0.5362 - val_loss: 1.2240 - val_accuracy: 0.5861\n",
            "Epoch 130/400\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 1.3440 - accuracy: 0.5378 - val_loss: 1.1496 - val_accuracy: 0.6030\n",
            "Epoch 131/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3475 - accuracy: 0.5364 - val_loss: 1.1255 - val_accuracy: 0.6157\n",
            "Epoch 132/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3404 - accuracy: 0.5358 - val_loss: 1.1876 - val_accuracy: 0.5782\n",
            "Epoch 133/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3319 - accuracy: 0.5390 - val_loss: 1.1131 - val_accuracy: 0.6229\n",
            "Epoch 134/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3323 - accuracy: 0.5406 - val_loss: 1.1174 - val_accuracy: 0.6253\n",
            "Epoch 135/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3335 - accuracy: 0.5378 - val_loss: 1.1147 - val_accuracy: 0.6223\n",
            "Epoch 136/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3358 - accuracy: 0.5390 - val_loss: 1.2964 - val_accuracy: 0.5501\n",
            "Epoch 137/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3352 - accuracy: 0.5399 - val_loss: 1.1838 - val_accuracy: 0.5819\n",
            "Epoch 138/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3327 - accuracy: 0.5410 - val_loss: 1.2890 - val_accuracy: 0.5366\n",
            "Epoch 139/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3361 - accuracy: 0.5391 - val_loss: 1.1974 - val_accuracy: 0.5809\n",
            "Epoch 140/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3389 - accuracy: 0.5379 - val_loss: 1.1827 - val_accuracy: 0.5980\n",
            "Epoch 141/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3290 - accuracy: 0.5397 - val_loss: 1.1054 - val_accuracy: 0.6204\n",
            "Epoch 142/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3357 - accuracy: 0.5409 - val_loss: 1.1311 - val_accuracy: 0.6016\n",
            "Epoch 143/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3339 - accuracy: 0.5404 - val_loss: 1.0794 - val_accuracy: 0.6314\n",
            "Epoch 144/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3280 - accuracy: 0.5425 - val_loss: 1.2285 - val_accuracy: 0.5649\n",
            "Epoch 145/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3433 - accuracy: 0.5381 - val_loss: 1.1610 - val_accuracy: 0.5894\n",
            "Epoch 146/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3388 - accuracy: 0.5397 - val_loss: 1.1805 - val_accuracy: 0.5904\n",
            "Epoch 147/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3297 - accuracy: 0.5434 - val_loss: 1.2398 - val_accuracy: 0.5609\n",
            "Epoch 148/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3401 - accuracy: 0.5385 - val_loss: 1.2663 - val_accuracy: 0.5553\n",
            "Epoch 149/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3299 - accuracy: 0.5408 - val_loss: 1.2300 - val_accuracy: 0.5623\n",
            "Epoch 150/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3307 - accuracy: 0.5429 - val_loss: 1.1377 - val_accuracy: 0.5938\n",
            "Epoch 151/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3292 - accuracy: 0.5442 - val_loss: 1.1563 - val_accuracy: 0.5855\n",
            "Epoch 152/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3314 - accuracy: 0.5405 - val_loss: 1.1577 - val_accuracy: 0.5977\n",
            "Epoch 153/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3377 - accuracy: 0.5389 - val_loss: 1.2524 - val_accuracy: 0.5642\n",
            "Epoch 154/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3325 - accuracy: 0.5411 - val_loss: 1.0802 - val_accuracy: 0.6334\n",
            "Epoch 155/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3246 - accuracy: 0.5458 - val_loss: 1.2122 - val_accuracy: 0.5844\n",
            "Epoch 156/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3319 - accuracy: 0.5423 - val_loss: 1.1607 - val_accuracy: 0.5997\n",
            "Epoch 157/400\n",
            "50000/50000 [==============================] - 2s 48us/sample - loss: 1.3342 - accuracy: 0.5427 - val_loss: 1.2539 - val_accuracy: 0.5515\n",
            "Epoch 158/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3229 - accuracy: 0.5443 - val_loss: 1.1222 - val_accuracy: 0.6064\n",
            "Epoch 159/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3175 - accuracy: 0.5450 - val_loss: 1.2187 - val_accuracy: 0.5619\n",
            "Epoch 160/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3200 - accuracy: 0.5489 - val_loss: 1.2897 - val_accuracy: 0.5435\n",
            "Epoch 161/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3272 - accuracy: 0.5449 - val_loss: 1.1000 - val_accuracy: 0.6255\n",
            "Epoch 162/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3294 - accuracy: 0.5457 - val_loss: 1.2011 - val_accuracy: 0.5769\n",
            "Epoch 163/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3310 - accuracy: 0.5441 - val_loss: 1.1088 - val_accuracy: 0.6224\n",
            "Epoch 164/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3278 - accuracy: 0.5442 - val_loss: 1.1679 - val_accuracy: 0.5960\n",
            "Epoch 165/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3250 - accuracy: 0.5455 - val_loss: 1.1162 - val_accuracy: 0.6087\n",
            "Epoch 166/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3185 - accuracy: 0.5463 - val_loss: 1.0810 - val_accuracy: 0.6252\n",
            "Epoch 167/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3159 - accuracy: 0.5468 - val_loss: 1.1114 - val_accuracy: 0.6165\n",
            "Epoch 168/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3178 - accuracy: 0.5474 - val_loss: 1.0811 - val_accuracy: 0.6285\n",
            "Epoch 169/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3195 - accuracy: 0.5487 - val_loss: 1.1120 - val_accuracy: 0.6161\n",
            "Epoch 170/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3176 - accuracy: 0.5505 - val_loss: 1.0781 - val_accuracy: 0.6310\n",
            "Epoch 171/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3164 - accuracy: 0.5512 - val_loss: 1.1222 - val_accuracy: 0.6059\n",
            "Epoch 172/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3154 - accuracy: 0.5499 - val_loss: 1.1238 - val_accuracy: 0.5996\n",
            "Epoch 173/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3211 - accuracy: 0.5456 - val_loss: 1.1433 - val_accuracy: 0.5955\n",
            "Epoch 174/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3175 - accuracy: 0.5490 - val_loss: 1.0765 - val_accuracy: 0.6243\n",
            "Epoch 175/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3222 - accuracy: 0.5464 - val_loss: 1.1693 - val_accuracy: 0.5909\n",
            "Epoch 176/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3257 - accuracy: 0.5458 - val_loss: 1.1031 - val_accuracy: 0.6224\n",
            "Epoch 177/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3270 - accuracy: 0.5464 - val_loss: 1.2984 - val_accuracy: 0.5261\n",
            "Epoch 178/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3250 - accuracy: 0.5458 - val_loss: 1.1897 - val_accuracy: 0.5822\n",
            "Epoch 179/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3269 - accuracy: 0.5472 - val_loss: 1.0936 - val_accuracy: 0.6302\n",
            "Epoch 180/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3165 - accuracy: 0.5479 - val_loss: 1.1453 - val_accuracy: 0.5972\n",
            "Epoch 181/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3166 - accuracy: 0.5521 - val_loss: 1.2611 - val_accuracy: 0.5615\n",
            "Epoch 182/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3233 - accuracy: 0.5474 - val_loss: 1.1421 - val_accuracy: 0.6070\n",
            "Epoch 183/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3170 - accuracy: 0.5486 - val_loss: 1.1595 - val_accuracy: 0.6099\n",
            "Epoch 184/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3184 - accuracy: 0.5510 - val_loss: 1.1757 - val_accuracy: 0.5979\n",
            "Epoch 185/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3175 - accuracy: 0.5524 - val_loss: 1.1263 - val_accuracy: 0.6037\n",
            "Epoch 186/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3049 - accuracy: 0.5527 - val_loss: 1.1126 - val_accuracy: 0.6165\n",
            "Epoch 187/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3129 - accuracy: 0.5500 - val_loss: 1.1077 - val_accuracy: 0.6262\n",
            "Epoch 188/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3244 - accuracy: 0.5498 - val_loss: 1.1268 - val_accuracy: 0.6183\n",
            "Epoch 189/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3137 - accuracy: 0.5520 - val_loss: 1.1259 - val_accuracy: 0.6074\n",
            "Epoch 190/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3169 - accuracy: 0.5497 - val_loss: 1.2302 - val_accuracy: 0.5619\n",
            "Epoch 191/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3220 - accuracy: 0.5466 - val_loss: 1.1024 - val_accuracy: 0.6242\n",
            "Epoch 192/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3159 - accuracy: 0.5493 - val_loss: 1.0748 - val_accuracy: 0.6276\n",
            "Epoch 193/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3175 - accuracy: 0.5514 - val_loss: 1.1057 - val_accuracy: 0.6308\n",
            "Epoch 194/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3177 - accuracy: 0.5474 - val_loss: 1.1155 - val_accuracy: 0.6097\n",
            "Epoch 195/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3169 - accuracy: 0.5520 - val_loss: 1.1489 - val_accuracy: 0.5949\n",
            "Epoch 196/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3138 - accuracy: 0.5508 - val_loss: 1.1483 - val_accuracy: 0.5863\n",
            "Epoch 197/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3173 - accuracy: 0.5464 - val_loss: 1.1134 - val_accuracy: 0.6200\n",
            "Epoch 198/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3166 - accuracy: 0.5491 - val_loss: 1.0917 - val_accuracy: 0.6159\n",
            "Epoch 199/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3196 - accuracy: 0.5491 - val_loss: 1.0352 - val_accuracy: 0.6503\n",
            "Epoch 200/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3180 - accuracy: 0.5481 - val_loss: 1.0335 - val_accuracy: 0.6482\n",
            "Epoch 201/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3130 - accuracy: 0.5544 - val_loss: 1.1912 - val_accuracy: 0.5767\n",
            "Epoch 202/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3126 - accuracy: 0.5544 - val_loss: 1.1633 - val_accuracy: 0.5808\n",
            "Epoch 203/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3207 - accuracy: 0.5463 - val_loss: 1.1880 - val_accuracy: 0.6011\n",
            "Epoch 204/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3073 - accuracy: 0.5541 - val_loss: 1.2210 - val_accuracy: 0.5651\n",
            "Epoch 205/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3067 - accuracy: 0.5545 - val_loss: 1.1475 - val_accuracy: 0.6006\n",
            "Epoch 206/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3179 - accuracy: 0.5521 - val_loss: 1.1681 - val_accuracy: 0.5890\n",
            "Epoch 207/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3302 - accuracy: 0.5469 - val_loss: 1.1714 - val_accuracy: 0.5888\n",
            "Epoch 208/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3146 - accuracy: 0.5519 - val_loss: 1.2412 - val_accuracy: 0.5678\n",
            "Epoch 209/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3080 - accuracy: 0.5570 - val_loss: 1.1090 - val_accuracy: 0.6115\n",
            "Epoch 210/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3096 - accuracy: 0.5538 - val_loss: 1.0891 - val_accuracy: 0.6167\n",
            "Epoch 211/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3169 - accuracy: 0.5502 - val_loss: 1.1089 - val_accuracy: 0.6121\n",
            "Epoch 212/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3025 - accuracy: 0.5550 - val_loss: 1.0958 - val_accuracy: 0.6127\n",
            "Epoch 213/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3075 - accuracy: 0.5537 - val_loss: 1.1313 - val_accuracy: 0.5945\n",
            "Epoch 214/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3084 - accuracy: 0.5538 - val_loss: 1.0659 - val_accuracy: 0.6330\n",
            "Epoch 215/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3193 - accuracy: 0.5496 - val_loss: 1.1366 - val_accuracy: 0.6028\n",
            "Epoch 216/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3156 - accuracy: 0.5527 - val_loss: 1.1730 - val_accuracy: 0.5708\n",
            "Epoch 217/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3133 - accuracy: 0.5506 - val_loss: 1.0891 - val_accuracy: 0.6236\n",
            "Epoch 218/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.2996 - accuracy: 0.5566 - val_loss: 1.1150 - val_accuracy: 0.5976\n",
            "Epoch 219/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3075 - accuracy: 0.5536 - val_loss: 1.0860 - val_accuracy: 0.6141\n",
            "Epoch 220/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3114 - accuracy: 0.5544 - val_loss: 1.0539 - val_accuracy: 0.6426\n",
            "Epoch 221/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3168 - accuracy: 0.5504 - val_loss: 1.1149 - val_accuracy: 0.6001\n",
            "Epoch 222/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3073 - accuracy: 0.5525 - val_loss: 1.0561 - val_accuracy: 0.6353\n",
            "Epoch 223/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3172 - accuracy: 0.5492 - val_loss: 1.1973 - val_accuracy: 0.5829\n",
            "Epoch 224/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3149 - accuracy: 0.5512 - val_loss: 1.1092 - val_accuracy: 0.6175\n",
            "Epoch 225/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3039 - accuracy: 0.5562 - val_loss: 1.0998 - val_accuracy: 0.6109\n",
            "Epoch 226/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3071 - accuracy: 0.5534 - val_loss: 1.0856 - val_accuracy: 0.6315\n",
            "Epoch 227/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3078 - accuracy: 0.5565 - val_loss: 1.1573 - val_accuracy: 0.5909\n",
            "Epoch 228/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3146 - accuracy: 0.5518 - val_loss: 1.1873 - val_accuracy: 0.5759\n",
            "Epoch 229/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3043 - accuracy: 0.5557 - val_loss: 1.0550 - val_accuracy: 0.6406\n",
            "Epoch 230/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.2983 - accuracy: 0.5554 - val_loss: 1.1158 - val_accuracy: 0.6133\n",
            "Epoch 231/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3126 - accuracy: 0.5534 - val_loss: 1.1193 - val_accuracy: 0.6041\n",
            "Epoch 232/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3100 - accuracy: 0.5536 - val_loss: 1.0903 - val_accuracy: 0.6242\n",
            "Epoch 233/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3117 - accuracy: 0.5557 - val_loss: 1.1693 - val_accuracy: 0.5927\n",
            "Epoch 234/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3181 - accuracy: 0.5550 - val_loss: 1.0656 - val_accuracy: 0.6312\n",
            "Epoch 235/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3061 - accuracy: 0.5549 - val_loss: 1.1134 - val_accuracy: 0.6201\n",
            "Epoch 236/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3215 - accuracy: 0.5524 - val_loss: 1.1291 - val_accuracy: 0.6129\n",
            "Epoch 237/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3194 - accuracy: 0.5527 - val_loss: 1.0958 - val_accuracy: 0.6126\n",
            "Epoch 238/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3105 - accuracy: 0.5588 - val_loss: 1.1332 - val_accuracy: 0.6095\n",
            "Epoch 239/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3185 - accuracy: 0.5548 - val_loss: 1.0734 - val_accuracy: 0.6343\n",
            "Epoch 240/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3164 - accuracy: 0.5527 - val_loss: 1.0867 - val_accuracy: 0.6233\n",
            "Epoch 241/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3142 - accuracy: 0.5541 - val_loss: 1.1084 - val_accuracy: 0.6162\n",
            "Epoch 242/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3128 - accuracy: 0.5542 - val_loss: 1.0657 - val_accuracy: 0.6370\n",
            "Epoch 243/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3155 - accuracy: 0.5536 - val_loss: 1.1250 - val_accuracy: 0.6125\n",
            "Epoch 244/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.2955 - accuracy: 0.5609 - val_loss: 1.1212 - val_accuracy: 0.6253\n",
            "Epoch 245/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3101 - accuracy: 0.5567 - val_loss: 1.0677 - val_accuracy: 0.6337\n",
            "Epoch 246/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3113 - accuracy: 0.5551 - val_loss: 1.1115 - val_accuracy: 0.6014\n",
            "Epoch 247/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3079 - accuracy: 0.5527 - val_loss: 1.0653 - val_accuracy: 0.6298\n",
            "Epoch 248/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3013 - accuracy: 0.5566 - val_loss: 1.0697 - val_accuracy: 0.6239\n",
            "Epoch 249/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3179 - accuracy: 0.5539 - val_loss: 1.1102 - val_accuracy: 0.5935\n",
            "Epoch 250/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3142 - accuracy: 0.5547 - val_loss: 1.0832 - val_accuracy: 0.6360\n",
            "Epoch 251/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3180 - accuracy: 0.5508 - val_loss: 1.1596 - val_accuracy: 0.6007\n",
            "Epoch 252/400\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 1.3076 - accuracy: 0.5569 - val_loss: 1.1149 - val_accuracy: 0.6127\n",
            "Epoch 253/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3000 - accuracy: 0.5572 - val_loss: 1.2005 - val_accuracy: 0.5824\n",
            "Epoch 254/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3112 - accuracy: 0.5520 - val_loss: 1.0425 - val_accuracy: 0.6427\n",
            "Epoch 255/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3107 - accuracy: 0.5546 - val_loss: 1.1820 - val_accuracy: 0.5791\n",
            "Epoch 256/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3109 - accuracy: 0.5540 - val_loss: 1.1050 - val_accuracy: 0.6308\n",
            "Epoch 257/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3111 - accuracy: 0.5538 - val_loss: 1.1663 - val_accuracy: 0.5871\n",
            "Epoch 258/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3156 - accuracy: 0.5534 - val_loss: 1.1110 - val_accuracy: 0.6154\n",
            "Epoch 259/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3025 - accuracy: 0.5560 - val_loss: 1.0536 - val_accuracy: 0.6399\n",
            "Epoch 260/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3097 - accuracy: 0.5578 - val_loss: 1.1237 - val_accuracy: 0.6130\n",
            "Epoch 261/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3123 - accuracy: 0.5549 - val_loss: 1.0474 - val_accuracy: 0.6369\n",
            "Epoch 262/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.2980 - accuracy: 0.5607 - val_loss: 1.1374 - val_accuracy: 0.6015\n",
            "Epoch 263/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3130 - accuracy: 0.5553 - val_loss: 1.0817 - val_accuracy: 0.6146\n",
            "Epoch 264/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3069 - accuracy: 0.5548 - val_loss: 1.0087 - val_accuracy: 0.6633\n",
            "Epoch 265/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3129 - accuracy: 0.5563 - val_loss: 1.1338 - val_accuracy: 0.6042\n",
            "Epoch 266/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3047 - accuracy: 0.5561 - val_loss: 1.0963 - val_accuracy: 0.6166\n",
            "Epoch 267/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3092 - accuracy: 0.5532 - val_loss: 1.1987 - val_accuracy: 0.5851\n",
            "Epoch 268/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3119 - accuracy: 0.5531 - val_loss: 1.0603 - val_accuracy: 0.6351\n",
            "Epoch 269/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3074 - accuracy: 0.5571 - val_loss: 1.0825 - val_accuracy: 0.6067\n",
            "Epoch 270/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3059 - accuracy: 0.5560 - val_loss: 1.2096 - val_accuracy: 0.5676\n",
            "Epoch 271/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3059 - accuracy: 0.5559 - val_loss: 1.0572 - val_accuracy: 0.6284\n",
            "Epoch 272/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3080 - accuracy: 0.5549 - val_loss: 1.0376 - val_accuracy: 0.6564\n",
            "Epoch 273/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3254 - accuracy: 0.5452 - val_loss: 1.0576 - val_accuracy: 0.6281\n",
            "Epoch 274/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3167 - accuracy: 0.5515 - val_loss: 1.0874 - val_accuracy: 0.6227\n",
            "Epoch 275/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3056 - accuracy: 0.5530 - val_loss: 1.1544 - val_accuracy: 0.5868\n",
            "Epoch 276/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.2906 - accuracy: 0.5618 - val_loss: 1.0344 - val_accuracy: 0.6551\n",
            "Epoch 277/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3113 - accuracy: 0.5551 - val_loss: 1.0830 - val_accuracy: 0.6090\n",
            "Epoch 278/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3085 - accuracy: 0.5602 - val_loss: 1.0763 - val_accuracy: 0.6314\n",
            "Epoch 279/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3101 - accuracy: 0.5558 - val_loss: 1.0613 - val_accuracy: 0.6405\n",
            "Epoch 280/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3147 - accuracy: 0.5563 - val_loss: 1.0676 - val_accuracy: 0.6234\n",
            "Epoch 281/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3108 - accuracy: 0.5563 - val_loss: 1.1477 - val_accuracy: 0.6092\n",
            "Epoch 282/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3108 - accuracy: 0.5561 - val_loss: 1.1240 - val_accuracy: 0.5939\n",
            "Epoch 283/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3079 - accuracy: 0.5539 - val_loss: 1.0782 - val_accuracy: 0.6359\n",
            "Epoch 284/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3126 - accuracy: 0.5560 - val_loss: 1.0607 - val_accuracy: 0.6342\n",
            "Epoch 285/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3121 - accuracy: 0.5566 - val_loss: 1.1256 - val_accuracy: 0.5975\n",
            "Epoch 286/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3075 - accuracy: 0.5569 - val_loss: 1.1361 - val_accuracy: 0.6134\n",
            "Epoch 287/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3061 - accuracy: 0.5570 - val_loss: 1.1120 - val_accuracy: 0.6198\n",
            "Epoch 288/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.2950 - accuracy: 0.5585 - val_loss: 1.1488 - val_accuracy: 0.5958\n",
            "Epoch 289/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3133 - accuracy: 0.5587 - val_loss: 1.1008 - val_accuracy: 0.6113\n",
            "Epoch 290/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3247 - accuracy: 0.5521 - val_loss: 1.0527 - val_accuracy: 0.6442\n",
            "Epoch 291/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3192 - accuracy: 0.5551 - val_loss: 1.0794 - val_accuracy: 0.6247\n",
            "Epoch 292/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3087 - accuracy: 0.5585 - val_loss: 1.0553 - val_accuracy: 0.6425\n",
            "Epoch 293/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3231 - accuracy: 0.5514 - val_loss: 1.0827 - val_accuracy: 0.6273\n",
            "Epoch 294/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3061 - accuracy: 0.5586 - val_loss: 1.1254 - val_accuracy: 0.6071\n",
            "Epoch 295/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3007 - accuracy: 0.5572 - val_loss: 1.0817 - val_accuracy: 0.6196\n",
            "Epoch 296/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3087 - accuracy: 0.5599 - val_loss: 1.0827 - val_accuracy: 0.6244\n",
            "Epoch 297/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3030 - accuracy: 0.5572 - val_loss: 1.1465 - val_accuracy: 0.5882\n",
            "Epoch 298/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3317 - accuracy: 0.5514 - val_loss: 1.0410 - val_accuracy: 0.6339\n",
            "Epoch 299/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3238 - accuracy: 0.5531 - val_loss: 1.0575 - val_accuracy: 0.6243\n",
            "Epoch 300/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3128 - accuracy: 0.5559 - val_loss: 1.1138 - val_accuracy: 0.6264\n",
            "Epoch 301/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3052 - accuracy: 0.5616 - val_loss: 1.1427 - val_accuracy: 0.6059\n",
            "Epoch 302/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3048 - accuracy: 0.5595 - val_loss: 1.1805 - val_accuracy: 0.5839\n",
            "Epoch 303/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3191 - accuracy: 0.5555 - val_loss: 1.0310 - val_accuracy: 0.6514\n",
            "Epoch 304/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3099 - accuracy: 0.5569 - val_loss: 1.0538 - val_accuracy: 0.6281\n",
            "Epoch 305/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3084 - accuracy: 0.5563 - val_loss: 1.0397 - val_accuracy: 0.6515\n",
            "Epoch 306/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3101 - accuracy: 0.5536 - val_loss: 1.1116 - val_accuracy: 0.6170\n",
            "Epoch 307/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3071 - accuracy: 0.5574 - val_loss: 1.0843 - val_accuracy: 0.6137\n",
            "Epoch 308/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3067 - accuracy: 0.5592 - val_loss: 1.0972 - val_accuracy: 0.6156\n",
            "Epoch 309/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3069 - accuracy: 0.5580 - val_loss: 1.0326 - val_accuracy: 0.6396\n",
            "Epoch 310/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3110 - accuracy: 0.5562 - val_loss: 1.1095 - val_accuracy: 0.6210\n",
            "Epoch 311/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3316 - accuracy: 0.5486 - val_loss: 1.1165 - val_accuracy: 0.6037\n",
            "Epoch 312/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3176 - accuracy: 0.5525 - val_loss: 1.1578 - val_accuracy: 0.5833\n",
            "Epoch 313/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3089 - accuracy: 0.5536 - val_loss: 1.0670 - val_accuracy: 0.6269\n",
            "Epoch 314/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3028 - accuracy: 0.5615 - val_loss: 1.1619 - val_accuracy: 0.5922\n",
            "Epoch 315/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3139 - accuracy: 0.5530 - val_loss: 1.0479 - val_accuracy: 0.6337\n",
            "Epoch 316/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3198 - accuracy: 0.5523 - val_loss: 1.0521 - val_accuracy: 0.6561\n",
            "Epoch 317/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3177 - accuracy: 0.5532 - val_loss: 1.1220 - val_accuracy: 0.6042\n",
            "Epoch 318/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3128 - accuracy: 0.5567 - val_loss: 1.1293 - val_accuracy: 0.6114\n",
            "Epoch 319/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3007 - accuracy: 0.5587 - val_loss: 1.1070 - val_accuracy: 0.6219\n",
            "Epoch 320/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3017 - accuracy: 0.5594 - val_loss: 1.0706 - val_accuracy: 0.6356\n",
            "Epoch 321/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3103 - accuracy: 0.5586 - val_loss: 1.0999 - val_accuracy: 0.6255\n",
            "Epoch 322/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3103 - accuracy: 0.5576 - val_loss: 1.0802 - val_accuracy: 0.6265\n",
            "Epoch 323/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3121 - accuracy: 0.5529 - val_loss: 1.0461 - val_accuracy: 0.6452\n",
            "Epoch 324/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3196 - accuracy: 0.5524 - val_loss: 1.0560 - val_accuracy: 0.6204\n",
            "Epoch 325/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3106 - accuracy: 0.5563 - val_loss: 1.0505 - val_accuracy: 0.6470\n",
            "Epoch 326/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3096 - accuracy: 0.5538 - val_loss: 1.0637 - val_accuracy: 0.6301\n",
            "Epoch 327/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3193 - accuracy: 0.5539 - val_loss: 1.0437 - val_accuracy: 0.6507\n",
            "Epoch 328/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3193 - accuracy: 0.5532 - val_loss: 1.0620 - val_accuracy: 0.6329\n",
            "Epoch 329/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3196 - accuracy: 0.5564 - val_loss: 1.0525 - val_accuracy: 0.6541\n",
            "Epoch 330/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3161 - accuracy: 0.5541 - val_loss: 1.0751 - val_accuracy: 0.6287\n",
            "Epoch 331/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3140 - accuracy: 0.5527 - val_loss: 1.1102 - val_accuracy: 0.6103\n",
            "Epoch 332/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3199 - accuracy: 0.5540 - val_loss: 1.0432 - val_accuracy: 0.6465\n",
            "Epoch 333/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3182 - accuracy: 0.5553 - val_loss: 1.0549 - val_accuracy: 0.6426\n",
            "Epoch 334/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3023 - accuracy: 0.5590 - val_loss: 1.0631 - val_accuracy: 0.6449\n",
            "Epoch 335/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3060 - accuracy: 0.5595 - val_loss: 1.3139 - val_accuracy: 0.5363\n",
            "Epoch 336/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3082 - accuracy: 0.5584 - val_loss: 1.1370 - val_accuracy: 0.5889\n",
            "Epoch 337/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3269 - accuracy: 0.5506 - val_loss: 1.0732 - val_accuracy: 0.6177\n",
            "Epoch 338/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3152 - accuracy: 0.5525 - val_loss: 1.0582 - val_accuracy: 0.6389\n",
            "Epoch 339/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3065 - accuracy: 0.5565 - val_loss: 1.1390 - val_accuracy: 0.6289\n",
            "Epoch 340/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3149 - accuracy: 0.5552 - val_loss: 1.0711 - val_accuracy: 0.6305\n",
            "Epoch 341/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3215 - accuracy: 0.5527 - val_loss: 1.0665 - val_accuracy: 0.6449\n",
            "Epoch 342/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3064 - accuracy: 0.5586 - val_loss: 1.0809 - val_accuracy: 0.6201\n",
            "Epoch 343/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3189 - accuracy: 0.5534 - val_loss: 1.0657 - val_accuracy: 0.6317\n",
            "Epoch 344/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.2999 - accuracy: 0.5597 - val_loss: 1.1105 - val_accuracy: 0.6157\n",
            "Epoch 345/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3117 - accuracy: 0.5575 - val_loss: 1.1347 - val_accuracy: 0.5992\n",
            "Epoch 346/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3160 - accuracy: 0.5559 - val_loss: 1.0897 - val_accuracy: 0.6259\n",
            "Epoch 347/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3164 - accuracy: 0.5561 - val_loss: 1.2037 - val_accuracy: 0.5733\n",
            "Epoch 348/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3110 - accuracy: 0.5562 - val_loss: 1.0421 - val_accuracy: 0.6434\n",
            "Epoch 349/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3212 - accuracy: 0.5535 - val_loss: 1.0924 - val_accuracy: 0.6168\n",
            "Epoch 350/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3106 - accuracy: 0.5587 - val_loss: 1.1219 - val_accuracy: 0.6113\n",
            "Epoch 351/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3075 - accuracy: 0.5569 - val_loss: 1.1071 - val_accuracy: 0.6145\n",
            "Epoch 352/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3191 - accuracy: 0.5546 - val_loss: 1.0504 - val_accuracy: 0.6361\n",
            "Epoch 353/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3230 - accuracy: 0.5526 - val_loss: 1.1685 - val_accuracy: 0.5880\n",
            "Epoch 354/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3081 - accuracy: 0.5562 - val_loss: 1.0535 - val_accuracy: 0.6334\n",
            "Epoch 355/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3167 - accuracy: 0.5535 - val_loss: 1.0782 - val_accuracy: 0.6384\n",
            "Epoch 356/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3186 - accuracy: 0.5553 - val_loss: 1.0683 - val_accuracy: 0.6387\n",
            "Epoch 357/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3054 - accuracy: 0.5590 - val_loss: 1.1364 - val_accuracy: 0.5918\n",
            "Epoch 358/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3117 - accuracy: 0.5591 - val_loss: 1.0108 - val_accuracy: 0.6555\n",
            "Epoch 359/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3045 - accuracy: 0.5617 - val_loss: 1.0442 - val_accuracy: 0.6499\n",
            "Epoch 360/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3133 - accuracy: 0.5584 - val_loss: 1.1032 - val_accuracy: 0.6344\n",
            "Epoch 361/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3180 - accuracy: 0.5557 - val_loss: 1.1104 - val_accuracy: 0.6105\n",
            "Epoch 362/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3178 - accuracy: 0.5556 - val_loss: 1.1647 - val_accuracy: 0.5793\n",
            "Epoch 363/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3132 - accuracy: 0.5587 - val_loss: 1.0770 - val_accuracy: 0.6305\n",
            "Epoch 364/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3215 - accuracy: 0.5530 - val_loss: 1.0707 - val_accuracy: 0.6419\n",
            "Epoch 365/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3138 - accuracy: 0.5537 - val_loss: 1.0419 - val_accuracy: 0.6386\n",
            "Epoch 366/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3173 - accuracy: 0.5557 - val_loss: 1.1175 - val_accuracy: 0.6029\n",
            "Epoch 367/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3111 - accuracy: 0.5561 - val_loss: 1.0410 - val_accuracy: 0.6462\n",
            "Epoch 368/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3062 - accuracy: 0.5590 - val_loss: 1.0561 - val_accuracy: 0.6492\n",
            "Epoch 369/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3129 - accuracy: 0.5559 - val_loss: 1.1930 - val_accuracy: 0.5656\n",
            "Epoch 370/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3193 - accuracy: 0.5509 - val_loss: 1.1355 - val_accuracy: 0.6098\n",
            "Epoch 371/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3212 - accuracy: 0.5528 - val_loss: 1.0898 - val_accuracy: 0.6199\n",
            "Epoch 372/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3161 - accuracy: 0.5530 - val_loss: 1.0437 - val_accuracy: 0.6432\n",
            "Epoch 373/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.2977 - accuracy: 0.5609 - val_loss: 1.0280 - val_accuracy: 0.6421\n",
            "Epoch 374/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.2953 - accuracy: 0.5622 - val_loss: 1.1230 - val_accuracy: 0.6106\n",
            "Epoch 375/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3140 - accuracy: 0.5563 - val_loss: 1.0737 - val_accuracy: 0.6275\n",
            "Epoch 376/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3144 - accuracy: 0.5542 - val_loss: 1.0650 - val_accuracy: 0.6425\n",
            "Epoch 377/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3078 - accuracy: 0.5588 - val_loss: 1.0819 - val_accuracy: 0.6432\n",
            "Epoch 378/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3116 - accuracy: 0.5561 - val_loss: 1.0243 - val_accuracy: 0.6659\n",
            "Epoch 379/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3103 - accuracy: 0.5540 - val_loss: 1.1233 - val_accuracy: 0.6005\n",
            "Epoch 380/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3173 - accuracy: 0.5516 - val_loss: 1.0780 - val_accuracy: 0.6376\n",
            "Epoch 381/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3364 - accuracy: 0.5493 - val_loss: 1.0218 - val_accuracy: 0.6506\n",
            "Epoch 382/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3139 - accuracy: 0.5538 - val_loss: 1.0528 - val_accuracy: 0.6293\n",
            "Epoch 383/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3129 - accuracy: 0.5583 - val_loss: 1.0913 - val_accuracy: 0.6192\n",
            "Epoch 384/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3378 - accuracy: 0.5484 - val_loss: 1.0944 - val_accuracy: 0.6357\n",
            "Epoch 385/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3234 - accuracy: 0.5518 - val_loss: 1.1254 - val_accuracy: 0.5987\n",
            "Epoch 386/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3150 - accuracy: 0.5542 - val_loss: 1.1206 - val_accuracy: 0.5965\n",
            "Epoch 387/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3249 - accuracy: 0.5509 - val_loss: 1.0683 - val_accuracy: 0.6288\n",
            "Epoch 388/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3161 - accuracy: 0.5567 - val_loss: 1.1102 - val_accuracy: 0.6116\n",
            "Epoch 389/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3200 - accuracy: 0.5540 - val_loss: 1.0972 - val_accuracy: 0.6185\n",
            "Epoch 390/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3195 - accuracy: 0.5575 - val_loss: 1.0719 - val_accuracy: 0.6258\n",
            "Epoch 391/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3259 - accuracy: 0.5517 - val_loss: 1.1233 - val_accuracy: 0.6110\n",
            "Epoch 392/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3396 - accuracy: 0.5477 - val_loss: 1.0710 - val_accuracy: 0.6409\n",
            "Epoch 393/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3273 - accuracy: 0.5527 - val_loss: 1.0771 - val_accuracy: 0.6264\n",
            "Epoch 394/400\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 1.3292 - accuracy: 0.5506 - val_loss: 1.0589 - val_accuracy: 0.6158\n",
            "Epoch 395/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3296 - accuracy: 0.5517 - val_loss: 1.0702 - val_accuracy: 0.6362\n",
            "Epoch 396/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3132 - accuracy: 0.5509 - val_loss: 1.0892 - val_accuracy: 0.6094\n",
            "Epoch 397/400\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 1.3240 - accuracy: 0.5554 - val_loss: 1.1215 - val_accuracy: 0.6059\n",
            "Epoch 398/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3270 - accuracy: 0.5523 - val_loss: 1.0366 - val_accuracy: 0.6597\n",
            "Epoch 399/400\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3077 - accuracy: 0.5582 - val_loss: 1.0693 - val_accuracy: 0.6423\n",
            "Epoch 400/400\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 1.3235 - accuracy: 0.5514 - val_loss: 1.0739 - val_accuracy: 0.6373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC4KZmSUuCGZmBsD/AblmpCGE99D6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS9nrtWF6YYr",
        "colab_type": "text"
      },
      "source": [
        "### Adding L2 regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wuAOzGqKmPy",
        "colab_type": "code",
        "outputId": "22e6c789-f961-43bd-e99b-23debfaf8a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.layers import Input, Add, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.activations import relu, softmax\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "\n",
        "def conv_model(dropout_rate = 0.0):\n",
        "    \n",
        "    dropout_rate = dropout_rate\n",
        "    \n",
        "    input = Input((32, 32, 3), name='input')\n",
        "    \n",
        "    conv_1 = Conv2D(64, (3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.00001), activation='relu', name='conv_1')(input)\n",
        "    pool_1 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_1')(conv_1)\n",
        "    dropout_1 = Dropout(dropout_rate, name='dropout_1')(pool_1)\n",
        "    \n",
        "    conv_2 = Conv2D(64, (3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.00001), activation='relu', name='conv_2')(dropout_1)\n",
        "    pool_2 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_2')(conv_2)\n",
        "    dropout_2 = Dropout(dropout_rate, name='dropout_2')(pool_2)\n",
        "\n",
        "    conv_3 = Conv2D(96, (3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.00001), activation='relu', name='conv_3')(dropout_2)\n",
        "    pool_3 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_3')(conv_3)\n",
        "    dropout_3 = Dropout(dropout_rate, name='dropout_3')(pool_3)\n",
        "\n",
        "    conv_4 = Conv2D(96, (3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.00001), activation='relu', name='conv_4')(dropout_3)\n",
        "    pool_4 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_4')(conv_4)\n",
        "    dropout_4 = Dropout(dropout_rate, name='dropout_4')(pool_4)\n",
        "\n",
        "    conv_5 = Conv2D(96, (3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.00001), activation='relu', name='conv_5')(dropout_4)\n",
        "    pool_5 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_5')(conv_5)\n",
        "    dropout_5 = Dropout(dropout_rate, name='dropout_5')(pool_5)\n",
        "    \n",
        "    flatten = Flatten(name='flatten')(dropout_5)\n",
        "    \n",
        "    fc_1 = Dense(120, activation='relu', name='fc_1')(flatten)\n",
        "    dropout_6 = Dropout(dropout_rate, name='dropout_6')(fc_1)\n",
        "    fc_2 = Dense(80, activation='relu', name='fc_2')(dropout_6)\n",
        "    dropout_7 = Dropout(dropout_rate, name='dropout_7')(fc_2)\n",
        "    \n",
        "    output = Dense(10, activation='softmax', name='output')(dropout_7)\n",
        "    model = Model(input, output)\n",
        "    \n",
        "    plot_model(model, 'CNN_2.png')\n",
        "    \n",
        "    model.compile(\n",
        "      optimizer=Adam(learning_rate=0.001),\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "    )\n",
        "\n",
        "    \n",
        "    hist = model.fit(x_train, y_train , epochs=200,\n",
        "                     batch_size=256,\n",
        "                     validation_data=(x_test, y_test))\n",
        "    \n",
        "    history_model(hist.history)\n",
        "\n",
        "conv_model(0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "50000/50000 [==============================] - 3s 66us/sample - loss: 2.0348 - accuracy: 0.2201 - val_loss: 1.7154 - val_accuracy: 0.3590\n",
            "Epoch 2/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.5988 - accuracy: 0.4028 - val_loss: 1.3848 - val_accuracy: 0.4907\n",
            "Epoch 3/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.3527 - accuracy: 0.5076 - val_loss: 1.2293 - val_accuracy: 0.5557\n",
            "Epoch 4/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.2305 - accuracy: 0.5593 - val_loss: 1.0758 - val_accuracy: 0.6195\n",
            "Epoch 5/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.1452 - accuracy: 0.5964 - val_loss: 1.0769 - val_accuracy: 0.6241\n",
            "Epoch 6/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.0746 - accuracy: 0.6239 - val_loss: 0.9775 - val_accuracy: 0.6612\n",
            "Epoch 7/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 1.0087 - accuracy: 0.6497 - val_loss: 0.8983 - val_accuracy: 0.6866\n",
            "Epoch 8/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.9744 - accuracy: 0.6630 - val_loss: 0.8679 - val_accuracy: 0.6988\n",
            "Epoch 9/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.9371 - accuracy: 0.6778 - val_loss: 0.8286 - val_accuracy: 0.7123\n",
            "Epoch 10/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.8855 - accuracy: 0.6948 - val_loss: 0.7995 - val_accuracy: 0.7255\n",
            "Epoch 11/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.8626 - accuracy: 0.7045 - val_loss: 0.7968 - val_accuracy: 0.7275\n",
            "Epoch 12/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.8302 - accuracy: 0.7157 - val_loss: 0.7618 - val_accuracy: 0.7426\n",
            "Epoch 13/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.8194 - accuracy: 0.7228 - val_loss: 0.7509 - val_accuracy: 0.7422\n",
            "Epoch 14/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7853 - accuracy: 0.7344 - val_loss: 0.7322 - val_accuracy: 0.7536\n",
            "Epoch 15/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.7699 - accuracy: 0.7390 - val_loss: 0.7424 - val_accuracy: 0.7522\n",
            "Epoch 16/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7572 - accuracy: 0.7438 - val_loss: 0.7205 - val_accuracy: 0.7583\n",
            "Epoch 17/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7346 - accuracy: 0.7525 - val_loss: 0.7147 - val_accuracy: 0.7598\n",
            "Epoch 18/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.7264 - accuracy: 0.7572 - val_loss: 0.6856 - val_accuracy: 0.7681\n",
            "Epoch 19/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.7071 - accuracy: 0.7616 - val_loss: 0.7272 - val_accuracy: 0.7606\n",
            "Epoch 20/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6872 - accuracy: 0.7681 - val_loss: 0.7009 - val_accuracy: 0.7625\n",
            "Epoch 21/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.6939 - accuracy: 0.7678 - val_loss: 0.7432 - val_accuracy: 0.7559\n",
            "Epoch 22/200\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 0.6778 - accuracy: 0.7729 - val_loss: 0.6784 - val_accuracy: 0.7752\n",
            "Epoch 23/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6634 - accuracy: 0.7784 - val_loss: 0.6887 - val_accuracy: 0.7709\n",
            "Epoch 24/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6576 - accuracy: 0.7798 - val_loss: 0.6485 - val_accuracy: 0.7831\n",
            "Epoch 25/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6448 - accuracy: 0.7849 - val_loss: 0.6702 - val_accuracy: 0.7762\n",
            "Epoch 26/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6437 - accuracy: 0.7868 - val_loss: 0.6342 - val_accuracy: 0.7876\n",
            "Epoch 27/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6266 - accuracy: 0.7925 - val_loss: 0.6501 - val_accuracy: 0.7861\n",
            "Epoch 28/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6204 - accuracy: 0.7935 - val_loss: 0.6541 - val_accuracy: 0.7859\n",
            "Epoch 29/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6115 - accuracy: 0.7993 - val_loss: 0.6256 - val_accuracy: 0.7947\n",
            "Epoch 30/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6071 - accuracy: 0.8007 - val_loss: 0.6244 - val_accuracy: 0.7942\n",
            "Epoch 31/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.6032 - accuracy: 0.7991 - val_loss: 0.6294 - val_accuracy: 0.7946\n",
            "Epoch 32/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.5984 - accuracy: 0.8014 - val_loss: 0.6300 - val_accuracy: 0.7944\n",
            "Epoch 33/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.5962 - accuracy: 0.8046 - val_loss: 0.6309 - val_accuracy: 0.7976\n",
            "Epoch 34/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5932 - accuracy: 0.8055 - val_loss: 0.6343 - val_accuracy: 0.7943\n",
            "Epoch 35/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.5803 - accuracy: 0.8096 - val_loss: 0.6502 - val_accuracy: 0.7926\n",
            "Epoch 36/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5788 - accuracy: 0.8102 - val_loss: 0.6421 - val_accuracy: 0.7905\n",
            "Epoch 37/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5684 - accuracy: 0.8139 - val_loss: 0.6256 - val_accuracy: 0.7958\n",
            "Epoch 38/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5719 - accuracy: 0.8107 - val_loss: 0.6309 - val_accuracy: 0.7974\n",
            "Epoch 39/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5658 - accuracy: 0.8120 - val_loss: 0.6138 - val_accuracy: 0.7969\n",
            "Epoch 40/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.5638 - accuracy: 0.8163 - val_loss: 0.6211 - val_accuracy: 0.7928\n",
            "Epoch 41/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5594 - accuracy: 0.8185 - val_loss: 0.6111 - val_accuracy: 0.8013\n",
            "Epoch 42/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5538 - accuracy: 0.8174 - val_loss: 0.6096 - val_accuracy: 0.8013\n",
            "Epoch 43/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5471 - accuracy: 0.8211 - val_loss: 0.6260 - val_accuracy: 0.7975\n",
            "Epoch 44/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5487 - accuracy: 0.8209 - val_loss: 0.6158 - val_accuracy: 0.7983\n",
            "Epoch 45/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.5476 - accuracy: 0.8210 - val_loss: 0.6424 - val_accuracy: 0.7941\n",
            "Epoch 46/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.5367 - accuracy: 0.8250 - val_loss: 0.6162 - val_accuracy: 0.8014\n",
            "Epoch 47/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5251 - accuracy: 0.8289 - val_loss: 0.6151 - val_accuracy: 0.8026\n",
            "Epoch 48/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5345 - accuracy: 0.8272 - val_loss: 0.6234 - val_accuracy: 0.8021\n",
            "Epoch 49/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5281 - accuracy: 0.8288 - val_loss: 0.6120 - val_accuracy: 0.8018\n",
            "Epoch 50/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5348 - accuracy: 0.8258 - val_loss: 0.6483 - val_accuracy: 0.7937\n",
            "Epoch 51/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5293 - accuracy: 0.8276 - val_loss: 0.6096 - val_accuracy: 0.8060\n",
            "Epoch 52/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5203 - accuracy: 0.8310 - val_loss: 0.6008 - val_accuracy: 0.8118\n",
            "Epoch 53/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5205 - accuracy: 0.8306 - val_loss: 0.6102 - val_accuracy: 0.8084\n",
            "Epoch 54/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5130 - accuracy: 0.8342 - val_loss: 0.5990 - val_accuracy: 0.8088\n",
            "Epoch 55/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5203 - accuracy: 0.8309 - val_loss: 0.6109 - val_accuracy: 0.8073\n",
            "Epoch 56/200\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 0.5132 - accuracy: 0.8347 - val_loss: 0.6159 - val_accuracy: 0.8028\n",
            "Epoch 57/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.5116 - accuracy: 0.8354 - val_loss: 0.5986 - val_accuracy: 0.8097\n",
            "Epoch 58/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5024 - accuracy: 0.8396 - val_loss: 0.5920 - val_accuracy: 0.8122\n",
            "Epoch 59/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5031 - accuracy: 0.8380 - val_loss: 0.6109 - val_accuracy: 0.8057\n",
            "Epoch 60/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4997 - accuracy: 0.8406 - val_loss: 0.6207 - val_accuracy: 0.8012\n",
            "Epoch 61/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5098 - accuracy: 0.8368 - val_loss: 0.6319 - val_accuracy: 0.8013\n",
            "Epoch 62/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.5064 - accuracy: 0.8373 - val_loss: 0.6098 - val_accuracy: 0.8048\n",
            "Epoch 63/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.5034 - accuracy: 0.8382 - val_loss: 0.6221 - val_accuracy: 0.8060\n",
            "Epoch 64/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.5008 - accuracy: 0.8382 - val_loss: 0.5960 - val_accuracy: 0.8134\n",
            "Epoch 65/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4970 - accuracy: 0.8397 - val_loss: 0.6118 - val_accuracy: 0.8107\n",
            "Epoch 66/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4920 - accuracy: 0.8422 - val_loss: 0.6101 - val_accuracy: 0.8103\n",
            "Epoch 67/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4989 - accuracy: 0.8399 - val_loss: 0.6024 - val_accuracy: 0.8116\n",
            "Epoch 68/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4870 - accuracy: 0.8445 - val_loss: 0.5966 - val_accuracy: 0.8096\n",
            "Epoch 69/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4934 - accuracy: 0.8395 - val_loss: 0.5944 - val_accuracy: 0.8151\n",
            "Epoch 70/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4852 - accuracy: 0.8440 - val_loss: 0.5935 - val_accuracy: 0.8137\n",
            "Epoch 71/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4791 - accuracy: 0.8458 - val_loss: 0.5878 - val_accuracy: 0.8162\n",
            "Epoch 72/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4819 - accuracy: 0.8452 - val_loss: 0.6043 - val_accuracy: 0.8147\n",
            "Epoch 73/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4826 - accuracy: 0.8466 - val_loss: 0.5938 - val_accuracy: 0.8161\n",
            "Epoch 74/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4831 - accuracy: 0.8445 - val_loss: 0.5896 - val_accuracy: 0.8180\n",
            "Epoch 75/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4779 - accuracy: 0.8486 - val_loss: 0.6202 - val_accuracy: 0.8076\n",
            "Epoch 76/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4820 - accuracy: 0.8489 - val_loss: 0.5947 - val_accuracy: 0.8195\n",
            "Epoch 77/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4761 - accuracy: 0.8481 - val_loss: 0.5848 - val_accuracy: 0.8179\n",
            "Epoch 78/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4785 - accuracy: 0.8464 - val_loss: 0.6123 - val_accuracy: 0.8080\n",
            "Epoch 79/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4724 - accuracy: 0.8518 - val_loss: 0.5895 - val_accuracy: 0.8142\n",
            "Epoch 80/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4756 - accuracy: 0.8503 - val_loss: 0.5913 - val_accuracy: 0.8136\n",
            "Epoch 81/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.4738 - accuracy: 0.8518 - val_loss: 0.5962 - val_accuracy: 0.8164\n",
            "Epoch 82/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4725 - accuracy: 0.8525 - val_loss: 0.6136 - val_accuracy: 0.8179\n",
            "Epoch 83/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4625 - accuracy: 0.8541 - val_loss: 0.6102 - val_accuracy: 0.8115\n",
            "Epoch 84/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4702 - accuracy: 0.8510 - val_loss: 0.6056 - val_accuracy: 0.8141\n",
            "Epoch 85/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4664 - accuracy: 0.8540 - val_loss: 0.6009 - val_accuracy: 0.8158\n",
            "Epoch 86/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4644 - accuracy: 0.8547 - val_loss: 0.6417 - val_accuracy: 0.8048\n",
            "Epoch 87/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4680 - accuracy: 0.8535 - val_loss: 0.5906 - val_accuracy: 0.8156\n",
            "Epoch 88/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4661 - accuracy: 0.8536 - val_loss: 0.5897 - val_accuracy: 0.8190\n",
            "Epoch 89/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4695 - accuracy: 0.8519 - val_loss: 0.5822 - val_accuracy: 0.8235\n",
            "Epoch 90/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4620 - accuracy: 0.8547 - val_loss: 0.6031 - val_accuracy: 0.8163\n",
            "Epoch 91/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4564 - accuracy: 0.8560 - val_loss: 0.5919 - val_accuracy: 0.8202\n",
            "Epoch 92/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4609 - accuracy: 0.8543 - val_loss: 0.6051 - val_accuracy: 0.8185\n",
            "Epoch 93/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4636 - accuracy: 0.8551 - val_loss: 0.6126 - val_accuracy: 0.8168\n",
            "Epoch 94/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4642 - accuracy: 0.8541 - val_loss: 0.5993 - val_accuracy: 0.8146\n",
            "Epoch 95/200\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4580 - accuracy: 0.8571 - val_loss: 0.5974 - val_accuracy: 0.8218\n",
            "Epoch 96/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4598 - accuracy: 0.8566 - val_loss: 0.5957 - val_accuracy: 0.8195\n",
            "Epoch 97/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4614 - accuracy: 0.8564 - val_loss: 0.5931 - val_accuracy: 0.8155\n",
            "Epoch 98/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4599 - accuracy: 0.8562 - val_loss: 0.5916 - val_accuracy: 0.8184\n",
            "Epoch 99/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4504 - accuracy: 0.8601 - val_loss: 0.6168 - val_accuracy: 0.8164\n",
            "Epoch 100/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4520 - accuracy: 0.8615 - val_loss: 0.6056 - val_accuracy: 0.8179\n",
            "Epoch 101/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4539 - accuracy: 0.8599 - val_loss: 0.5733 - val_accuracy: 0.8269\n",
            "Epoch 102/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4511 - accuracy: 0.8587 - val_loss: 0.5999 - val_accuracy: 0.8192\n",
            "Epoch 103/200\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4461 - accuracy: 0.8629 - val_loss: 0.5898 - val_accuracy: 0.8226\n",
            "Epoch 104/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4517 - accuracy: 0.8596 - val_loss: 0.5899 - val_accuracy: 0.8209\n",
            "Epoch 105/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.4504 - accuracy: 0.8612 - val_loss: 0.5936 - val_accuracy: 0.8223\n",
            "Epoch 106/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4518 - accuracy: 0.8590 - val_loss: 0.5740 - val_accuracy: 0.8265\n",
            "Epoch 107/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4441 - accuracy: 0.8648 - val_loss: 0.5812 - val_accuracy: 0.8231\n",
            "Epoch 108/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4488 - accuracy: 0.8610 - val_loss: 0.5923 - val_accuracy: 0.8190\n",
            "Epoch 109/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4461 - accuracy: 0.8628 - val_loss: 0.5888 - val_accuracy: 0.8220\n",
            "Epoch 110/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4465 - accuracy: 0.8637 - val_loss: 0.5967 - val_accuracy: 0.8212\n",
            "Epoch 111/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4453 - accuracy: 0.8616 - val_loss: 0.6051 - val_accuracy: 0.8211\n",
            "Epoch 112/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4391 - accuracy: 0.8648 - val_loss: 0.5781 - val_accuracy: 0.8277\n",
            "Epoch 113/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4368 - accuracy: 0.8659 - val_loss: 0.5834 - val_accuracy: 0.8248\n",
            "Epoch 114/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4371 - accuracy: 0.8654 - val_loss: 0.6026 - val_accuracy: 0.8183\n",
            "Epoch 115/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4499 - accuracy: 0.8604 - val_loss: 0.5898 - val_accuracy: 0.8248\n",
            "Epoch 116/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4434 - accuracy: 0.8657 - val_loss: 0.5898 - val_accuracy: 0.8203\n",
            "Epoch 117/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4392 - accuracy: 0.8660 - val_loss: 0.5911 - val_accuracy: 0.8218\n",
            "Epoch 118/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4423 - accuracy: 0.8637 - val_loss: 0.6217 - val_accuracy: 0.8142\n",
            "Epoch 119/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4392 - accuracy: 0.8637 - val_loss: 0.6006 - val_accuracy: 0.8246\n",
            "Epoch 120/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.4389 - accuracy: 0.8656 - val_loss: 0.6044 - val_accuracy: 0.8154\n",
            "Epoch 121/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.4393 - accuracy: 0.8652 - val_loss: 0.5861 - val_accuracy: 0.8267\n",
            "Epoch 122/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.4412 - accuracy: 0.8652 - val_loss: 0.5829 - val_accuracy: 0.8282\n",
            "Epoch 123/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.4376 - accuracy: 0.8673 - val_loss: 0.5959 - val_accuracy: 0.8285\n",
            "Epoch 124/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4404 - accuracy: 0.8669 - val_loss: 0.5961 - val_accuracy: 0.8235\n",
            "Epoch 125/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4295 - accuracy: 0.8684 - val_loss: 0.6016 - val_accuracy: 0.8210\n",
            "Epoch 126/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4343 - accuracy: 0.8670 - val_loss: 0.5882 - val_accuracy: 0.8212\n",
            "Epoch 127/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4339 - accuracy: 0.8678 - val_loss: 0.5927 - val_accuracy: 0.8229\n",
            "Epoch 128/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4390 - accuracy: 0.8696 - val_loss: 0.6040 - val_accuracy: 0.8202\n",
            "Epoch 129/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.4260 - accuracy: 0.8698 - val_loss: 0.5969 - val_accuracy: 0.8211\n",
            "Epoch 130/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4261 - accuracy: 0.8700 - val_loss: 0.6165 - val_accuracy: 0.8164\n",
            "Epoch 131/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4311 - accuracy: 0.8693 - val_loss: 0.6074 - val_accuracy: 0.8213\n",
            "Epoch 132/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4291 - accuracy: 0.8696 - val_loss: 0.6026 - val_accuracy: 0.8242\n",
            "Epoch 133/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4236 - accuracy: 0.8709 - val_loss: 0.5846 - val_accuracy: 0.8284\n",
            "Epoch 134/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4304 - accuracy: 0.8695 - val_loss: 0.6044 - val_accuracy: 0.8203\n",
            "Epoch 135/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4287 - accuracy: 0.8704 - val_loss: 0.5939 - val_accuracy: 0.8227\n",
            "Epoch 136/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4240 - accuracy: 0.8727 - val_loss: 0.5768 - val_accuracy: 0.8271\n",
            "Epoch 137/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4291 - accuracy: 0.8701 - val_loss: 0.6005 - val_accuracy: 0.8277\n",
            "Epoch 138/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4281 - accuracy: 0.8710 - val_loss: 0.5927 - val_accuracy: 0.8224\n",
            "Epoch 139/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4298 - accuracy: 0.8692 - val_loss: 0.5946 - val_accuracy: 0.8242\n",
            "Epoch 140/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4269 - accuracy: 0.8704 - val_loss: 0.6025 - val_accuracy: 0.8229\n",
            "Epoch 141/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4254 - accuracy: 0.8708 - val_loss: 0.5983 - val_accuracy: 0.8249\n",
            "Epoch 142/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4281 - accuracy: 0.8706 - val_loss: 0.5939 - val_accuracy: 0.8260\n",
            "Epoch 143/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4274 - accuracy: 0.8714 - val_loss: 0.5807 - val_accuracy: 0.8276\n",
            "Epoch 144/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4241 - accuracy: 0.8723 - val_loss: 0.5840 - val_accuracy: 0.8273\n",
            "Epoch 145/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4250 - accuracy: 0.8727 - val_loss: 0.5904 - val_accuracy: 0.8250\n",
            "Epoch 146/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4206 - accuracy: 0.8739 - val_loss: 0.5896 - val_accuracy: 0.8230\n",
            "Epoch 147/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4220 - accuracy: 0.8750 - val_loss: 0.6198 - val_accuracy: 0.8241\n",
            "Epoch 148/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4248 - accuracy: 0.8731 - val_loss: 0.5986 - val_accuracy: 0.8235\n",
            "Epoch 149/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4292 - accuracy: 0.8727 - val_loss: 0.6124 - val_accuracy: 0.8224\n",
            "Epoch 150/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4308 - accuracy: 0.8700 - val_loss: 0.5937 - val_accuracy: 0.8215\n",
            "Epoch 151/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4231 - accuracy: 0.8733 - val_loss: 0.6031 - val_accuracy: 0.8274\n",
            "Epoch 152/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4256 - accuracy: 0.8731 - val_loss: 0.5960 - val_accuracy: 0.8241\n",
            "Epoch 153/200\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4210 - accuracy: 0.8745 - val_loss: 0.5837 - val_accuracy: 0.8323\n",
            "Epoch 154/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4197 - accuracy: 0.8752 - val_loss: 0.6006 - val_accuracy: 0.8278\n",
            "Epoch 155/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4200 - accuracy: 0.8724 - val_loss: 0.6061 - val_accuracy: 0.8238\n",
            "Epoch 156/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4273 - accuracy: 0.8739 - val_loss: 0.6169 - val_accuracy: 0.8201\n",
            "Epoch 157/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4133 - accuracy: 0.8775 - val_loss: 0.6042 - val_accuracy: 0.8253\n",
            "Epoch 158/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4237 - accuracy: 0.8744 - val_loss: 0.5966 - val_accuracy: 0.8253\n",
            "Epoch 159/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4235 - accuracy: 0.8722 - val_loss: 0.5777 - val_accuracy: 0.8286\n",
            "Epoch 160/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4190 - accuracy: 0.8746 - val_loss: 0.5891 - val_accuracy: 0.8272\n",
            "Epoch 161/200\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4170 - accuracy: 0.8757 - val_loss: 0.6051 - val_accuracy: 0.8269\n",
            "Epoch 162/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4162 - accuracy: 0.8747 - val_loss: 0.6101 - val_accuracy: 0.8262\n",
            "Epoch 163/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4232 - accuracy: 0.8741 - val_loss: 0.5919 - val_accuracy: 0.8276\n",
            "Epoch 164/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4171 - accuracy: 0.8759 - val_loss: 0.5932 - val_accuracy: 0.8303\n",
            "Epoch 165/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4206 - accuracy: 0.8746 - val_loss: 0.6082 - val_accuracy: 0.8266\n",
            "Epoch 166/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4153 - accuracy: 0.8775 - val_loss: 0.6005 - val_accuracy: 0.8264\n",
            "Epoch 167/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4157 - accuracy: 0.8762 - val_loss: 0.5904 - val_accuracy: 0.8303\n",
            "Epoch 168/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4167 - accuracy: 0.8768 - val_loss: 0.6189 - val_accuracy: 0.8226\n",
            "Epoch 169/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4107 - accuracy: 0.8793 - val_loss: 0.5856 - val_accuracy: 0.8335\n",
            "Epoch 170/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4184 - accuracy: 0.8752 - val_loss: 0.5938 - val_accuracy: 0.8382\n",
            "Epoch 171/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4150 - accuracy: 0.8780 - val_loss: 0.6436 - val_accuracy: 0.8156\n",
            "Epoch 172/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4240 - accuracy: 0.8730 - val_loss: 0.5918 - val_accuracy: 0.8286\n",
            "Epoch 173/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4171 - accuracy: 0.8751 - val_loss: 0.5920 - val_accuracy: 0.8299\n",
            "Epoch 174/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4120 - accuracy: 0.8782 - val_loss: 0.5982 - val_accuracy: 0.8282\n",
            "Epoch 175/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4158 - accuracy: 0.8783 - val_loss: 0.6023 - val_accuracy: 0.8264\n",
            "Epoch 176/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4090 - accuracy: 0.8780 - val_loss: 0.6027 - val_accuracy: 0.8267\n",
            "Epoch 177/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4128 - accuracy: 0.8776 - val_loss: 0.5873 - val_accuracy: 0.8298\n",
            "Epoch 178/200\n",
            "50000/50000 [==============================] - 3s 51us/sample - loss: 0.4135 - accuracy: 0.8767 - val_loss: 0.6130 - val_accuracy: 0.8265\n",
            "Epoch 179/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4135 - accuracy: 0.8799 - val_loss: 0.6024 - val_accuracy: 0.8298\n",
            "Epoch 180/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4121 - accuracy: 0.8784 - val_loss: 0.6155 - val_accuracy: 0.8275\n",
            "Epoch 181/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4106 - accuracy: 0.8803 - val_loss: 0.5936 - val_accuracy: 0.8296\n",
            "Epoch 182/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4078 - accuracy: 0.8791 - val_loss: 0.6171 - val_accuracy: 0.8233\n",
            "Epoch 183/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4127 - accuracy: 0.8796 - val_loss: 0.5909 - val_accuracy: 0.8311\n",
            "Epoch 184/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4073 - accuracy: 0.8817 - val_loss: 0.5909 - val_accuracy: 0.8300\n",
            "Epoch 185/200\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4105 - accuracy: 0.8793 - val_loss: 0.6376 - val_accuracy: 0.8224\n",
            "Epoch 186/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4100 - accuracy: 0.8810 - val_loss: 0.6124 - val_accuracy: 0.8271\n",
            "Epoch 187/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4128 - accuracy: 0.8807 - val_loss: 0.6011 - val_accuracy: 0.8271\n",
            "Epoch 188/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4072 - accuracy: 0.8806 - val_loss: 0.5898 - val_accuracy: 0.8343\n",
            "Epoch 189/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4091 - accuracy: 0.8807 - val_loss: 0.5967 - val_accuracy: 0.8290\n",
            "Epoch 190/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4025 - accuracy: 0.8823 - val_loss: 0.6112 - val_accuracy: 0.8273\n",
            "Epoch 191/200\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4075 - accuracy: 0.8813 - val_loss: 0.5820 - val_accuracy: 0.8335\n",
            "Epoch 192/200\n",
            "50000/50000 [==============================] - 3s 50us/sample - loss: 0.4095 - accuracy: 0.8797 - val_loss: 0.5915 - val_accuracy: 0.8340\n",
            "Epoch 193/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4086 - accuracy: 0.8804 - val_loss: 0.5901 - val_accuracy: 0.8313\n",
            "Epoch 194/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4097 - accuracy: 0.8807 - val_loss: 0.6057 - val_accuracy: 0.8314\n",
            "Epoch 195/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4101 - accuracy: 0.8788 - val_loss: 0.5909 - val_accuracy: 0.8364\n",
            "Epoch 196/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4099 - accuracy: 0.8812 - val_loss: 0.5994 - val_accuracy: 0.8298\n",
            "Epoch 197/200\n",
            "50000/50000 [==============================] - 2s 50us/sample - loss: 0.4046 - accuracy: 0.8819 - val_loss: 0.5988 - val_accuracy: 0.8307\n",
            "Epoch 198/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4041 - accuracy: 0.8814 - val_loss: 0.5932 - val_accuracy: 0.8300\n",
            "Epoch 199/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4062 - accuracy: 0.8818 - val_loss: 0.5888 - val_accuracy: 0.8304\n",
            "Epoch 200/200\n",
            "50000/50000 [==============================] - 2s 49us/sample - loss: 0.4076 - accuracy: 0.8814 - val_loss: 0.6162 - val_accuracy: 0.8310\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmRUuCmZmVrgomJlZ8T/JatZeDjtcqAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7d0iOD1_Wg_",
        "colab_type": "text"
      },
      "source": [
        "L2 + batchnorm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EE6tWlP_WXD",
        "colab_type": "code",
        "outputId": "1f16becc-88dd-41fa-8884-828aeaba8c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.layers import Input, Add, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.activations import relu, softmax\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "\n",
        "def conv_model(dropout_rate = 0.0):\n",
        "    \n",
        "    dropout_rate = dropout_rate\n",
        "    \n",
        "    input = Input((32, 32, 3), name='input')\n",
        "\n",
        "    batch_norm = BatchNormalization(name=\"batch_norm\")(input)\n",
        "    \n",
        "    conv_1 = Conv2D(64, (3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.00001), activation='relu', name='conv_1')(batch_norm)\n",
        "    pool_1 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_1')(conv_1)\n",
        "    dropout_1 = Dropout(dropout_rate, name='dropout_1')(pool_1)\n",
        "    \n",
        "    conv_2 = Conv2D(64, (3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.00001), activation='relu', name='conv_2')(dropout_1)\n",
        "    pool_2 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_2')(conv_2)\n",
        "    dropout_2 = Dropout(dropout_rate, name='dropout_2')(pool_2)\n",
        "\n",
        "    conv_3 = Conv2D(96, (3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.00001), activation='relu', name='conv_3')(dropout_2)\n",
        "    pool_3 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_3')(conv_3)\n",
        "    dropout_3 = Dropout(dropout_rate, name='dropout_3')(pool_3)\n",
        "\n",
        "    conv_4 = Conv2D(96, (3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.00001), activation='relu', name='conv_4')(dropout_3)\n",
        "    pool_4 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_4')(conv_4)\n",
        "    dropout_4 = Dropout(dropout_rate, name='dropout_4')(pool_4)\n",
        "\n",
        "    conv_5 = Conv2D(96, (3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.00001), activation='relu', name='conv_5')(dropout_4)\n",
        "    pool_5 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_5')(conv_5)\n",
        "    dropout_5 = Dropout(dropout_rate, name='dropout_5')(pool_5)\n",
        "    \n",
        "    flatten = Flatten(name='flatten')(dropout_4)\n",
        "    batch_norm_2 = BatchNormalization(name=\"batch_norm_2\")(flatten)\n",
        "\n",
        "    fc_1 = Dense(120, activation='relu', name='fc_1')(batch_norm_2)\n",
        "    dropout_6 = Dropout(dropout_rate, name='dropout_6')(fc_1)\n",
        "    fc_2 = Dense(80, activation='relu', name='fc_2')(dropout_6)\n",
        "    dropout_7 = Dropout(dropout_rate, name='dropout_7')(fc_2)\n",
        "    \n",
        "    output = Dense(10, activation='softmax', name='output')(dropout_7)\n",
        "    model = Model(input, output)\n",
        "    \n",
        "    plot_model(model, 'CNN_2.png')\n",
        "    \n",
        "    model.compile(\n",
        "      optimizer=Adam(learning_rate=0.001),\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "    )\n",
        "\n",
        "    \n",
        "    hist = model.fit(x_train, y_train , epochs=200,\n",
        "                     batch_size=256,\n",
        "                     validation_data=(x_test, y_test))\n",
        "    \n",
        "    history_model(hist.history)\n",
        "\n",
        "conv_model(0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "50000/50000 [==============================] - 4s 71us/sample - loss: 1.8098 - accuracy: 0.3303 - val_loss: 2.3104 - val_accuracy: 0.1465\n",
            "Epoch 2/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 1.4132 - accuracy: 0.4860 - val_loss: 1.5149 - val_accuracy: 0.4535\n",
            "Epoch 3/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 1.2230 - accuracy: 0.5624 - val_loss: 1.1193 - val_accuracy: 0.6008\n",
            "Epoch 4/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 1.0964 - accuracy: 0.6110 - val_loss: 0.9547 - val_accuracy: 0.6619\n",
            "Epoch 5/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 1.0014 - accuracy: 0.6478 - val_loss: 0.8636 - val_accuracy: 0.6925\n",
            "Epoch 6/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.9379 - accuracy: 0.6722 - val_loss: 0.8374 - val_accuracy: 0.7092\n",
            "Epoch 7/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.8863 - accuracy: 0.6926 - val_loss: 0.7971 - val_accuracy: 0.7254\n",
            "Epoch 8/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.8415 - accuracy: 0.7104 - val_loss: 0.7571 - val_accuracy: 0.7411\n",
            "Epoch 9/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.8009 - accuracy: 0.7241 - val_loss: 0.7265 - val_accuracy: 0.7503\n",
            "Epoch 10/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.7675 - accuracy: 0.7370 - val_loss: 0.7266 - val_accuracy: 0.7524\n",
            "Epoch 11/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.7512 - accuracy: 0.7417 - val_loss: 0.6900 - val_accuracy: 0.7645\n",
            "Epoch 12/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.7287 - accuracy: 0.7505 - val_loss: 0.6813 - val_accuracy: 0.7684\n",
            "Epoch 13/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.7035 - accuracy: 0.7605 - val_loss: 0.6271 - val_accuracy: 0.7870\n",
            "Epoch 14/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.6837 - accuracy: 0.7678 - val_loss: 0.6429 - val_accuracy: 0.7816\n",
            "Epoch 15/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.6639 - accuracy: 0.7738 - val_loss: 0.6366 - val_accuracy: 0.7863\n",
            "Epoch 16/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.6511 - accuracy: 0.7783 - val_loss: 0.6331 - val_accuracy: 0.7847\n",
            "Epoch 17/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.6359 - accuracy: 0.7832 - val_loss: 0.6669 - val_accuracy: 0.7761\n",
            "Epoch 18/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.6238 - accuracy: 0.7864 - val_loss: 0.6478 - val_accuracy: 0.7839\n",
            "Epoch 19/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.6144 - accuracy: 0.7911 - val_loss: 0.6057 - val_accuracy: 0.7965\n",
            "Epoch 20/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.5999 - accuracy: 0.7959 - val_loss: 0.6040 - val_accuracy: 0.7984\n",
            "Epoch 21/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.5909 - accuracy: 0.7986 - val_loss: 0.6006 - val_accuracy: 0.8002\n",
            "Epoch 22/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.5822 - accuracy: 0.8045 - val_loss: 0.6105 - val_accuracy: 0.7959\n",
            "Epoch 23/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.5772 - accuracy: 0.8034 - val_loss: 0.5758 - val_accuracy: 0.8070\n",
            "Epoch 24/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.5681 - accuracy: 0.8064 - val_loss: 0.5722 - val_accuracy: 0.8064\n",
            "Epoch 25/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.5556 - accuracy: 0.8134 - val_loss: 0.6201 - val_accuracy: 0.7978\n",
            "Epoch 26/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.5513 - accuracy: 0.8132 - val_loss: 0.5898 - val_accuracy: 0.8055\n",
            "Epoch 27/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.5443 - accuracy: 0.8171 - val_loss: 0.5644 - val_accuracy: 0.8094\n",
            "Epoch 28/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.5367 - accuracy: 0.8193 - val_loss: 0.5678 - val_accuracy: 0.8128\n",
            "Epoch 29/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.5307 - accuracy: 0.8214 - val_loss: 0.5724 - val_accuracy: 0.8113\n",
            "Epoch 30/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.5194 - accuracy: 0.8243 - val_loss: 0.5993 - val_accuracy: 0.8001\n",
            "Epoch 31/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.5176 - accuracy: 0.8255 - val_loss: 0.5549 - val_accuracy: 0.8151\n",
            "Epoch 32/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.5073 - accuracy: 0.8287 - val_loss: 0.5558 - val_accuracy: 0.8157\n",
            "Epoch 33/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.5064 - accuracy: 0.8299 - val_loss: 0.5528 - val_accuracy: 0.8134\n",
            "Epoch 34/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.5099 - accuracy: 0.8281 - val_loss: 0.5534 - val_accuracy: 0.8200\n",
            "Epoch 35/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4919 - accuracy: 0.8330 - val_loss: 0.5885 - val_accuracy: 0.8075\n",
            "Epoch 36/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4867 - accuracy: 0.8363 - val_loss: 0.5556 - val_accuracy: 0.8160\n",
            "Epoch 37/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4919 - accuracy: 0.8348 - val_loss: 0.5327 - val_accuracy: 0.8268\n",
            "Epoch 38/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4867 - accuracy: 0.8379 - val_loss: 0.6022 - val_accuracy: 0.8050\n",
            "Epoch 39/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4826 - accuracy: 0.8382 - val_loss: 0.5568 - val_accuracy: 0.8203\n",
            "Epoch 40/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4809 - accuracy: 0.8385 - val_loss: 0.5357 - val_accuracy: 0.8231\n",
            "Epoch 41/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4738 - accuracy: 0.8413 - val_loss: 0.5508 - val_accuracy: 0.8214\n",
            "Epoch 42/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4679 - accuracy: 0.8443 - val_loss: 0.5417 - val_accuracy: 0.8249\n",
            "Epoch 43/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4694 - accuracy: 0.8419 - val_loss: 0.5675 - val_accuracy: 0.8127\n",
            "Epoch 44/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4633 - accuracy: 0.8454 - val_loss: 0.5516 - val_accuracy: 0.8195\n",
            "Epoch 45/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4629 - accuracy: 0.8454 - val_loss: 0.5883 - val_accuracy: 0.8111\n",
            "Epoch 46/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4553 - accuracy: 0.8479 - val_loss: 0.5522 - val_accuracy: 0.8227\n",
            "Epoch 47/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4539 - accuracy: 0.8501 - val_loss: 0.5758 - val_accuracy: 0.8109\n",
            "Epoch 48/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4546 - accuracy: 0.8472 - val_loss: 0.5516 - val_accuracy: 0.8223\n",
            "Epoch 49/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4523 - accuracy: 0.8499 - val_loss: 0.5418 - val_accuracy: 0.8272\n",
            "Epoch 50/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4464 - accuracy: 0.8518 - val_loss: 0.5642 - val_accuracy: 0.8180\n",
            "Epoch 51/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.4400 - accuracy: 0.8541 - val_loss: 0.5426 - val_accuracy: 0.8273\n",
            "Epoch 52/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4403 - accuracy: 0.8556 - val_loss: 0.5455 - val_accuracy: 0.8289\n",
            "Epoch 53/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4358 - accuracy: 0.8555 - val_loss: 0.5610 - val_accuracy: 0.8185\n",
            "Epoch 54/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4360 - accuracy: 0.8546 - val_loss: 0.5712 - val_accuracy: 0.8204\n",
            "Epoch 55/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4416 - accuracy: 0.8511 - val_loss: 0.5573 - val_accuracy: 0.8207\n",
            "Epoch 56/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4289 - accuracy: 0.8575 - val_loss: 0.5536 - val_accuracy: 0.8258\n",
            "Epoch 57/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4371 - accuracy: 0.8551 - val_loss: 0.5442 - val_accuracy: 0.8282\n",
            "Epoch 58/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4270 - accuracy: 0.8600 - val_loss: 0.5544 - val_accuracy: 0.8243\n",
            "Epoch 59/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4293 - accuracy: 0.8599 - val_loss: 0.5287 - val_accuracy: 0.8289\n",
            "Epoch 60/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4260 - accuracy: 0.8590 - val_loss: 0.5615 - val_accuracy: 0.8211\n",
            "Epoch 61/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4228 - accuracy: 0.8576 - val_loss: 0.5355 - val_accuracy: 0.8269\n",
            "Epoch 62/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4196 - accuracy: 0.8618 - val_loss: 0.5460 - val_accuracy: 0.8257\n",
            "Epoch 63/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4181 - accuracy: 0.8625 - val_loss: 0.5474 - val_accuracy: 0.8255\n",
            "Epoch 64/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4176 - accuracy: 0.8606 - val_loss: 0.5457 - val_accuracy: 0.8296\n",
            "Epoch 65/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4157 - accuracy: 0.8642 - val_loss: 0.5623 - val_accuracy: 0.8245\n",
            "Epoch 66/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4195 - accuracy: 0.8620 - val_loss: 0.5754 - val_accuracy: 0.8193\n",
            "Epoch 67/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.4113 - accuracy: 0.8643 - val_loss: 0.5559 - val_accuracy: 0.8237\n",
            "Epoch 68/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4147 - accuracy: 0.8632 - val_loss: 0.5362 - val_accuracy: 0.8355\n",
            "Epoch 69/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4101 - accuracy: 0.8650 - val_loss: 0.5236 - val_accuracy: 0.8344\n",
            "Epoch 70/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4089 - accuracy: 0.8662 - val_loss: 0.5539 - val_accuracy: 0.8290\n",
            "Epoch 71/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4095 - accuracy: 0.8666 - val_loss: 0.5306 - val_accuracy: 0.8331\n",
            "Epoch 72/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4015 - accuracy: 0.8694 - val_loss: 0.5413 - val_accuracy: 0.8324\n",
            "Epoch 73/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.4059 - accuracy: 0.8677 - val_loss: 0.5351 - val_accuracy: 0.8329\n",
            "Epoch 74/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.3940 - accuracy: 0.8723 - val_loss: 0.5428 - val_accuracy: 0.8300\n",
            "Epoch 75/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3987 - accuracy: 0.8679 - val_loss: 0.5310 - val_accuracy: 0.8371\n",
            "Epoch 76/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3999 - accuracy: 0.8707 - val_loss: 0.5362 - val_accuracy: 0.8363\n",
            "Epoch 77/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.4077 - accuracy: 0.8660 - val_loss: 0.5299 - val_accuracy: 0.8350\n",
            "Epoch 78/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.3916 - accuracy: 0.8709 - val_loss: 0.5560 - val_accuracy: 0.8290\n",
            "Epoch 79/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.3949 - accuracy: 0.8713 - val_loss: 0.5505 - val_accuracy: 0.8329\n",
            "Epoch 80/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.3951 - accuracy: 0.8721 - val_loss: 0.5481 - val_accuracy: 0.8334\n",
            "Epoch 81/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.3954 - accuracy: 0.8715 - val_loss: 0.5477 - val_accuracy: 0.8330\n",
            "Epoch 82/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3943 - accuracy: 0.8725 - val_loss: 0.5778 - val_accuracy: 0.8262\n",
            "Epoch 83/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3906 - accuracy: 0.8726 - val_loss: 0.5523 - val_accuracy: 0.8296\n",
            "Epoch 84/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3880 - accuracy: 0.8734 - val_loss: 0.5658 - val_accuracy: 0.8287\n",
            "Epoch 85/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3895 - accuracy: 0.8740 - val_loss: 0.5323 - val_accuracy: 0.8369\n",
            "Epoch 86/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3879 - accuracy: 0.8750 - val_loss: 0.5484 - val_accuracy: 0.8378\n",
            "Epoch 87/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3909 - accuracy: 0.8741 - val_loss: 0.5774 - val_accuracy: 0.8239\n",
            "Epoch 88/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3913 - accuracy: 0.8714 - val_loss: 0.5522 - val_accuracy: 0.8329\n",
            "Epoch 89/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3878 - accuracy: 0.8761 - val_loss: 0.5763 - val_accuracy: 0.8260\n",
            "Epoch 90/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3824 - accuracy: 0.8768 - val_loss: 0.5436 - val_accuracy: 0.8350\n",
            "Epoch 91/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3844 - accuracy: 0.8763 - val_loss: 0.5394 - val_accuracy: 0.8349\n",
            "Epoch 92/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3879 - accuracy: 0.8758 - val_loss: 0.5539 - val_accuracy: 0.8359\n",
            "Epoch 93/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3835 - accuracy: 0.8763 - val_loss: 0.5575 - val_accuracy: 0.8345\n",
            "Epoch 94/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3829 - accuracy: 0.8770 - val_loss: 0.5505 - val_accuracy: 0.8333\n",
            "Epoch 95/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3776 - accuracy: 0.8779 - val_loss: 0.5771 - val_accuracy: 0.8268\n",
            "Epoch 96/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.3800 - accuracy: 0.8787 - val_loss: 0.5414 - val_accuracy: 0.8346\n",
            "Epoch 97/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3795 - accuracy: 0.8782 - val_loss: 0.5353 - val_accuracy: 0.8394\n",
            "Epoch 98/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3756 - accuracy: 0.8802 - val_loss: 0.5405 - val_accuracy: 0.8393\n",
            "Epoch 99/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3772 - accuracy: 0.8801 - val_loss: 0.5511 - val_accuracy: 0.8337\n",
            "Epoch 100/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3734 - accuracy: 0.8803 - val_loss: 0.5526 - val_accuracy: 0.8334\n",
            "Epoch 101/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3763 - accuracy: 0.8799 - val_loss: 0.5547 - val_accuracy: 0.8354\n",
            "Epoch 102/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3775 - accuracy: 0.8799 - val_loss: 0.5521 - val_accuracy: 0.8389\n",
            "Epoch 103/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3744 - accuracy: 0.8798 - val_loss: 0.5650 - val_accuracy: 0.8330\n",
            "Epoch 104/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3749 - accuracy: 0.8795 - val_loss: 0.5479 - val_accuracy: 0.8355\n",
            "Epoch 105/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3751 - accuracy: 0.8809 - val_loss: 0.5312 - val_accuracy: 0.8369\n",
            "Epoch 106/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3701 - accuracy: 0.8841 - val_loss: 0.5480 - val_accuracy: 0.8362\n",
            "Epoch 107/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3676 - accuracy: 0.8838 - val_loss: 0.5424 - val_accuracy: 0.8391\n",
            "Epoch 108/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3735 - accuracy: 0.8806 - val_loss: 0.5484 - val_accuracy: 0.8354\n",
            "Epoch 109/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3716 - accuracy: 0.8821 - val_loss: 0.5652 - val_accuracy: 0.8319\n",
            "Epoch 110/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3716 - accuracy: 0.8832 - val_loss: 0.5366 - val_accuracy: 0.8386\n",
            "Epoch 111/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3676 - accuracy: 0.8840 - val_loss: 0.5575 - val_accuracy: 0.8366\n",
            "Epoch 112/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.3673 - accuracy: 0.8830 - val_loss: 0.5942 - val_accuracy: 0.8221\n",
            "Epoch 113/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3675 - accuracy: 0.8853 - val_loss: 0.5431 - val_accuracy: 0.8369\n",
            "Epoch 114/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3687 - accuracy: 0.8827 - val_loss: 0.5450 - val_accuracy: 0.8401\n",
            "Epoch 115/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3630 - accuracy: 0.8858 - val_loss: 0.5508 - val_accuracy: 0.8374\n",
            "Epoch 116/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3674 - accuracy: 0.8853 - val_loss: 0.5389 - val_accuracy: 0.8408\n",
            "Epoch 117/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3619 - accuracy: 0.8846 - val_loss: 0.5626 - val_accuracy: 0.8313\n",
            "Epoch 118/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3619 - accuracy: 0.8866 - val_loss: 0.5574 - val_accuracy: 0.8366\n",
            "Epoch 119/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.3577 - accuracy: 0.8869 - val_loss: 0.5415 - val_accuracy: 0.8418\n",
            "Epoch 120/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3585 - accuracy: 0.8883 - val_loss: 0.5298 - val_accuracy: 0.8424\n",
            "Epoch 121/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3589 - accuracy: 0.8876 - val_loss: 0.5710 - val_accuracy: 0.8328\n",
            "Epoch 122/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3621 - accuracy: 0.8858 - val_loss: 0.5359 - val_accuracy: 0.8404\n",
            "Epoch 123/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3615 - accuracy: 0.8874 - val_loss: 0.5835 - val_accuracy: 0.8347\n",
            "Epoch 124/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3636 - accuracy: 0.8862 - val_loss: 0.5545 - val_accuracy: 0.8342\n",
            "Epoch 125/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3572 - accuracy: 0.8880 - val_loss: 0.5426 - val_accuracy: 0.8416\n",
            "Epoch 126/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3626 - accuracy: 0.8867 - val_loss: 0.5569 - val_accuracy: 0.8372\n",
            "Epoch 127/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3582 - accuracy: 0.8864 - val_loss: 0.5488 - val_accuracy: 0.8392\n",
            "Epoch 128/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3627 - accuracy: 0.8871 - val_loss: 0.5528 - val_accuracy: 0.8385\n",
            "Epoch 129/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3553 - accuracy: 0.8893 - val_loss: 0.5531 - val_accuracy: 0.8408\n",
            "Epoch 130/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3607 - accuracy: 0.8878 - val_loss: 0.5410 - val_accuracy: 0.8417\n",
            "Epoch 131/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3611 - accuracy: 0.8867 - val_loss: 0.5550 - val_accuracy: 0.8359\n",
            "Epoch 132/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3551 - accuracy: 0.8890 - val_loss: 0.5757 - val_accuracy: 0.8348\n",
            "Epoch 133/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3555 - accuracy: 0.8887 - val_loss: 0.5633 - val_accuracy: 0.8349\n",
            "Epoch 134/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3517 - accuracy: 0.8902 - val_loss: 0.5491 - val_accuracy: 0.8412\n",
            "Epoch 135/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3526 - accuracy: 0.8898 - val_loss: 0.5532 - val_accuracy: 0.8404\n",
            "Epoch 136/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3551 - accuracy: 0.8903 - val_loss: 0.5753 - val_accuracy: 0.8375\n",
            "Epoch 137/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3549 - accuracy: 0.8876 - val_loss: 0.5623 - val_accuracy: 0.8404\n",
            "Epoch 138/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3557 - accuracy: 0.8883 - val_loss: 0.5556 - val_accuracy: 0.8426\n",
            "Epoch 139/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3545 - accuracy: 0.8896 - val_loss: 0.5468 - val_accuracy: 0.8401\n",
            "Epoch 140/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3505 - accuracy: 0.8917 - val_loss: 0.5493 - val_accuracy: 0.8389\n",
            "Epoch 141/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3572 - accuracy: 0.8903 - val_loss: 0.5588 - val_accuracy: 0.8367\n",
            "Epoch 142/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.3500 - accuracy: 0.8924 - val_loss: 0.5551 - val_accuracy: 0.8397\n",
            "Epoch 143/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3549 - accuracy: 0.8901 - val_loss: 0.5634 - val_accuracy: 0.8368\n",
            "Epoch 144/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3506 - accuracy: 0.8912 - val_loss: 0.5858 - val_accuracy: 0.8316\n",
            "Epoch 145/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3527 - accuracy: 0.8891 - val_loss: 0.5849 - val_accuracy: 0.8356\n",
            "Epoch 146/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3520 - accuracy: 0.8920 - val_loss: 0.5556 - val_accuracy: 0.8408\n",
            "Epoch 147/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3478 - accuracy: 0.8928 - val_loss: 0.5671 - val_accuracy: 0.8354\n",
            "Epoch 148/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3484 - accuracy: 0.8921 - val_loss: 0.5546 - val_accuracy: 0.8423\n",
            "Epoch 149/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3511 - accuracy: 0.8937 - val_loss: 0.5646 - val_accuracy: 0.8385\n",
            "Epoch 150/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3546 - accuracy: 0.8921 - val_loss: 0.5580 - val_accuracy: 0.8376\n",
            "Epoch 151/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3512 - accuracy: 0.8921 - val_loss: 0.5580 - val_accuracy: 0.8401\n",
            "Epoch 152/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3454 - accuracy: 0.8937 - val_loss: 0.6019 - val_accuracy: 0.8325\n",
            "Epoch 153/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3515 - accuracy: 0.8914 - val_loss: 0.5563 - val_accuracy: 0.8425\n",
            "Epoch 154/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3477 - accuracy: 0.8946 - val_loss: 0.5589 - val_accuracy: 0.8393\n",
            "Epoch 155/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3428 - accuracy: 0.8939 - val_loss: 0.5776 - val_accuracy: 0.8391\n",
            "Epoch 156/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3507 - accuracy: 0.8920 - val_loss: 0.5628 - val_accuracy: 0.8403\n",
            "Epoch 157/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3548 - accuracy: 0.8913 - val_loss: 0.5645 - val_accuracy: 0.8373\n",
            "Epoch 158/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3415 - accuracy: 0.8946 - val_loss: 0.5791 - val_accuracy: 0.8383\n",
            "Epoch 159/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3430 - accuracy: 0.8936 - val_loss: 0.5908 - val_accuracy: 0.8385\n",
            "Epoch 160/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3457 - accuracy: 0.8950 - val_loss: 0.5853 - val_accuracy: 0.8374\n",
            "Epoch 161/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3458 - accuracy: 0.8950 - val_loss: 0.5524 - val_accuracy: 0.8447\n",
            "Epoch 162/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3460 - accuracy: 0.8944 - val_loss: 0.5837 - val_accuracy: 0.8337\n",
            "Epoch 163/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3435 - accuracy: 0.8944 - val_loss: 0.5603 - val_accuracy: 0.8394\n",
            "Epoch 164/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3498 - accuracy: 0.8941 - val_loss: 0.5752 - val_accuracy: 0.8399\n",
            "Epoch 165/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.3434 - accuracy: 0.8945 - val_loss: 0.5688 - val_accuracy: 0.8417\n",
            "Epoch 166/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3397 - accuracy: 0.8966 - val_loss: 0.5685 - val_accuracy: 0.8428\n",
            "Epoch 167/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3455 - accuracy: 0.8938 - val_loss: 0.5708 - val_accuracy: 0.8357\n",
            "Epoch 168/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3452 - accuracy: 0.8950 - val_loss: 0.5923 - val_accuracy: 0.8346\n",
            "Epoch 169/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3497 - accuracy: 0.8937 - val_loss: 0.5645 - val_accuracy: 0.8381\n",
            "Epoch 170/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3348 - accuracy: 0.8987 - val_loss: 0.5667 - val_accuracy: 0.8412\n",
            "Epoch 171/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3409 - accuracy: 0.8976 - val_loss: 0.5513 - val_accuracy: 0.8457\n",
            "Epoch 172/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3393 - accuracy: 0.8964 - val_loss: 0.5712 - val_accuracy: 0.8414\n",
            "Epoch 173/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3392 - accuracy: 0.8973 - val_loss: 0.5593 - val_accuracy: 0.8401\n",
            "Epoch 174/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3456 - accuracy: 0.8952 - val_loss: 0.5798 - val_accuracy: 0.8339\n",
            "Epoch 175/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3452 - accuracy: 0.8951 - val_loss: 0.5610 - val_accuracy: 0.8426\n",
            "Epoch 176/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3410 - accuracy: 0.8963 - val_loss: 0.5611 - val_accuracy: 0.8431\n",
            "Epoch 177/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3424 - accuracy: 0.8959 - val_loss: 0.5739 - val_accuracy: 0.8354\n",
            "Epoch 178/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3389 - accuracy: 0.8971 - val_loss: 0.6102 - val_accuracy: 0.8335\n",
            "Epoch 179/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3418 - accuracy: 0.8953 - val_loss: 0.5836 - val_accuracy: 0.8399\n",
            "Epoch 180/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3381 - accuracy: 0.8973 - val_loss: 0.5678 - val_accuracy: 0.8407\n",
            "Epoch 181/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3329 - accuracy: 0.8996 - val_loss: 0.5558 - val_accuracy: 0.8421\n",
            "Epoch 182/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3424 - accuracy: 0.8957 - val_loss: 0.5947 - val_accuracy: 0.8339\n",
            "Epoch 183/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3421 - accuracy: 0.8972 - val_loss: 0.5687 - val_accuracy: 0.8400\n",
            "Epoch 184/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3411 - accuracy: 0.8962 - val_loss: 0.5628 - val_accuracy: 0.8429\n",
            "Epoch 185/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3403 - accuracy: 0.8979 - val_loss: 0.5657 - val_accuracy: 0.8411\n",
            "Epoch 186/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3369 - accuracy: 0.8984 - val_loss: 0.5652 - val_accuracy: 0.8415\n",
            "Epoch 187/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3367 - accuracy: 0.8978 - val_loss: 0.5475 - val_accuracy: 0.8451\n",
            "Epoch 188/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.3338 - accuracy: 0.9006 - val_loss: 0.5742 - val_accuracy: 0.8379\n",
            "Epoch 189/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3344 - accuracy: 0.8992 - val_loss: 0.5698 - val_accuracy: 0.8386\n",
            "Epoch 190/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3402 - accuracy: 0.8982 - val_loss: 0.5932 - val_accuracy: 0.8378\n",
            "Epoch 191/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3353 - accuracy: 0.8983 - val_loss: 0.5749 - val_accuracy: 0.8423\n",
            "Epoch 192/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3388 - accuracy: 0.8983 - val_loss: 0.5708 - val_accuracy: 0.8418\n",
            "Epoch 193/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3360 - accuracy: 0.8986 - val_loss: 0.5642 - val_accuracy: 0.8426\n",
            "Epoch 194/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3387 - accuracy: 0.8979 - val_loss: 0.5820 - val_accuracy: 0.8392\n",
            "Epoch 195/200\n",
            "50000/50000 [==============================] - 3s 55us/sample - loss: 0.3424 - accuracy: 0.8975 - val_loss: 0.5734 - val_accuracy: 0.8426\n",
            "Epoch 196/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.3369 - accuracy: 0.8975 - val_loss: 0.5672 - val_accuracy: 0.8424\n",
            "Epoch 197/200\n",
            "50000/50000 [==============================] - 3s 54us/sample - loss: 0.3418 - accuracy: 0.8980 - val_loss: 0.5674 - val_accuracy: 0.8398\n",
            "Epoch 198/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3347 - accuracy: 0.8996 - val_loss: 0.5570 - val_accuracy: 0.8447\n",
            "Epoch 199/200\n",
            "50000/50000 [==============================] - 3s 52us/sample - loss: 0.3350 - accuracy: 0.8992 - val_loss: 0.5749 - val_accuracy: 0.8414\n",
            "Epoch 200/200\n",
            "50000/50000 [==============================] - 3s 53us/sample - loss: 0.3345 - accuracy: 0.9016 - val_loss: 0.5659 - val_accuracy: 0.8420\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJgvK6AHPd5Y",
        "colab_type": "text"
      },
      "source": [
        "### Adding Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-UqwpMMcdzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Add, Conv2D, Dense, Dropout, Flatten, MaxPooling2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.activations import relu, softmax\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def conv_model(dropout_rate = 0.0):\n",
        "    \n",
        "    dropout_rate = dropout_rate\n",
        "    \n",
        "    input = Input((32, 32, 3), name='input')\n",
        "\n",
        "    batch_norm = BatchNormalization(name=\"batch_norm\")(input)\n",
        "    \n",
        "    conv_1 = Conv2D(32, (3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.00001), activation='relu', name='conv_1')(batch_norm)\n",
        "    pool_1 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_1')(conv_1)\n",
        "    dropout_1 = Dropout(dropout_rate, name='dropout_1')(pool_1)\n",
        "    \n",
        "    conv_2 = Conv2D(32, (3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.00001), activation='relu', name='conv_2')(dropout_1)\n",
        "    pool_2 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_2')(conv_2)\n",
        "    dropout_2 = Dropout(dropout_rate, name='dropout_2')(pool_2)\n",
        "\n",
        "    conv_3 = Conv2D(64, (3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.00001), activation='relu', name='conv_3')(dropout_2)\n",
        "    pool_3 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_3')(conv_3)\n",
        "    dropout_3 = Dropout(dropout_rate, name='dropout_3')(pool_3)\n",
        "\n",
        "    conv_4 = Conv2D(64, (3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.00001), activation='relu', name='conv_4')(dropout_3)\n",
        "    pool_4 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_4')(conv_4)\n",
        "    dropout_4 = Dropout(dropout_rate, name='dropout_4')(pool_4)\n",
        "\n",
        "    conv_5 = Conv2D(96, (3,3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.00001), activation='relu', name='conv_5')(dropout_4)\n",
        "    pool_5 = MaxPooling2D(pool_size=(2, 2), padding='same', name='pool_5')(conv_5)\n",
        "    dropout_5 = Dropout(dropout_rate, name='dropout_5')(pool_5)\n",
        "    \n",
        "    flatten = Flatten(name='flatten')(dropout_4)\n",
        "    batch_norm_2 = BatchNormalization(name=\"batch_norm_2\")(flatten)\n",
        "\n",
        "    fc_1 = Dense(120, activation='relu', name='fc_1')(batch_norm_2)\n",
        "    batch_norm_3 = BatchNormalization(name=\"batch_norm_3\")(fc_1)\n",
        "    dropout_6 = Dropout(dropout_rate, name='dropout_6')(batch_norm_3)\n",
        "    fc_2 = Dense(80, activation='relu', name='fc_2')(dropout_6)\n",
        "    batch_norm_4 = BatchNormalization(name=\"batch_norm_4\")(fc_2)\n",
        "    dropout_7 = Dropout(dropout_rate, name='dropout_7')(batch_norm_4)\n",
        "    \n",
        "    output = Dense(10, activation='softmax', name='output')(dropout_7)\n",
        "    model = Model(input, output)\n",
        "    \n",
        "    plot_model(model, 'CNN_2.png')\n",
        "    \n",
        "    model.compile(\n",
        "      optimizer=Adam(learning_rate=0.001),\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "    )\n",
        "\n",
        "    #data augmentation\n",
        "    datagen = ImageDataGenerator(\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        )\n",
        "  \n",
        "    batch_size = 128\n",
        "    train_datagen = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
        "    steps = int(x_train.shape[0] / batch_size)\n",
        "\n",
        "    hist = model.fit_generator(train_datagen, \n",
        "                               steps_per_epoch=steps,\n",
        "                               epochs=150,\n",
        "                               validation_data=(x_test, y_test))\n",
        "\n",
        "\t  #history = model.fit_generator( epochs=200, validation_data=(testX, testY), verbose=0)\n",
        "\n",
        "\n",
        "    history_model(hist.history)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = conv_model(0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1ruFLClIAKn",
        "colab_type": "text"
      },
      "source": [
        "### Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1ImzPuBIdjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"CNN.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT432S9k00Zx",
        "colab_type": "text"
      },
      "source": [
        "### let's run some tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBUQ8WcScUre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "img_row, img_height, img_depth = 32,32,3\n",
        "color = True\n",
        "scale = 8\n",
        "\n",
        "\n",
        "#model = model.load_weights(tf.train.latest_checkpoint('/content/chekpoints'))\n",
        "eval_loss, eval_acc = model.evaluate(x_test, y_test)\n",
        "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))\n",
        "\n",
        "def draw_test(name, res, input_im, scale, img_row, img_height):\n",
        "    BLACK = [0,0,0]\n",
        "    res = int(res)\n",
        "    if res == 0:\n",
        "        pred = \"airplane\"\n",
        "    if res == 1:\n",
        "        pred = \"automobile\"\n",
        "    if res == 2:\n",
        "        pred = \"bird\"\n",
        "    if res == 3:\n",
        "        pred = \"cat\"\n",
        "    if res == 4:\n",
        "        pred = \"deer\"\n",
        "    if res == 5:\n",
        "        pred = \"dog\"\n",
        "    if res == 6:\n",
        "        pred = \"frog\"\n",
        "    if res == 7:\n",
        "        pred = \"horse\"\n",
        "    if res == 8:\n",
        "        pred = \"ship\"\n",
        "    if res == 9:\n",
        "        pred = \"truck\"\n",
        "        \n",
        "    expanded_image = cv2.copyMakeBorder(input_im, 0, 0, 0, imageL.shape[0]*2 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
        "    if color == False:\n",
        "        expanded_image = cv2.cvtColor(expanded_image, cv2.COLOR_GRAY2BGR)\n",
        "    cv2.putText(expanded_image, str(pred), (300, 80) , cv2.FONT_HERSHEY_COMPLEX_SMALL,4, (0,255,255), 2)\n",
        "    cv2_imshow( expanded_image)\n",
        "    #cv2.imshow(name, expanded_image)\n",
        "\n",
        "\n",
        "for i in range(0,10):\n",
        "    rand = np.random.randint(0,len(x_test))\n",
        "    input_im = x_test[rand]\n",
        "    imageL = cv2.resize(input_im, None, fx=scale, fy=scale, interpolation = cv2.INTER_CUBIC) \n",
        "    input_im = input_im.reshape(1,img_row, img_height, img_depth) \n",
        "    \n",
        "    ## Get Prediction\n",
        "    res = model.predict(input_im)\n",
        "    res = np.where(res[0] == max(res[0]))[0][0]\n",
        "    draw_test(\"Prediction\", res, imageL, scale, img_row, img_height) \n",
        "    cv2.waitKey(0)\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}